{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Concatenate, Dot, Add, ReLU, Activation\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>측정날짜</th>\n",
       "      <th>측정소명</th>\n",
       "      <th>수온</th>\n",
       "      <th>수소이온농도</th>\n",
       "      <th>전기전도도</th>\n",
       "      <th>용존산소</th>\n",
       "      <th>탁도</th>\n",
       "      <th>총유기탄소</th>\n",
       "      <th>총질소</th>\n",
       "      <th>총인</th>\n",
       "      <th>클로로필-a</th>\n",
       "      <th>미생물_독성지수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.01.01 00:00</td>\n",
       "      <td>가평</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.398</td>\n",
       "      <td>0.006</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.01.01 01:00</td>\n",
       "      <td>가평</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.490</td>\n",
       "      <td>0.003</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.01.01 02:00</td>\n",
       "      <td>가평</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.545</td>\n",
       "      <td>0.003</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.01.01 03:00</td>\n",
       "      <td>가평</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.482</td>\n",
       "      <td>0.002</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.01.01 04:00</td>\n",
       "      <td>가평</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.453</td>\n",
       "      <td>0.003</td>\n",
       "      <td>5.4</td>\n",
       "      <td>-2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8779</th>\n",
       "      <td>2016.12.31 19:00</td>\n",
       "      <td>가평</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.941</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>2016.12.31 20:00</td>\n",
       "      <td>가평</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.034</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>2016.12.31 21:00</td>\n",
       "      <td>가평</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.991</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>2016.12.31 22:00</td>\n",
       "      <td>가평</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.947</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8783</th>\n",
       "      <td>2016.12.31 23:00</td>\n",
       "      <td>가평</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.951</td>\n",
       "      <td>0.008</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8784 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  측정날짜 측정소명   수온  수소이온농도  전기전도도  용존산소   탁도  총유기탄소    총질소  \\\n",
       "0     2016.01.01 00:00   가평  4.5     7.5  126.0  10.8  0.6    1.4  2.398   \n",
       "1     2016.01.01 01:00   가평  4.3     7.5  126.0  10.8  0.5    1.4  2.490   \n",
       "2     2016.01.01 02:00   가평  4.4     7.5  126.0  10.8  0.5    1.4  2.545   \n",
       "3     2016.01.01 03:00   가평  4.4     7.5  126.0  10.8  0.6    1.4  2.482   \n",
       "4     2016.01.01 04:00   가평  4.4     7.5  126.0  10.8  0.6    1.4  2.453   \n",
       "...                ...  ...  ...     ...    ...   ...  ...    ...    ...   \n",
       "8779  2016.12.31 19:00   가평  4.0     7.2  103.0  12.1  0.7    1.6  1.941   \n",
       "8780  2016.12.31 20:00   가평  3.9     7.2  103.0  12.0  0.7    1.6  2.034   \n",
       "8781  2016.12.31 21:00   가평  3.9     7.2  103.0  12.0  0.7    1.6  1.991   \n",
       "8782  2016.12.31 22:00   가평  3.8     7.2  103.0  12.0  0.7    1.6  1.947   \n",
       "8783  2016.12.31 23:00   가평  3.8     7.2  103.0  12.0  0.7    1.6  1.951   \n",
       "\n",
       "         총인  클로로필-a  미생물_독성지수  \n",
       "0     0.006     5.7       0.5  \n",
       "1     0.003     5.4       0.4  \n",
       "2     0.003     5.4       0.5  \n",
       "3     0.002     5.4       4.7  \n",
       "4     0.003     5.4      -2.5  \n",
       "...     ...     ...       ...  \n",
       "8779  0.006     2.0      -0.5  \n",
       "8780  0.006     2.0       1.4  \n",
       "8781  0.007     1.9       0.3  \n",
       "8782  0.008     1.9      -0.7  \n",
       "8783  0.008     2.0      -0.4  \n",
       "\n",
       "[8784 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join('data/', '가평_2016.xlsx')\n",
    "df = pd.read_excel(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 24*60*60\n",
    "year = (365.2425)*day\n",
    "\n",
    "\n",
    "date_time = pd.to_datetime(df.iloc[:, 0], format='%Y.%m.%d %H:%M')\n",
    "\n",
    "timestamp_s = date_time.map(datetime.datetime.timestamp)\n",
    "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = df.mean()\n",
    "train_std = df.std()\n",
    "df = (df-train_mean)/train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>수온</th>\n",
       "      <td>1.411416e+01</td>\n",
       "      <td>8.040039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>수소이온농도</th>\n",
       "      <td>7.373216e+00</td>\n",
       "      <td>0.289219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>전기전도도</th>\n",
       "      <td>1.197928e+02</td>\n",
       "      <td>16.273093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>용존산소</th>\n",
       "      <td>9.891239e+00</td>\n",
       "      <td>1.604121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>탁도</th>\n",
       "      <td>2.743162e+00</td>\n",
       "      <td>5.730403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총유기탄소</th>\n",
       "      <td>1.656653e+00</td>\n",
       "      <td>0.292953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총질소</th>\n",
       "      <td>1.996826e+00</td>\n",
       "      <td>0.582533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>총인</th>\n",
       "      <td>6.082315e-03</td>\n",
       "      <td>0.006765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>클로로필-a</th>\n",
       "      <td>9.806030e+00</td>\n",
       "      <td>6.812405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>미생물_독성지수</th>\n",
       "      <td>-4.918176e-02</td>\n",
       "      <td>1.689751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day sin</th>\n",
       "      <td>2.607568e-14</td>\n",
       "      <td>0.707147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day cos</th>\n",
       "      <td>-2.408112e-15</td>\n",
       "      <td>0.707147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year sin</th>\n",
       "      <td>-6.126821e-06</td>\n",
       "      <td>0.706415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year cos</th>\n",
       "      <td>2.069648e-03</td>\n",
       "      <td>0.707875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0          1\n",
       "수온        1.411416e+01   8.040039\n",
       "수소이온농도    7.373216e+00   0.289219\n",
       "전기전도도     1.197928e+02  16.273093\n",
       "용존산소      9.891239e+00   1.604121\n",
       "탁도        2.743162e+00   5.730403\n",
       "총유기탄소     1.656653e+00   0.292953\n",
       "총질소       1.996826e+00   0.582533\n",
       "총인        6.082315e-03   0.006765\n",
       "클로로필-a    9.806030e+00   6.812405\n",
       "미생물_독성지수 -4.918176e-02   1.689751\n",
       "Day sin   2.607568e-14   0.707147\n",
       "Day cos  -2.408112e-15   0.707147\n",
       "Year sin -6.126821e-06   0.706415\n",
       "Year cos  2.069648e-03   0.707875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([train_mean, train_std], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = val_df = train_df = df\n",
    "\n",
    "OUT_STEPS = 24*3\n",
    "out_num_features = num_features = train_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "            #train_df=None, val_df=None, test_df=None,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "\n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "  def __repr__(self):\n",
    "    return '\\n'.join([\n",
    "        f'Total window size: {self.total_window_size}',\n",
    "        f'Input indices: {self.input_indices}',\n",
    "        f'Label indices: {self.label_indices}',\n",
    "        f'Label column name(s): {self.label_columns}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # Slicing doesn't preserve static shape information, so set the shapes\n",
    "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "@property\n",
    "def example(self):\n",
    "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    # No example batch was found, so get one from the `.train` dataset\n",
    "    result = next(iter(self.train))\n",
    "    # And cache it for next time\n",
    "    self._example = result\n",
    "  return result\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_batch_index(total, batch_size):\n",
    "    '''Sample index of the mini-batch.\n",
    "\n",
    "    Args:\n",
    "        - total: total number of samples\n",
    "        - batch_size: batch size\n",
    "\n",
    "    Returns:\n",
    "        - batch_idx: batch index\n",
    "    '''\n",
    "    total_idx = np.random.permutation(total)\n",
    "    batch_idx = total_idx[:batch_size]\n",
    "    return batch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_sampler(p, shape):\n",
    "  '''Sample binary random variables.\n",
    "  \n",
    "  Args:\n",
    "    - p: probability of 1\n",
    "    - shape: matrix shape\n",
    "    \n",
    "  Returns:\n",
    "    - binary_random_matrix: generated binary random matrix.\n",
    "  '''\n",
    "  unif_random_matrix = np.random.uniform(0., 1., size = shape)\n",
    "  binary_random_matrix = 1*(unif_random_matrix < p)\n",
    "  return binary_random_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_sampler(low, high, shape):\n",
    "  '''Sample uniform random variables.\n",
    "  \n",
    "  Args:\n",
    "    - low: low limit\n",
    "    - high: high limit\n",
    "    - rows: the number of rows\n",
    "    - cols: the number of columns\n",
    "    \n",
    "  Returns:\n",
    "    - uniform_random_matrix: generated uniform random matrix.\n",
    "  '''\n",
    "  return np.random.uniform(low, high, size = shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization (data, parameters=None):\n",
    "  '''Normalize data in [0, 1] range.\n",
    "  \n",
    "  Args:\n",
    "    - data: original data\n",
    "  \n",
    "  Returns:\n",
    "    - norm_data: normalized data\n",
    "    - norm_parameters: min_val, max_val for each feature for renormalization\n",
    "  '''\n",
    "\n",
    "  # Parameters\n",
    "  _, dim = data.shape\n",
    "  norm_data = data.copy()\n",
    "\n",
    "  if parameters is None:\n",
    "\n",
    "    # MixMax normalization\n",
    "    min_val = np.zeros(dim)\n",
    "    max_val = np.zeros(dim)\n",
    "   \n",
    "    # For each dimension\n",
    "    for i in range(dim):\n",
    "      min_val[i] = np.nanmin(norm_data[:,i])\n",
    "      norm_data[:,i] = norm_data[:,i] - np.nanmin(norm_data[:,i])\n",
    "      max_val[i] = np.nanmax(norm_data[:,i])\n",
    "      norm_data[:,i] = norm_data[:,i] / (np.nanmax(norm_data[:,i]) + 1e-6)\n",
    "\n",
    "    # Return norm_parameters for renormalization\n",
    "    norm_parameters = {'min_val': min_val,\n",
    "                       'max_val': max_val}\n",
    "  else:\n",
    "    min_val = parameters['min_val']\n",
    "    max_val = parameters['max_val']\n",
    "\n",
    "    # For each dimension\n",
    "    for i in range(dim):\n",
    "      norm_data[:,i] = norm_data[:,i] - min_val[i]\n",
    "      norm_data[:,i] = norm_data[:,i] / (max_val[i] + 1e-6)\n",
    "\n",
    "    norm_parameters = parameters\n",
    "\n",
    "  return norm_data, norm_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features = [6]\n",
    "class WaterDataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for water'\n",
    "    def __init__(self,\n",
    "                 imputed_data,\n",
    "                 ori_data = None,\n",
    "                 batch_size=32,\n",
    "                 input_width=24*7,\n",
    "                 label_width=24*3,\n",
    "                 shift=24*3,\n",
    "                 skip_time = None,\n",
    "                 shuffle = True,\n",
    "                 out_features = None,\n",
    "                 out_num_features = None,\n",
    "                ):\n",
    "        'Initialization'\n",
    "        self.window_size = input_width+shift\n",
    "        self.total_no = imputed_data.shape[0]\n",
    "        self.data = imputed_data\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = (batch_size, input_width, self.data.shape[1])\n",
    "        self.out_num_features = out_num_features\n",
    "        if out_features:\n",
    "            self.out_features = out_features\n",
    "        else:\n",
    "            self.out_features = [i for i in range(out_num_features)]\n",
    "        self.label_shape = (batch_size, label_width, self.out_num_features)\n",
    "        if (skip_time):\n",
    "            # TO-DO\n",
    "            self.no = self.total_no - self.window_size\n",
    "            self.data_idx = np.arange(0, self.no)\n",
    "        else:\n",
    "            self.no = self.total_no - self.window_size\n",
    "            self.data_idx = np.arange(0, self.no)\n",
    "            \n",
    "        if shuffle:\n",
    "            self.batch_idx = np.random.permutation(self.no)\n",
    "        else:\n",
    "            self.batch_idx = np.arange(0, self.no)\n",
    "        self.batch_id = 0\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        #return int(128/self.batch_size)\n",
    "        #return 2\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        #print('index =', index)\n",
    "        #print('self.no =', self.no)\n",
    "        #print('self.total_no =', self.total_no)\n",
    "        #print('self.batch_id =', self.batch_id)\n",
    "        # Sample batch\n",
    "        label_width = self.label_width\n",
    "        batch_idx = self.batch_idx\n",
    "        \n",
    "        x = np.empty((0, self.input_width, self.data.shape[1]))\n",
    "        \n",
    "        #y = np.empty((0, self.input_width, self.data.shape[1]))\n",
    "        y = np.empty((0, self.label_width, self.out_num_features))\n",
    "       \n",
    "        #print(x.shape)\n",
    "        #print(y.shape)\n",
    "        \n",
    "        \n",
    "        for cnt in range(0, self.batch_size):\n",
    "            i = self.batch_id\n",
    "            self.batch_id += 1\n",
    "            idx1 = self.data_idx[batch_idx[i]]\n",
    "            idx2 = idx1 + self.input_width\n",
    "            \n",
    "            X = self.data[idx1:idx2].to_numpy()\n",
    "            \n",
    "            \n",
    "            idx1 = self.data_idx[batch_idx[i]] + self.window_size - label_width\n",
    "            idx2 = idx1 + label_width\n",
    "            \n",
    "            #Y = self.data[idx1:idx2,:,:out_num_features]\n",
    "            Y = self.data.iloc[idx1:idx2, self.out_features].to_numpy()\n",
    "            #Y = self.data[idx1:idx2]\n",
    "            #print('Y.shape = ', Y.shape)\n",
    "            #Y = Y.iloc[:,:out_num_features]\n",
    "            \n",
    "            self.batch_id %= self.no\n",
    "            #print(\"x.shape=\", x.shape)\n",
    "            #print('X.shape=', X.shape)\n",
    "            #print(type(x), type(X))\n",
    "            x = np.append(x, [X], axis = 0)\n",
    "            \n",
    "            y = np.append(y, [Y], axis = 0)\n",
    "            \n",
    "        return x, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_water(self, data):\n",
    "  dg = WaterDataGenerator(\n",
    "      data,\n",
    "      batch_size = 128,\n",
    "      input_width = self.input_width,\n",
    "      label_width = self.label_width,\n",
    "      shift = self.label_width,\n",
    "      out_features = out_features,\n",
    "      out_num_features = out_num_features,\n",
    "  )\n",
    "  #self.dg = dg\n",
    "  ds = tf.data.Dataset.from_generator(\n",
    "      lambda: dg,\n",
    "      output_types=(tf.float32, tf.float32),\n",
    "      output_shapes=(\n",
    "        dg.input_shape,\n",
    "        dg.label_shape\n",
    "        #[batch_size, train_generator.dim],\n",
    "        #[batch_size, train_generator.dim],\n",
    "      )\n",
    "  )\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset_water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_window = WindowGenerator(input_width=24*7,\n",
    "                               label_width=OUT_STEPS,\n",
    "                               shift=OUT_STEPS,\n",
    "                               train_df=train_df,\n",
    "                               val_df=val_df,\n",
    "                               test_df=test_df,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 400\n",
    "\n",
    "def compile_and_fit(model, window, patience=1000):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "#   model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "#                 optimizer=tf.optimizers.Adam(),\n",
    "#                 metrics=[tf.metrics.MeanSquaredError()])\n",
    "  #model.compile(loss=GAIN.RMSE_loss)\n",
    "\n",
    "  history = model.fit(\n",
    "      window.train,\n",
    "      epochs=MAX_EPOCHS,\n",
    "      validation_data=window.val,\n",
    "      callbacks=[early_stopping])\n",
    "                      \n",
    "                     #)\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 16 and the array at index 1 has size 1\nTraceback (most recent call last):\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 483, in __iter__\n    for item in (self[i] for i in range(len(self))):\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 483, in <genexpr>\n    for item in (self[i] for i in range(len(self))):\n\n  File \"<ipython-input-15-2a9f18bd70d5>\", line 94, in __getitem__\n    y = np.append(y, [Y], axis = 0)\n\n  File \"<__array_function__ internals>\", line 6, in append\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/numpy/lib/function_base.py\", line 4671, in append\n    return concatenate((arr, values), axis=axis)\n\n  File \"<__array_function__ internals>\", line 6, in concatenate\n\nValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 16 and the array at index 1 has size 1\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_5206]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e11f0853b8b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#multi_linear_model.summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_and_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_linear_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-25d534edb90a>\u001b[0m in \u001b[0;36mcompile_and_fit\u001b[0;34m(model, window, patience)\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       callbacks=[])\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                      \u001b[0;31m#)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv379/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv379/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv379/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv379/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv379/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv379/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/venv379/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 16 and the array at index 1 has size 1\nTraceback (most recent call last):\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 891, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 483, in __iter__\n    for item in (self[i] for i in range(len(self))):\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 483, in <genexpr>\n    for item in (self[i] for i in range(len(self))):\n\n  File \"<ipython-input-15-2a9f18bd70d5>\", line 94, in __getitem__\n    y = np.append(y, [Y], axis = 0)\n\n  File \"<__array_function__ internals>\", line 6, in append\n\n  File \"/home/jaewon/venv379/lib/python3.7/site-packages/numpy/lib/function_base.py\", line 4671, in append\n    return concatenate((arr, values), axis=axis)\n\n  File \"<__array_function__ internals>\", line 6, in concatenate\n\nValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 16 and the array at index 1 has size 1\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_5206]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "multi_linear_model = tf.keras.Sequential([\n",
    "    # Take the last time-step.\n",
    "    # Shape [batch, time, features] => [batch, 1, features]\n",
    "    tf.keras.layers.Lambda(lambda x: x[:, -1:, :]),\n",
    "    # Shape => [batch, 1, out_steps*features]\n",
    "    tf.keras.layers.Dense(OUT_STEPS*out_num_features,\n",
    "                          kernel_initializer=tf.initializers.zeros),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, out_num_features])\n",
    "])\n",
    "\n",
    "#multi_linear_model.summary\n",
    "\n",
    "history = compile_and_fit(multi_linear_model, multi_window)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satellite-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "from core.gain import *\n",
    "from core.rnn_predic import *\n",
    "from core.models import *\n",
    "from core.util import *\n",
    "#from core.window import WindowGenerator, MissData, make_dataset_water, WaterDataGenerator\n",
    "from core.window import WindowGenerator, make_dataset_gain, make_dataset_water\n",
    "from core.file_open import make_dataframe\n",
    "from core.miss_data import MissData\n",
    "import json\n",
    "%matplotlib widget\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collective-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "parameters_dir = 'input'\n",
    "\n",
    "parameters_file = 'input.json'\n",
    "parameters_path = '{dir}/{file}'.format(dir=parameters_dir, file=parameters_file)\n",
    "\n",
    "with open(parameters_path, encoding='utf8') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "\n",
    "gain_parameters = parameters['gain']\n",
    "rnn_parameters = parameters['rnn']\n",
    "file_parameters = parameters['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "saving-locator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'watershed': 'han'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "virgin-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_path = parameters_dir+'/'+ file_parameters['watershed'] + '.json'\n",
    "with open(parameters_path, encoding='utf8') as json_file:\n",
    "    parameters = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "satellite-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "shaped-criticism",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parameters = parameters['data']\n",
    "\n",
    "interpolation_option = data_parameters['interpolation']\n",
    "colum_idx = data_parameters['columns']\n",
    "watershed = data_parameters['watershed']\n",
    "file_names = data_parameters['files']\n",
    "folder = data_parameters['directorys']\n",
    "for i in range(len(folder)):\n",
    "    folder[i] = watershed+folder[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recorded-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "__GAIN_TRAINING__ = gain_parameters['train']\n",
    "gain_epochs = gain_parameters['max_epochs']\n",
    "gain_in_setps = gain_parameters['input_width']\n",
    "gain_out_setps = gain_parameters['label_width']\n",
    "gain_batch_size = gain_parameters['batch_size']\n",
    "gain_fill_no = gain_parameters['fill_width']\n",
    "gain_shift = gain_parameters['shift_width']\n",
    "gain_miss_rate = gain_parameters['miss_rate']\n",
    "\n",
    "__RNN_TRAINING__ = rnn_parameters['train']\n",
    "rnn_epochs = rnn_parameters['max_epochs']\n",
    "rnn_in_setps = rnn_parameters['input_width']\n",
    "rnn_out_steps = rnn_parameters['label_width']\n",
    "rnn_batch_size = rnn_parameters['batch_size']\n",
    "rnn_predict_day = rnn_parameters['predict_day']\n",
    "rnn_target_column = rnn_parameters['target_column']\n",
    "\n",
    "if rnn_predict_day < 3 or rnn_predict_day >5:\n",
    "    print('predict_day err')\n",
    "    exit(88)\n",
    "rnn_predict_day -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "loved-serum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 150)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gain_epochs , rnn_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vertical-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_num = range(len(folder))\n",
    "real_df_all = pd.DataFrame([])\n",
    "target_all = target_mean = target_std = 0\n",
    "\n",
    "gain_val_performance = {}\n",
    "gain_performance = {}\n",
    "\n",
    "length = len(run_num)\n",
    "#length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "authorized-ribbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpol flag :  [False, False]\n",
      "folder :  data/han/자동/\n",
      "colum_idx :  :,[26,27,28,29,30,31,32,33]\n",
      "file_names[idx] :  [['가평_2016.xlsx', '가평_2017.xlsx', '가평_2018.xlsx', '가평_2019.xlsx'], ['서상_2016.xlsx', '서상_2017.xlsx', '서상_2018.xlsx', '서상_2019.xlsx'], ['의암호_2016.xlsx', '의암호_2017.xlsx', '의암호_2018.xlsx', '의암호_2019.xlsx']]\n",
      "data/han/자동/가평_2016.xlsx\n",
      "data/han/자동/가평_2017.xlsx\n",
      "data/han/자동/가평_2018.xlsx\n",
      "data/han/자동/가평_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/자동/서상_2016.xlsx\n",
      "data/han/자동/서상_2017.xlsx\n",
      "data/han/자동/서상_2018.xlsx\n",
      "data/han/자동/서상_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/자동/의암호_2016.xlsx\n",
      "data/han/자동/의암호_2017.xlsx\n",
      "data/han/자동/의암호_2018.xlsx\n",
      "data/han/자동/의암호_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "MissData :  save/  miss :  (5327, 12)\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2665\n",
      "MissData :  save/  miss :  (5327, 12)\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/han/수질/\n",
      "colum_idx :  :,[28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44]\n",
      "file_names[idx] :  [['대성리_2016.xlsx', '대성리_2017.xlsx', '대성리_2018.xlsx', '대성리_2019.xlsx'], ['청평댐3_2016.xlsx', '청평댐3_2017.xlsx', '청평댐3_2018.xlsx', '청평댐3_2019.xlsx'], ['남이섬_2016.xlsx', '남이섬_2017.xlsx', '남이섬_2018.xlsx', '남이섬_2019.xlsx'], ['가평천3_2016.xlsx', '가평천3_2017.xlsx', '가평천3_2018.xlsx', '가평천3_2019.xlsx'], ['춘성교_2016.xlsx', '춘성교_2017.xlsx', '춘성교_2018.xlsx', '춘성교_2019.xlsx'], ['의암_2016.xlsx', '의암_2017.xlsx', '의암_2018.xlsx', '의암_2019.xlsx'], ['춘천_2016.xlsx', '춘천_2017.xlsx', '춘천_2018.xlsx', '춘천_2019.xlsx'], ['춘천댐1_2016.xlsx', '춘천댐1_2017.xlsx', '춘천댐1_2018.xlsx', '춘천댐1_2019.xlsx'], ['춘천댐3_2016.xlsx', '춘천댐3_2017.xlsx', '춘천댐3_2018.xlsx', '춘천댐3_2019.xlsx']]\n",
      "data/han/수질/대성리_2016.xlsx\n",
      "data/han/수질/대성리_2017.xlsx\n",
      "data/han/수질/대성리_2018.xlsx\n",
      "data/han/수질/대성리_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수질/청평댐3_2016.xlsx\n",
      "data/han/수질/청평댐3_2017.xlsx\n",
      "data/han/수질/청평댐3_2018.xlsx\n",
      "data/han/수질/청평댐3_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수질/남이섬_2016.xlsx\n",
      "data/han/수질/남이섬_2017.xlsx\n",
      "data/han/수질/남이섬_2018.xlsx\n",
      "data/han/수질/남이섬_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수질/가평천3_2016.xlsx\n",
      "data/han/수질/가평천3_2017.xlsx\n",
      "data/han/수질/가평천3_2018.xlsx\n",
      "data/han/수질/가평천3_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수질/춘성교_2016.xlsx\n",
      "data/han/수질/춘성교_2017.xlsx\n",
      "data/han/수질/춘성교_2018.xlsx\n",
      "data/han/수질/춘성교_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수질/의암_2016.xlsx\n",
      "data/han/수질/의암_2017.xlsx\n",
      "data/han/수질/의암_2018.xlsx\n",
      "data/han/수질/의암_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수질/춘천_2016.xlsx\n",
      "data/han/수질/춘천_2017.xlsx\n",
      "data/han/수질/춘천_2018.xlsx\n",
      "data/han/수질/춘천_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수질/춘천댐1_2016.xlsx\n",
      "data/han/수질/춘천댐1_2017.xlsx\n",
      "data/han/수질/춘천댐1_2018.xlsx\n",
      "data/han/수질/춘천댐1_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수질/춘천댐3_2016.xlsx\n",
      "data/han/수질/춘천댐3_2017.xlsx\n",
      "data/han/수질/춘천댐3_2018.xlsx\n",
      "data/han/수질/춘천댐3_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/han/방사성/\n",
      "colum_idx :  :,[29]\n",
      "file_names[idx] :  [['의암댐_2016.xlsx', '의암댐_2017.xlsx', '의암댐_2018.xlsx', '의암댐_2019.xlsx']]\n",
      "data/han/방사성/의암댐_2016.xlsx\n",
      "data/han/방사성/의암댐_2017.xlsx\n",
      "data/han/방사성/의암댐_2018.xlsx\n",
      "data/han/방사성/의암댐_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/han/TMS/\n",
      "colum_idx :  :,[27,28,30,31,32,33,35]\n",
      "file_names[idx] :  [['가평청평하수_2016.xlsx', '가평청평하수_2017.xlsx', '가평청평하수_2018.xlsx', '가평청평하수_2019.xlsx'], ['가평신천하수_2016.xlsx', '가평신천하수_2017.xlsx', '가평신천하수_2018.xlsx', '가평신천하수_2019.xlsx'], ['가평하수_2016.xlsx', '가평하수_2017.xlsx', '가평하수_2018.xlsx', '가평하수_2019.xlsx'], ['춘천강촌하수_2016.xlsx', '춘천강촌하수_2017.xlsx', '춘천강촌하수_2018.xlsx', '춘천강촌하수_2019.xlsx'], ['춘천하수_2016.xlsx', '춘천하수_2017.xlsx', '춘천하수_2018.xlsx', '춘천하수_2019.xlsx'], ['화천하수_2016.xlsx', '화천하수_2017.xlsx', '화천하수_2018.xlsx', '화천하수_2019.xlsx']]\n",
      "data/han/TMS/가평청평하수_2016.xlsx\n",
      "data/han/TMS/가평청평하수_2017.xlsx\n",
      "data/han/TMS/가평청평하수_2018.xlsx\n",
      "data/han/TMS/가평청평하수_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/TMS/가평신천하수_2016.xlsx\n",
      "data/han/TMS/가평신천하수_2017.xlsx\n",
      "data/han/TMS/가평신천하수_2018.xlsx\n",
      "data/han/TMS/가평신천하수_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/TMS/가평하수_2016.xlsx\n",
      "data/han/TMS/가평하수_2017.xlsx\n",
      "data/han/TMS/가평하수_2018.xlsx\n",
      "data/han/TMS/가평하수_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/TMS/춘천강촌하수_2016.xlsx\n",
      "data/han/TMS/춘천강촌하수_2017.xlsx\n",
      "data/han/TMS/춘천강촌하수_2018.xlsx\n",
      "data/han/TMS/춘천강촌하수_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/TMS/춘천하수_2016.xlsx\n",
      "data/han/TMS/춘천하수_2017.xlsx\n",
      "data/han/TMS/춘천하수_2018.xlsx\n",
      "data/han/TMS/춘천하수_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/TMS/화천하수_2016.xlsx\n",
      "data/han/TMS/화천하수_2017.xlsx\n",
      "data/han/TMS/화천하수_2018.xlsx\n",
      "data/han/TMS/화천하수_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "interpol flag :  [False, False]\n",
      "folder :  data/han/유량/\n",
      "colum_idx :  :,[26]\n",
      "file_names[idx] :  [['가평군(대성리)_2016.xlsx', '가평군(대성리)_2017.xlsx', '가평군(대성리)_2018.xlsx', '가평군(대성리)_2019.xlsx'], ['가평군(청평교)_2016.xlsx', '가평군(청평교)_2017.xlsx', '가평군(청평교)_2018.xlsx', '가평군(청평교)_2019.xlsx'], ['가평군(가평교)_2016.xlsx', '가평군(가평교)_2017.xlsx', '가평군(가평교)_2018.xlsx', '가평군(가평교)_2019.xlsx'], ['춘천시(강촌교)_2016.xlsx', '춘천시(강촌교)_2017.xlsx', '춘천시(강촌교)_2018.xlsx', '춘천시(강촌교)_2019.xlsx']]\n",
      "data/han/유량/가평군(대성리)_2016.xlsx\n",
      "data/han/유량/가평군(대성리)_2017.xlsx\n",
      "data/han/유량/가평군(대성리)_2018.xlsx\n",
      "data/han/유량/가평군(대성리)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/유량/가평군(청평교)_2016.xlsx\n",
      "data/han/유량/가평군(청평교)_2017.xlsx\n",
      "data/han/유량/가평군(청평교)_2018.xlsx\n",
      "data/han/유량/가평군(청평교)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/유량/가평군(가평교)_2016.xlsx\n",
      "data/han/유량/가평군(가평교)_2017.xlsx\n",
      "data/han/유량/가평군(가평교)_2018.xlsx\n",
      "data/han/유량/가평군(가평교)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/유량/춘천시(강촌교)_2016.xlsx\n",
      "data/han/유량/춘천시(강촌교)_2017.xlsx\n",
      "data/han/유량/춘천시(강촌교)_2018.xlsx\n",
      "data/han/유량/춘천시(강촌교)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "MissData :  save/  miss :  (3796, 5)\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2488\n",
      "MissData :  save/  miss :  (3796, 5)\n",
      "interpol flag :  [False, False]\n",
      "folder :  data/han/수위/\n",
      "colum_idx :  :,[26]\n",
      "file_names[idx] :  [['가평군(대성리)_2016.xlsx', '가평군(대성리)_2017.xlsx', '가평군(대성리)_2018.xlsx', '가평군(대성리)_2019.xlsx'], ['가평군(청평교)_2016.xlsx', '가평군(청평교)_2017.xlsx', '가평군(청평교)_2018.xlsx', '가평군(청평교)_2019.xlsx'], ['가평군(청평댐)_2016.xlsx', '가평군(청평댐)_2017.xlsx', '가평군(청평댐)_2018.xlsx', '가평군(청평댐)_2019.xlsx'], ['가평군(가평교)_2016.xlsx', '가평군(가평교)_2017.xlsx', '가평군(가평교)_2018.xlsx', '가평군(가평교)_2019.xlsx'], ['춘천시(강촌교)_2016.xlsx', '춘천시(강촌교)_2017.xlsx', '춘천시(강촌교)_2018.xlsx', '춘천시(강촌교)_2019.xlsx'], ['춘천시(소양2교)_2016.xlsx', '춘천시(소양2교)_2017.xlsx', '춘천시(소양2교)_2018.xlsx', '춘천시(소양2교)_2019.xlsx'], ['춘천시(춘천댐)_2016.xlsx', '춘천시(춘천댐)_2017.xlsx', '춘천시(춘천댐)_2018.xlsx', '춘천시(춘천댐)_2019.xlsx'], ['화천군(화천대교)_2016.xlsx', '화천군(화천대교)_2017.xlsx', '화천군(화천대교)_2018.xlsx', '화천군(화천대교)_2019.xlsx']]\n",
      "data/han/수위/가평군(대성리)_2016.xlsx\n",
      "data/han/수위/가평군(대성리)_2017.xlsx\n",
      "data/han/수위/가평군(대성리)_2018.xlsx\n",
      "data/han/수위/가평군(대성리)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수위/가평군(청평교)_2016.xlsx\n",
      "data/han/수위/가평군(청평교)_2017.xlsx\n",
      "data/han/수위/가평군(청평교)_2018.xlsx\n",
      "data/han/수위/가평군(청평교)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수위/가평군(청평댐)_2016.xlsx\n",
      "data/han/수위/가평군(청평댐)_2017.xlsx\n",
      "data/han/수위/가평군(청평댐)_2018.xlsx\n",
      "data/han/수위/가평군(청평댐)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수위/가평군(가평교)_2016.xlsx\n",
      "data/han/수위/가평군(가평교)_2017.xlsx\n",
      "data/han/수위/가평군(가평교)_2018.xlsx\n",
      "data/han/수위/가평군(가평교)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수위/춘천시(강촌교)_2016.xlsx\n",
      "data/han/수위/춘천시(강촌교)_2017.xlsx\n",
      "data/han/수위/춘천시(강촌교)_2018.xlsx\n",
      "data/han/수위/춘천시(강촌교)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/han/수위/춘천시(소양2교)_2016.xlsx\n",
      "data/han/수위/춘천시(소양2교)_2017.xlsx\n",
      "data/han/수위/춘천시(소양2교)_2018.xlsx\n",
      "data/han/수위/춘천시(소양2교)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수위/춘천시(춘천댐)_2016.xlsx\n",
      "data/han/수위/춘천시(춘천댐)_2017.xlsx\n",
      "data/han/수위/춘천시(춘천댐)_2018.xlsx\n",
      "data/han/수위/춘천시(춘천댐)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/수위/화천군(화천대교)_2016.xlsx\n",
      "data/han/수위/화천군(화천대교)_2017.xlsx\n",
      "data/han/수위/화천군(화천대교)_2018.xlsx\n",
      "data/han/수위/화천군(화천대교)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "MissData :  save/  miss :  (5759, 5)\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1020\n",
      "MissData :  save/  miss :  (5759, 5)\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/han/총량/\n",
      "colum_idx :  :,28:45\n",
      "file_names[idx] :  [['조종천3_2016.xlsx', '조종천3_2017.xlsx', '조종천3_2018.xlsx', '조종천3_2019.xlsx'], ['청평_2016.xlsx', '청평_2017.xlsx', '청평_2018.xlsx', '청평_2019.xlsx'], ['가평천3_2016.xlsx', '가평천3_2017.xlsx', '가평천3_2018.xlsx', '가평천3_2019.xlsx'], ['춘성교_2016.xlsx', '춘성교_2017.xlsx', '춘성교_2018.xlsx', '춘성교_2019.xlsx'], ['화천_2016.xlsx', '화천_2017.xlsx', '화천_2018.xlsx', '화천_2019.xlsx']]\n",
      "data/han/총량/조종천3_2016.xlsx\n",
      "data/han/총량/조종천3_2017.xlsx\n",
      "data/han/총량/조종천3_2018.xlsx\n",
      "data/han/총량/조종천3_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/총량/청평_2016.xlsx\n",
      "data/han/총량/청평_2017.xlsx\n",
      "data/han/총량/청평_2018.xlsx\n",
      "data/han/총량/청평_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/총량/가평천3_2016.xlsx\n",
      "data/han/총량/가평천3_2017.xlsx\n",
      "data/han/총량/가평천3_2018.xlsx\n",
      "data/han/총량/가평천3_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/총량/춘성교_2016.xlsx\n",
      "data/han/총량/춘성교_2017.xlsx\n",
      "data/han/총량/춘성교_2018.xlsx\n",
      "data/han/총량/춘성교_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/총량/화천_2016.xlsx\n",
      "data/han/총량/화천_2017.xlsx\n",
      "data/han/총량/화천_2018.xlsx\n",
      "data/han/총량/화천_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/han/퇴적물/\n",
      "colum_idx :  :,[27,28,29,30,31,33]\n",
      "file_names[idx] :  [['대성리_2016.xlsx', '대성리_2017.xlsx', '대성리_2018.xlsx', '대성리_2019.xlsx'], ['청평댐2_2016.xlsx', '청평댐2_2017.xlsx', '청평댐2_2018.xlsx', '청평댐2_2019.xlsx'], ['춘성교_2016.xlsx', '춘성교_2017.xlsx', '춘성교_2018.xlsx', '춘성교_2019.xlsx'], ['의암댐2_2016.xlsx', '의암댐2_2017.xlsx', '의암댐2_2018.xlsx', '의암댐2_2019.xlsx'], ['춘천댐2_2016.xlsx', '춘천댐2_2017.xlsx', '춘천댐2_2018.xlsx', '춘천댐2_2019.xlsx'], ['춘천댐3_2016.xlsx', '춘천댐3_2017.xlsx', '춘천댐3_2018.xlsx', '춘천댐3_2019.xlsx']]\n",
      "data/han/퇴적물/대성리_2016.xlsx\n",
      "data/han/퇴적물/대성리_2017.xlsx\n",
      "data/han/퇴적물/대성리_2018.xlsx\n",
      "data/han/퇴적물/대성리_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/퇴적물/청평댐2_2016.xlsx\n",
      "data/han/퇴적물/청평댐2_2017.xlsx\n",
      "data/han/퇴적물/청평댐2_2018.xlsx\n",
      "data/han/퇴적물/청평댐2_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/퇴적물/춘성교_2016.xlsx\n",
      "data/han/퇴적물/춘성교_2017.xlsx\n",
      "data/han/퇴적물/춘성교_2018.xlsx\n",
      "data/han/퇴적물/춘성교_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/퇴적물/의암댐2_2016.xlsx\n",
      "data/han/퇴적물/의암댐2_2017.xlsx\n",
      "data/han/퇴적물/의암댐2_2018.xlsx\n",
      "data/han/퇴적물/의암댐2_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/퇴적물/춘천댐2_2016.xlsx\n",
      "data/han/퇴적물/춘천댐2_2017.xlsx\n",
      "data/han/퇴적물/춘천댐2_2018.xlsx\n",
      "data/han/퇴적물/춘천댐2_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/퇴적물/춘천댐3_2016.xlsx\n",
      "data/han/퇴적물/춘천댐3_2017.xlsx\n",
      "data/han/퇴적물/춘천댐3_2018.xlsx\n",
      "data/han/퇴적물/춘천댐3_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/han/조류/\n",
      "colum_idx :  :,[30,31,36,40,50]\n",
      "file_names[idx] :  [['의암호_2016.xlsx', '의암호_2017.xlsx', '의암호_2018.xlsx', '의암호_2019.xlsx'], ['춘천호_2016.xlsx', '춘천호_2017.xlsx', '춘천호_2018.xlsx', '춘천호_2019.xlsx']]\n",
      "data/han/조류/의암호_2016.xlsx\n",
      "data/han/조류/의암호_2017.xlsx\n",
      "data/han/조류/의암호_2018.xlsx\n",
      "data/han/조류/의암호_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/han/조류/춘천호_2016.xlsx\n",
      "data/han/조류/춘천호_2017.xlsx\n",
      "data/han/조류/춘천호_2018.xlsx\n",
      "data/han/조류/춘천호_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n"
     ]
    }
   ],
   "source": [
    "for i in range(length):\n",
    "\n",
    "    idx = run_num[i]\n",
    "\n",
    "    print('interpol flag : ', interpolation_option[idx])\n",
    "    print('folder : ', data_path + folder[idx])\n",
    "    print('colum_idx : ', colum_idx[idx])\n",
    "    print('file_names[idx] : ', file_names[idx])\n",
    "\n",
    "    #start = time.time()\n",
    "\n",
    "    #if watershed == '한강_12days_test':\n",
    "    #    df, times = make_dataframe_temp_12days(folder[idx], file_names[idx], colum_idx[idx], interpolate=interpolation_option[idx])\n",
    "    #else:\n",
    "    df, times = make_dataframe(data_path+folder[idx], file_names[idx], colum_idx[idx], interpolation=interpolation_option[idx])\n",
    "\n",
    "    df_all, train_mean, train_std, df = normalize(df)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "    if i == 0:\n",
    "        dfff = df\n",
    "        target_all = df_all\n",
    "        target_std = train_std\n",
    "        target_mean = train_mean\n",
    "        start_year = str(times.iloc[0].year)\n",
    "        end_year = str(times.iloc[-1].year)\n",
    "\n",
    "    if interpolation_option[idx][0] == False:\n",
    "\n",
    "        loadfiles = ['idx.npy', 'miss.npy', 'discriminator.h5', 'generator.h5']\n",
    "\n",
    "        gain_calc_falg = True\n",
    "\n",
    "        if __GAIN_TRAINING__ == True:\n",
    "            gain_calc_falg = MissData.save(pd.concat(df, axis=0).to_numpy(), max_tseq=24, save_dir='save/')\n",
    "            #print(folder[idx], ': training ', 'Miss date save : ', gain_calc_falg)\n",
    "        else:\n",
    "            for file in loadfiles:\n",
    "                if os.path.isfile('save/' + folder[idx]+file):\n",
    "                    shutil.copyfile('save/' + folder[idx]+file, 'save/'+file)\n",
    "                    #print('load file name : save/' + folder[idx]+file)\n",
    "                else:\n",
    "                    if file == 'miss.npy':\n",
    "                        gain_calc_falg = MissData.save(pd.concat(df, axis=0).to_numpy(), max_tseq=24, save_dir='save/')\n",
    "                        #print(folder[idx], ': is not miss.npy ', 'Miss date save : ', gain_calc_falg)\n",
    "\n",
    "        if gain_calc_falg == True:\n",
    "            #print('GainWindowGenerator in main')\n",
    "            WindowGenerator.make_dataset = make_dataset_gain\n",
    "            wide_window = WindowGenerator(input_width=gain_in_setps, label_width=gain_out_setps, shift=gain_shift,\n",
    "                                          fill_no=gain_fill_no, miss_rate=gain_miss_rate, batch_size=gain_batch_size,\n",
    "                                          train_df = df_all, val_df = df_all, test_df = df_all, df = df)\n",
    "\n",
    "            #gain = model_GAIN(shape=wide_window.dg.shape[1:], gen_sigmoid=False, epochs=gain_epochs, training_flag=__GAIN_TRAINING__, window=wide_window, model_save_path='save/')\n",
    "            gain = model_GAIN(shape=(gain_in_setps, df_all.shape[1]), gen_sigmoid=False, epochs=gain_epochs,\n",
    "                              training_flag=__GAIN_TRAINING__, window=wide_window, model_save_path='save/')\n",
    "\n",
    "            gain_val_performance[str(i)] = gain.evaluate(wide_window.val)\n",
    "            gain_performance[str(i)] = gain.evaluate(wide_window.test, verbose=0)\n",
    "\n",
    "            #print('file proc in main')\n",
    "            if __GAIN_TRAINING__ == True:\n",
    "                #dir = 'save/'+folder[i]\n",
    "                if not os.path.exists('save/' + folder[idx]):\n",
    "                    os.makedirs('save/'+folder[idx])\n",
    "                for file in loadfiles:\n",
    "                    shutil.copyfile('save/' + file, 'save/' + folder[idx] + file)\n",
    "\n",
    "            #print('create_dataset_with_gain in main')\n",
    "            #ori, gan = create_dataset_with_gain(gain=gain, window=wide_window, df=df)\n",
    "            ori, gan = create_dataset_with_gain(gain=gain, shape=(gain_in_setps, df_all.shape[1]), df=df)\n",
    "\n",
    "        else:\n",
    "            gan = create_dataset_interpol(window=gain_in_setps, df=df)\n",
    "    else:\n",
    "        gan = create_dataset_interpol(window=gain_in_setps, df=df)\n",
    "\n",
    "    if i == 0 :\n",
    "#        if i < length -1:\n",
    "#            gan = gan[:,:-4]  #맨마지막전까지 사인코사인삭제\n",
    "#            print(gan.shape)\n",
    "        real_df_all = pd.DataFrame(gan)\n",
    "    else:\n",
    "#        if i < length -1:\n",
    "#            gan = gan[:,:-4]  #맨마지막전까지 사인코사인삭제\n",
    "#            print(gan.shape)\n",
    "        real_df_all = pd.concat([real_df_all, pd.DataFrame(gan)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "australian-carter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35064, 530)\n"
     ]
    }
   ],
   "source": [
    "print(real_df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wooden-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df, test_df2 = dataset_slice(real_df_all, 0.8, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lined-county",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------prediction\n",
      "-------------------prediction\n",
      "-------------------prediction\n",
      "real_df_all.type :  <class 'pandas.core.frame.DataFrame'>\n",
      "train_df.type :  <class 'pandas.core.frame.DataFrame'>\n",
      "train_df.shape :  (28051, 530) val_df.shape :  (3506, 530) test_df.shape: (3507, 530)\n"
     ]
    }
   ],
   "source": [
    "print('-------------------prediction')\n",
    "print('-------------------prediction')\n",
    "print('-------------------prediction')\n",
    "\n",
    "print('real_df_all.type : ', type(real_df_all))\n",
    "print('train_df.type : ', type(train_df))\n",
    "print('train_df.shape : ', train_df.shape, 'val_df.shape : ', val_df.shape, 'test_df.shape:' ,test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "neither-bench",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_columns_indices:\n",
      "{'tmpr_value': 0, 'ph_value': 1, 'do_value': 2, 'ec_value': 3, 'toc_value': 4, '총질소_값': 5, '총인_값': 6, '클로로필-a_값': 7, 'Day sin': 8, 'Day cos': 9, 'Year sin': 10, 'Year cos': 11}\n",
      "target columns :  do\n",
      "target_col_idx :  2\n",
      "out_num_features :  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_columns_indices = {name: i for i, name in enumerate(dfff[0])}\n",
    "\n",
    "print(\"label_columns_indices:\")\n",
    "print(label_columns_indices)\n",
    "\n",
    "\n",
    "target_dic = {\"do\":\"do_value\", \"toc\":\"toc_value\", \"tn\":\"총질소_값\", \"tp\":\"총인_값\", \"chl-a\":\"클로로필-a_값\"}\n",
    "\n",
    "print('target columns : ', rnn_target_column)\n",
    "num_features = dfff[0].shape[1]\n",
    "\n",
    "target_col_idx = label_columns_indices[target_dic[rnn_target_column]]\n",
    "out_features = [target_col_idx]\n",
    "out_num_features = len(out_features)\n",
    "\n",
    "print(\"target_col_idx : \", target_col_idx)\n",
    "print('out_num_features : ', out_num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prescribed-slovak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model path :  save/han/models/do/\n"
     ]
    }
   ],
   "source": [
    "val_nse = {}\n",
    "val_pbias = {}\n",
    "\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset_water\n",
    "multi_window = WindowGenerator(\n",
    "    input_width=rnn_in_setps,label_width=rnn_out_steps, shift=rnn_out_steps,out_features=out_features,\n",
    "    out_num_features=out_num_features,label_columns=dfff[0].columns, batch_size=rnn_batch_size,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df, test_df2=test_df2)\n",
    "\n",
    "if __RNN_TRAINING__:\n",
    "    if not os.path.exists('save/' + watershed):\n",
    "        os.makedirs('save/' + watershed)\n",
    "\n",
    "\n",
    "idx = [2, 4, 5, 6, 7]\n",
    "pa = [\"do/\", \"toc/\", \"nitrogen/\", \"phosphorus/\", \"chlorophyll-a/\"]\n",
    "\n",
    "indices = {name: i for i, name in enumerate(idx)}\n",
    "\n",
    "model_path = \"save/\" + watershed + \"models/\" + pa[indices[target_col_idx]]\n",
    "print(\"save model path : \", model_path)\n",
    "\n",
    "val_nse = {}\n",
    "val_pbias = {}\n",
    "\n",
    " # +\"gru.ckpt\" -- path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-apollo",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compliant-development",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7669 - mean_absolute_error: 0.7308 - val_loss: 0.4214 - val_mean_absolute_error: 0.5145\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.5409 - mean_absolute_error: 0.5984 - val_loss: 0.2519 - val_mean_absolute_error: 0.3768\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4236 - mean_absolute_error: 0.5268 - val_loss: 0.1586 - val_mean_absolute_error: 0.3023\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.2915 - mean_absolute_error: 0.4218 - val_loss: 0.1844 - val_mean_absolute_error: 0.3161\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2065 - mean_absolute_error: 0.3518 - val_loss: 0.1055 - val_mean_absolute_error: 0.2347\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.1912 - mean_absolute_error: 0.3414 - val_loss: 0.0797 - val_mean_absolute_error: 0.2060\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.1429 - mean_absolute_error: 0.2951 - val_loss: 0.0483 - val_mean_absolute_error: 0.1741\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 0.1518 - mean_absolute_error: 0.3073 - val_loss: 0.0611 - val_mean_absolute_error: 0.1938\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.1614 - mean_absolute_error: 0.3067 - val_loss: 0.0701 - val_mean_absolute_error: 0.2074\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 0.1675 - mean_absolute_error: 0.3126 - val_loss: 0.0599 - val_mean_absolute_error: 0.1997\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.1481 - mean_absolute_error: 0.2993 - val_loss: 0.0609 - val_mean_absolute_error: 0.1941\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2204 - mean_absolute_error: 0.3621 - val_loss: 0.0625 - val_mean_absolute_error: 0.2075\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.1766 - mean_absolute_error: 0.3251 - val_loss: 0.0785 - val_mean_absolute_error: 0.2142\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.1602 - mean_absolute_error: 0.3102 - val_loss: 0.0730 - val_mean_absolute_error: 0.2121\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.1321 - mean_absolute_error: 0.2710 - val_loss: 0.0804 - val_mean_absolute_error: 0.2258\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1394 - mean_absolute_error: 0.3048 - val_loss: 0.0851 - val_mean_absolute_error: 0.2367\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 0.1263 - mean_absolute_error: 0.2873 - val_loss: 0.1036 - val_mean_absolute_error: 0.2643\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1319 - mean_absolute_error: 0.2865 - val_loss: 0.1138 - val_mean_absolute_error: 0.2781\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.1153 - mean_absolute_error: 0.2681 - val_loss: 0.1670 - val_mean_absolute_error: 0.3427\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.1115 - mean_absolute_error: 0.2645 - val_loss: 0.1771 - val_mean_absolute_error: 0.3565\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.1199 - mean_absolute_error: 0.2684 - val_loss: 0.1917 - val_mean_absolute_error: 0.3693\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0984 - mean_absolute_error: 0.2426 - val_loss: 0.2033 - val_mean_absolute_error: 0.3845\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1012 - mean_absolute_error: 0.2378 - val_loss: 0.2204 - val_mean_absolute_error: 0.4037\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.1046 - mean_absolute_error: 0.2450 - val_loss: 0.2303 - val_mean_absolute_error: 0.4010\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0792 - mean_absolute_error: 0.2112 - val_loss: 0.2151 - val_mean_absolute_error: 0.3817\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1122 - mean_absolute_error: 0.2429 - val_loss: 0.1548 - val_mean_absolute_error: 0.3310\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0946 - mean_absolute_error: 0.2238 - val_loss: 0.1923 - val_mean_absolute_error: 0.3544\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 0.0985 - mean_absolute_error: 0.2365 - val_loss: 0.1124 - val_mean_absolute_error: 0.2719\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0898 - mean_absolute_error: 0.2203 - val_loss: 0.1725 - val_mean_absolute_error: 0.3218\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.1110 - mean_absolute_error: 0.2489 - val_loss: 0.1456 - val_mean_absolute_error: 0.2764\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0970 - mean_absolute_error: 0.2252 - val_loss: 0.1140 - val_mean_absolute_error: 0.2490\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0820 - mean_absolute_error: 0.2164 - val_loss: 0.1012 - val_mean_absolute_error: 0.2411\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1067 - mean_absolute_error: 0.2458 - val_loss: 0.0914 - val_mean_absolute_error: 0.2271\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0936 - mean_absolute_error: 0.2321 - val_loss: 0.0842 - val_mean_absolute_error: 0.2161\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0803 - mean_absolute_error: 0.2225 - val_loss: 0.0630 - val_mean_absolute_error: 0.1942\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.0855 - mean_absolute_error: 0.2203 - val_loss: 0.0855 - val_mean_absolute_error: 0.2163\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 0.0794 - mean_absolute_error: 0.2170 - val_loss: 0.0661 - val_mean_absolute_error: 0.2050\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0770 - mean_absolute_error: 0.2141 - val_loss: 0.0868 - val_mean_absolute_error: 0.2190\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0957 - mean_absolute_error: 0.2319 - val_loss: 0.0783 - val_mean_absolute_error: 0.2061\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0832 - mean_absolute_error: 0.2277 - val_loss: 0.0877 - val_mean_absolute_error: 0.2224\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.0670 - mean_absolute_error: 0.1951 - val_loss: 0.0707 - val_mean_absolute_error: 0.2051\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.0755 - mean_absolute_error: 0.2118 - val_loss: 0.0837 - val_mean_absolute_error: 0.2170\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0868 - mean_absolute_error: 0.2229 - val_loss: 0.0759 - val_mean_absolute_error: 0.2123\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0842 - mean_absolute_error: 0.2178 - val_loss: 0.1022 - val_mean_absolute_error: 0.2456\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0705 - mean_absolute_error: 0.2023 - val_loss: 0.1014 - val_mean_absolute_error: 0.2509\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0977 - mean_absolute_error: 0.2350 - val_loss: 0.0880 - val_mean_absolute_error: 0.2278\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0749 - mean_absolute_error: 0.2053 - val_loss: 0.1028 - val_mean_absolute_error: 0.2482\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0670 - mean_absolute_error: 0.1977 - val_loss: 0.1042 - val_mean_absolute_error: 0.2519\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.1132 - mean_absolute_error: 0.2461 - val_loss: 0.1292 - val_mean_absolute_error: 0.2860\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0696 - mean_absolute_error: 0.2002 - val_loss: 0.1171 - val_mean_absolute_error: 0.2673\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 935ms/step - loss: 0.0592 - mean_absolute_error: 0.1872 - val_loss: 0.1040 - val_mean_absolute_error: 0.2583\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0659 - mean_absolute_error: 0.1979 - val_loss: 0.1353 - val_mean_absolute_error: 0.2935\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0864 - mean_absolute_error: 0.2239 - val_loss: 0.0895 - val_mean_absolute_error: 0.2390\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0845 - mean_absolute_error: 0.2150 - val_loss: 0.1401 - val_mean_absolute_error: 0.3053\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0702 - mean_absolute_error: 0.1955 - val_loss: 0.1373 - val_mean_absolute_error: 0.2903\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 0.0777 - mean_absolute_error: 0.2154 - val_loss: 0.1339 - val_mean_absolute_error: 0.2863\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0674 - mean_absolute_error: 0.1971 - val_loss: 0.1334 - val_mean_absolute_error: 0.2964\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0701 - mean_absolute_error: 0.1993 - val_loss: 0.1178 - val_mean_absolute_error: 0.2744\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0792 - mean_absolute_error: 0.2063 - val_loss: 0.1048 - val_mean_absolute_error: 0.2519\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0776 - mean_absolute_error: 0.2094 - val_loss: 0.1010 - val_mean_absolute_error: 0.2460\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0747 - mean_absolute_error: 0.1980 - val_loss: 0.1268 - val_mean_absolute_error: 0.2835\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0712 - mean_absolute_error: 0.2042 - val_loss: 0.0971 - val_mean_absolute_error: 0.2495\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0750 - mean_absolute_error: 0.2136 - val_loss: 0.1202 - val_mean_absolute_error: 0.2731\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0809 - mean_absolute_error: 0.2076 - val_loss: 0.1103 - val_mean_absolute_error: 0.2608\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0798 - mean_absolute_error: 0.2055 - val_loss: 0.1109 - val_mean_absolute_error: 0.2596\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0803 - mean_absolute_error: 0.2165 - val_loss: 0.1046 - val_mean_absolute_error: 0.2597\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0587 - mean_absolute_error: 0.1873 - val_loss: 0.0941 - val_mean_absolute_error: 0.2392\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0672 - mean_absolute_error: 0.1968 - val_loss: 0.0985 - val_mean_absolute_error: 0.2458\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0723 - mean_absolute_error: 0.2089 - val_loss: 0.1150 - val_mean_absolute_error: 0.2697\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0741 - mean_absolute_error: 0.2085 - val_loss: 0.1197 - val_mean_absolute_error: 0.2770\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0696 - mean_absolute_error: 0.2021 - val_loss: 0.1100 - val_mean_absolute_error: 0.2653\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0597 - mean_absolute_error: 0.1927 - val_loss: 0.1091 - val_mean_absolute_error: 0.2595\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0786 - mean_absolute_error: 0.2189 - val_loss: 0.1351 - val_mean_absolute_error: 0.2961\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0575 - mean_absolute_error: 0.1799 - val_loss: 0.1483 - val_mean_absolute_error: 0.3082\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0649 - mean_absolute_error: 0.1940 - val_loss: 0.1251 - val_mean_absolute_error: 0.2852\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0592 - mean_absolute_error: 0.1843 - val_loss: 0.1244 - val_mean_absolute_error: 0.2837\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.0610 - mean_absolute_error: 0.1843 - val_loss: 0.1491 - val_mean_absolute_error: 0.3197\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0700 - mean_absolute_error: 0.2024 - val_loss: 0.1169 - val_mean_absolute_error: 0.2769\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0642 - mean_absolute_error: 0.1913 - val_loss: 0.1505 - val_mean_absolute_error: 0.3251\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0578 - mean_absolute_error: 0.1857 - val_loss: 0.1611 - val_mean_absolute_error: 0.3244\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0601 - mean_absolute_error: 0.1812 - val_loss: 0.1426 - val_mean_absolute_error: 0.3106\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0636 - mean_absolute_error: 0.1933 - val_loss: 0.1553 - val_mean_absolute_error: 0.3284\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0687 - mean_absolute_error: 0.1983 - val_loss: 0.1241 - val_mean_absolute_error: 0.2919\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0711 - mean_absolute_error: 0.2062 - val_loss: 0.1410 - val_mean_absolute_error: 0.3011\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0705 - mean_absolute_error: 0.2037 - val_loss: 0.1049 - val_mean_absolute_error: 0.2581\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0783 - mean_absolute_error: 0.2065 - val_loss: 0.1242 - val_mean_absolute_error: 0.2881\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0705 - mean_absolute_error: 0.1952 - val_loss: 0.1246 - val_mean_absolute_error: 0.2856\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0666 - mean_absolute_error: 0.1900 - val_loss: 0.1260 - val_mean_absolute_error: 0.2861\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0711 - mean_absolute_error: 0.2023 - val_loss: 0.1213 - val_mean_absolute_error: 0.2803\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0620 - mean_absolute_error: 0.1908 - val_loss: 0.1228 - val_mean_absolute_error: 0.2761\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0543 - mean_absolute_error: 0.1764 - val_loss: 0.1180 - val_mean_absolute_error: 0.2791\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0628 - mean_absolute_error: 0.1878 - val_loss: 0.1094 - val_mean_absolute_error: 0.2606\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0580 - mean_absolute_error: 0.1817 - val_loss: 0.0986 - val_mean_absolute_error: 0.2494\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0691 - mean_absolute_error: 0.2022 - val_loss: 0.1234 - val_mean_absolute_error: 0.2796\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.0673 - mean_absolute_error: 0.1942 - val_loss: 0.1309 - val_mean_absolute_error: 0.2905\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0567 - mean_absolute_error: 0.1824 - val_loss: 0.1109 - val_mean_absolute_error: 0.2690\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0745 - mean_absolute_error: 0.2051 - val_loss: 0.1086 - val_mean_absolute_error: 0.2611\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0640 - mean_absolute_error: 0.1957 - val_loss: 0.1222 - val_mean_absolute_error: 0.2770\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0682 - mean_absolute_error: 0.2038 - val_loss: 0.1273 - val_mean_absolute_error: 0.2884\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 0.0588 - mean_absolute_error: 0.1851 - val_loss: 0.1342 - val_mean_absolute_error: 0.2973\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0496 - mean_absolute_error: 0.1730 - val_loss: 0.1111 - val_mean_absolute_error: 0.2634\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 1s 978ms/step - loss: 0.0622 - mean_absolute_error: 0.1867 - val_loss: 0.1348 - val_mean_absolute_error: 0.3045\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0724 - mean_absolute_error: 0.2050 - val_loss: 0.1175 - val_mean_absolute_error: 0.2766\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0612 - mean_absolute_error: 0.1880 - val_loss: 0.1292 - val_mean_absolute_error: 0.3005\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0503 - mean_absolute_error: 0.1766 - val_loss: 0.1472 - val_mean_absolute_error: 0.3130\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0532 - mean_absolute_error: 0.1787 - val_loss: 0.1373 - val_mean_absolute_error: 0.3045\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0971 - mean_absolute_error: 0.2272 - val_loss: 0.1640 - val_mean_absolute_error: 0.3344\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0677 - mean_absolute_error: 0.1925 - val_loss: 0.1291 - val_mean_absolute_error: 0.2981\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0703 - mean_absolute_error: 0.1902 - val_loss: 0.1522 - val_mean_absolute_error: 0.3233\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0689 - mean_absolute_error: 0.1972 - val_loss: 0.1123 - val_mean_absolute_error: 0.2672\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0627 - mean_absolute_error: 0.1898 - val_loss: 0.1242 - val_mean_absolute_error: 0.2904\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.0558 - mean_absolute_error: 0.1792 - val_loss: 0.1313 - val_mean_absolute_error: 0.2951\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0635 - mean_absolute_error: 0.1882 - val_loss: 0.1353 - val_mean_absolute_error: 0.2997\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0549 - mean_absolute_error: 0.1794 - val_loss: 0.1390 - val_mean_absolute_error: 0.3014\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0573 - mean_absolute_error: 0.1811 - val_loss: 0.1193 - val_mean_absolute_error: 0.2731\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0602 - mean_absolute_error: 0.1784 - val_loss: 0.1288 - val_mean_absolute_error: 0.2923\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0704 - mean_absolute_error: 0.1974 - val_loss: 0.1090 - val_mean_absolute_error: 0.2643\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0564 - mean_absolute_error: 0.1867 - val_loss: 0.1148 - val_mean_absolute_error: 0.2707\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0560 - mean_absolute_error: 0.1783 - val_loss: 0.1276 - val_mean_absolute_error: 0.2922\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.0602 - mean_absolute_error: 0.1878 - val_loss: 0.1573 - val_mean_absolute_error: 0.3232\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0743 - mean_absolute_error: 0.2010 - val_loss: 0.1400 - val_mean_absolute_error: 0.3083\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0597 - mean_absolute_error: 0.1863 - val_loss: 0.1456 - val_mean_absolute_error: 0.3109\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0544 - mean_absolute_error: 0.1758 - val_loss: 0.1678 - val_mean_absolute_error: 0.3389\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0556 - mean_absolute_error: 0.1751 - val_loss: 0.1672 - val_mean_absolute_error: 0.3407\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0527 - mean_absolute_error: 0.1701 - val_loss: 0.1734 - val_mean_absolute_error: 0.3443\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0574 - mean_absolute_error: 0.1842 - val_loss: 0.1351 - val_mean_absolute_error: 0.2971\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0556 - mean_absolute_error: 0.1777 - val_loss: 0.1509 - val_mean_absolute_error: 0.3238\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0590 - mean_absolute_error: 0.1796 - val_loss: 0.1320 - val_mean_absolute_error: 0.2940\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 0.0594 - mean_absolute_error: 0.1810 - val_loss: 0.1241 - val_mean_absolute_error: 0.2940\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0603 - mean_absolute_error: 0.1885 - val_loss: 0.1461 - val_mean_absolute_error: 0.3118\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0659 - mean_absolute_error: 0.1917 - val_loss: 0.1139 - val_mean_absolute_error: 0.2709\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0556 - mean_absolute_error: 0.1793 - val_loss: 0.1306 - val_mean_absolute_error: 0.2919\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0584 - mean_absolute_error: 0.1852 - val_loss: 0.1040 - val_mean_absolute_error: 0.2611\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0731 - mean_absolute_error: 0.2063 - val_loss: 0.1155 - val_mean_absolute_error: 0.2719\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0525 - mean_absolute_error: 0.1724 - val_loss: 0.1109 - val_mean_absolute_error: 0.2604\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0645 - mean_absolute_error: 0.1902 - val_loss: 0.1158 - val_mean_absolute_error: 0.2765\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0633 - mean_absolute_error: 0.1847 - val_loss: 0.1332 - val_mean_absolute_error: 0.2941\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0504 - mean_absolute_error: 0.1757 - val_loss: 0.1399 - val_mean_absolute_error: 0.3043\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0677 - mean_absolute_error: 0.1979 - val_loss: 0.1426 - val_mean_absolute_error: 0.3066\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0534 - mean_absolute_error: 0.1757 - val_loss: 0.1291 - val_mean_absolute_error: 0.2871\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0615 - mean_absolute_error: 0.1832 - val_loss: 0.1481 - val_mean_absolute_error: 0.3145\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0570 - mean_absolute_error: 0.1795 - val_loss: 0.1332 - val_mean_absolute_error: 0.3004\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0566 - mean_absolute_error: 0.1847 - val_loss: 0.1208 - val_mean_absolute_error: 0.2783\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0695 - mean_absolute_error: 0.1927 - val_loss: 0.1289 - val_mean_absolute_error: 0.2921\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0638 - mean_absolute_error: 0.1877 - val_loss: 0.1437 - val_mean_absolute_error: 0.3079\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0617 - mean_absolute_error: 0.1854 - val_loss: 0.1291 - val_mean_absolute_error: 0.2946\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0602 - mean_absolute_error: 0.1885 - val_loss: 0.1296 - val_mean_absolute_error: 0.2888\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0663 - mean_absolute_error: 0.1866 - val_loss: 0.1347 - val_mean_absolute_error: 0.2964\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0532 - mean_absolute_error: 0.1778 - val_loss: 0.1542 - val_mean_absolute_error: 0.3230\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0540 - mean_absolute_error: 0.1768 - val_loss: 0.1603 - val_mean_absolute_error: 0.3249\n"
     ]
    }
   ],
   "source": [
    "multi_linear_model = model_multi_linear(\n",
    "    window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "    #training_flag=__RNN_TRAINING__, checkpoint_path=\"save/\"+watershed+\"models/multi_linear.ckpt\")\n",
    "    training_flag=__RNN_TRAINING__, checkpoint_path=model_path+\"multi_linear.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "coordinated-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8191 - mean_absolute_error: 0.7431 - val_loss: 0.4583 - val_mean_absolute_error: 0.5038\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.7564 - mean_absolute_error: 0.7259 - val_loss: 0.5156 - val_mean_absolute_error: 0.5480\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 0.7440 - mean_absolute_error: 0.7174 - val_loss: 0.3902 - val_mean_absolute_error: 0.4832\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.6300 - mean_absolute_error: 0.6536 - val_loss: 0.3534 - val_mean_absolute_error: 0.4556\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.5424 - mean_absolute_error: 0.5833 - val_loss: 0.2688 - val_mean_absolute_error: 0.3739\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.3204 - mean_absolute_error: 0.4367 - val_loss: 0.1894 - val_mean_absolute_error: 0.2849\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2176 - mean_absolute_error: 0.3666 - val_loss: 0.1646 - val_mean_absolute_error: 0.2800\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2246 - mean_absolute_error: 0.3603 - val_loss: 0.1057 - val_mean_absolute_error: 0.2583\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2074 - mean_absolute_error: 0.3520 - val_loss: 0.1220 - val_mean_absolute_error: 0.2884\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1934 - mean_absolute_error: 0.3480 - val_loss: 0.1452 - val_mean_absolute_error: 0.3132\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1678 - mean_absolute_error: 0.3307 - val_loss: 0.1511 - val_mean_absolute_error: 0.3302\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.1994 - mean_absolute_error: 0.3653 - val_loss: 0.1520 - val_mean_absolute_error: 0.3340\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2037 - mean_absolute_error: 0.3644 - val_loss: 0.1342 - val_mean_absolute_error: 0.3095\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1882 - mean_absolute_error: 0.3645 - val_loss: 0.1200 - val_mean_absolute_error: 0.2946\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.1709 - mean_absolute_error: 0.3302 - val_loss: 0.0918 - val_mean_absolute_error: 0.2481\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.1718 - mean_absolute_error: 0.3248 - val_loss: 0.0819 - val_mean_absolute_error: 0.2261\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1680 - mean_absolute_error: 0.3334 - val_loss: 0.0756 - val_mean_absolute_error: 0.2154\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1315 - mean_absolute_error: 0.2743 - val_loss: 0.0983 - val_mean_absolute_error: 0.2387\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 0.1207 - mean_absolute_error: 0.2685 - val_loss: 0.0836 - val_mean_absolute_error: 0.2218\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1242 - mean_absolute_error: 0.2676 - val_loss: 0.1129 - val_mean_absolute_error: 0.2534\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.1229 - mean_absolute_error: 0.2712 - val_loss: 0.1153 - val_mean_absolute_error: 0.2572\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1114 - mean_absolute_error: 0.2578 - val_loss: 0.1213 - val_mean_absolute_error: 0.2572\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1171 - mean_absolute_error: 0.2577 - val_loss: 0.1208 - val_mean_absolute_error: 0.2553\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.1191 - mean_absolute_error: 0.2489 - val_loss: 0.1548 - val_mean_absolute_error: 0.2941\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.1203 - mean_absolute_error: 0.2647 - val_loss: 0.1113 - val_mean_absolute_error: 0.2540\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1040 - mean_absolute_error: 0.2482 - val_loss: 0.1252 - val_mean_absolute_error: 0.2615\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.1197 - mean_absolute_error: 0.2535 - val_loss: 0.1262 - val_mean_absolute_error: 0.2643\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1246 - mean_absolute_error: 0.2658 - val_loss: 0.1137 - val_mean_absolute_error: 0.2598\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1199 - mean_absolute_error: 0.2510 - val_loss: 0.1058 - val_mean_absolute_error: 0.2603\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0988 - mean_absolute_error: 0.2344 - val_loss: 0.1112 - val_mean_absolute_error: 0.2622\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0964 - mean_absolute_error: 0.2290 - val_loss: 0.0977 - val_mean_absolute_error: 0.2446\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0995 - mean_absolute_error: 0.2333 - val_loss: 0.1001 - val_mean_absolute_error: 0.2476\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 1s 943ms/step - loss: 0.1131 - mean_absolute_error: 0.2624 - val_loss: 0.0997 - val_mean_absolute_error: 0.2561\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.0960 - mean_absolute_error: 0.2316 - val_loss: 0.0858 - val_mean_absolute_error: 0.2338\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.1035 - mean_absolute_error: 0.2464 - val_loss: 0.1171 - val_mean_absolute_error: 0.2788\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0877 - mean_absolute_error: 0.2280 - val_loss: 0.1164 - val_mean_absolute_error: 0.2767\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0850 - mean_absolute_error: 0.2223 - val_loss: 0.1003 - val_mean_absolute_error: 0.2558\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.0841 - mean_absolute_error: 0.2174 - val_loss: 0.1046 - val_mean_absolute_error: 0.2629\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 0.0960 - mean_absolute_error: 0.2267 - val_loss: 0.1191 - val_mean_absolute_error: 0.2760\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0734 - mean_absolute_error: 0.2041 - val_loss: 0.1260 - val_mean_absolute_error: 0.2920\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0817 - mean_absolute_error: 0.2061 - val_loss: 0.1000 - val_mean_absolute_error: 0.2490\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0905 - mean_absolute_error: 0.2179 - val_loss: 0.1243 - val_mean_absolute_error: 0.2874\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.0778 - mean_absolute_error: 0.2086 - val_loss: 0.1289 - val_mean_absolute_error: 0.2861\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0823 - mean_absolute_error: 0.2101 - val_loss: 0.0973 - val_mean_absolute_error: 0.2463\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0715 - mean_absolute_error: 0.2036 - val_loss: 0.1132 - val_mean_absolute_error: 0.2711\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0825 - mean_absolute_error: 0.2112 - val_loss: 0.1181 - val_mean_absolute_error: 0.2757\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.0921 - mean_absolute_error: 0.2210 - val_loss: 0.0948 - val_mean_absolute_error: 0.2413\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0699 - mean_absolute_error: 0.1939 - val_loss: 0.1109 - val_mean_absolute_error: 0.2662\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0692 - mean_absolute_error: 0.1941 - val_loss: 0.1073 - val_mean_absolute_error: 0.2546\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0694 - mean_absolute_error: 0.1954 - val_loss: 0.0892 - val_mean_absolute_error: 0.2334\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0687 - mean_absolute_error: 0.1931 - val_loss: 0.1124 - val_mean_absolute_error: 0.2681\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0785 - mean_absolute_error: 0.2020 - val_loss: 0.1205 - val_mean_absolute_error: 0.2776\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 0.0736 - mean_absolute_error: 0.2042 - val_loss: 0.1185 - val_mean_absolute_error: 0.2728\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0584 - mean_absolute_error: 0.1783 - val_loss: 0.1230 - val_mean_absolute_error: 0.2929\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0673 - mean_absolute_error: 0.1850 - val_loss: 0.1266 - val_mean_absolute_error: 0.2889\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0675 - mean_absolute_error: 0.1921 - val_loss: 0.1247 - val_mean_absolute_error: 0.2856\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0648 - mean_absolute_error: 0.1872 - val_loss: 0.1401 - val_mean_absolute_error: 0.3058\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.0677 - mean_absolute_error: 0.1926 - val_loss: 0.1199 - val_mean_absolute_error: 0.2851\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.0537 - mean_absolute_error: 0.1722 - val_loss: 0.1182 - val_mean_absolute_error: 0.2823\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0757 - mean_absolute_error: 0.2030 - val_loss: 0.1521 - val_mean_absolute_error: 0.3200\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.0610 - mean_absolute_error: 0.1765 - val_loss: 0.1405 - val_mean_absolute_error: 0.3126\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0638 - mean_absolute_error: 0.1871 - val_loss: 0.1430 - val_mean_absolute_error: 0.3098\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0632 - mean_absolute_error: 0.1877 - val_loss: 0.1325 - val_mean_absolute_error: 0.3000\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0629 - mean_absolute_error: 0.1858 - val_loss: 0.1379 - val_mean_absolute_error: 0.3089\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 0.0660 - mean_absolute_error: 0.1821 - val_loss: 0.1550 - val_mean_absolute_error: 0.3291\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 0.0670 - mean_absolute_error: 0.1863 - val_loss: 0.1146 - val_mean_absolute_error: 0.2726\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0761 - mean_absolute_error: 0.1978 - val_loss: 0.1346 - val_mean_absolute_error: 0.3027\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.0703 - mean_absolute_error: 0.1949 - val_loss: 0.1322 - val_mean_absolute_error: 0.2958\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 0.0469 - mean_absolute_error: 0.1626 - val_loss: 0.1187 - val_mean_absolute_error: 0.2760\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0648 - mean_absolute_error: 0.1830 - val_loss: 0.1195 - val_mean_absolute_error: 0.2810\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0528 - mean_absolute_error: 0.1674 - val_loss: 0.1341 - val_mean_absolute_error: 0.3076\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.0528 - mean_absolute_error: 0.1697 - val_loss: 0.1211 - val_mean_absolute_error: 0.2821\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 0.0514 - mean_absolute_error: 0.1710 - val_loss: 0.1211 - val_mean_absolute_error: 0.2848\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.0566 - mean_absolute_error: 0.1778 - val_loss: 0.1217 - val_mean_absolute_error: 0.2838\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 0.0601 - mean_absolute_error: 0.1753 - val_loss: 0.1252 - val_mean_absolute_error: 0.2896\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.0674 - mean_absolute_error: 0.1842 - val_loss: 0.1353 - val_mean_absolute_error: 0.3090\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0549 - mean_absolute_error: 0.1720 - val_loss: 0.1515 - val_mean_absolute_error: 0.3238\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0622 - mean_absolute_error: 0.1846 - val_loss: 0.1485 - val_mean_absolute_error: 0.3203\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0615 - mean_absolute_error: 0.1779 - val_loss: 0.1448 - val_mean_absolute_error: 0.3214\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0528 - mean_absolute_error: 0.1689 - val_loss: 0.1380 - val_mean_absolute_error: 0.3129\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0495 - mean_absolute_error: 0.1671 - val_loss: 0.1414 - val_mean_absolute_error: 0.3056\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0487 - mean_absolute_error: 0.1607 - val_loss: 0.1196 - val_mean_absolute_error: 0.2809\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 0.0690 - mean_absolute_error: 0.1895 - val_loss: 0.1346 - val_mean_absolute_error: 0.3004\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 0.0407 - mean_absolute_error: 0.1589 - val_loss: 0.1263 - val_mean_absolute_error: 0.2904\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 0.0579 - mean_absolute_error: 0.1756 - val_loss: 0.1360 - val_mean_absolute_error: 0.2967\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0598 - mean_absolute_error: 0.1755 - val_loss: 0.1433 - val_mean_absolute_error: 0.3129\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 0.0515 - mean_absolute_error: 0.1661 - val_loss: 0.1535 - val_mean_absolute_error: 0.3182\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0492 - mean_absolute_error: 0.1661 - val_loss: 0.1196 - val_mean_absolute_error: 0.2787\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0611 - mean_absolute_error: 0.1758 - val_loss: 0.1386 - val_mean_absolute_error: 0.3100\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0554 - mean_absolute_error: 0.1726 - val_loss: 0.1451 - val_mean_absolute_error: 0.3100\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0519 - mean_absolute_error: 0.1657 - val_loss: 0.1129 - val_mean_absolute_error: 0.2700\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0522 - mean_absolute_error: 0.1648 - val_loss: 0.1346 - val_mean_absolute_error: 0.2995\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0480 - mean_absolute_error: 0.1546 - val_loss: 0.1314 - val_mean_absolute_error: 0.2962\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0527 - mean_absolute_error: 0.1680 - val_loss: 0.1237 - val_mean_absolute_error: 0.2821\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0473 - mean_absolute_error: 0.1611 - val_loss: 0.1270 - val_mean_absolute_error: 0.2930\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0500 - mean_absolute_error: 0.1616 - val_loss: 0.1386 - val_mean_absolute_error: 0.3165\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 1s 996ms/step - loss: 0.0458 - mean_absolute_error: 0.1565 - val_loss: 0.1177 - val_mean_absolute_error: 0.2824\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0520 - mean_absolute_error: 0.1673 - val_loss: 0.1361 - val_mean_absolute_error: 0.2986\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0417 - mean_absolute_error: 0.1559 - val_loss: 0.1291 - val_mean_absolute_error: 0.2938\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0479 - mean_absolute_error: 0.1618 - val_loss: 0.1187 - val_mean_absolute_error: 0.2754\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0567 - mean_absolute_error: 0.1674 - val_loss: 0.1192 - val_mean_absolute_error: 0.2854\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0559 - mean_absolute_error: 0.1636 - val_loss: 0.1391 - val_mean_absolute_error: 0.3065\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 1s 975ms/step - loss: 0.0468 - mean_absolute_error: 0.1629 - val_loss: 0.1354 - val_mean_absolute_error: 0.3029\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.0423 - mean_absolute_error: 0.1471 - val_loss: 0.1409 - val_mean_absolute_error: 0.3158\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.0481 - mean_absolute_error: 0.1585 - val_loss: 0.1189 - val_mean_absolute_error: 0.2871\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0493 - mean_absolute_error: 0.1610 - val_loss: 0.1377 - val_mean_absolute_error: 0.3027\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0473 - mean_absolute_error: 0.1532 - val_loss: 0.1176 - val_mean_absolute_error: 0.2796\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 0.0511 - mean_absolute_error: 0.1606 - val_loss: 0.1277 - val_mean_absolute_error: 0.2947\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0504 - mean_absolute_error: 0.1658 - val_loss: 0.1253 - val_mean_absolute_error: 0.2907\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0398 - mean_absolute_error: 0.1497 - val_loss: 0.1300 - val_mean_absolute_error: 0.2934\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0509 - mean_absolute_error: 0.1571 - val_loss: 0.1413 - val_mean_absolute_error: 0.3186\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0492 - mean_absolute_error: 0.1557 - val_loss: 0.1409 - val_mean_absolute_error: 0.3127\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0399 - mean_absolute_error: 0.1464 - val_loss: 0.1236 - val_mean_absolute_error: 0.2890\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0391 - mean_absolute_error: 0.1451 - val_loss: 0.1360 - val_mean_absolute_error: 0.3058\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.0376 - mean_absolute_error: 0.1471 - val_loss: 0.1432 - val_mean_absolute_error: 0.3135\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 1s 976ms/step - loss: 0.0505 - mean_absolute_error: 0.1615 - val_loss: 0.1173 - val_mean_absolute_error: 0.2807\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.0544 - mean_absolute_error: 0.1685 - val_loss: 0.1303 - val_mean_absolute_error: 0.2952\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.0411 - mean_absolute_error: 0.1493 - val_loss: 0.1257 - val_mean_absolute_error: 0.2932\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.0521 - mean_absolute_error: 0.1644 - val_loss: 0.1120 - val_mean_absolute_error: 0.2727\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0419 - mean_absolute_error: 0.1572 - val_loss: 0.1225 - val_mean_absolute_error: 0.2865\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 0.0414 - mean_absolute_error: 0.1540 - val_loss: 0.1327 - val_mean_absolute_error: 0.3126\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0542 - mean_absolute_error: 0.1702 - val_loss: 0.1229 - val_mean_absolute_error: 0.2950\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.0486 - mean_absolute_error: 0.1561 - val_loss: 0.1392 - val_mean_absolute_error: 0.3060\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0458 - mean_absolute_error: 0.1541 - val_loss: 0.1153 - val_mean_absolute_error: 0.2839\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0439 - mean_absolute_error: 0.1507 - val_loss: 0.1256 - val_mean_absolute_error: 0.2869\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0443 - mean_absolute_error: 0.1512 - val_loss: 0.1245 - val_mean_absolute_error: 0.3002\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0396 - mean_absolute_error: 0.1479 - val_loss: 0.1329 - val_mean_absolute_error: 0.3020\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0337 - mean_absolute_error: 0.1366 - val_loss: 0.1376 - val_mean_absolute_error: 0.3110\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0336 - mean_absolute_error: 0.1399 - val_loss: 0.1421 - val_mean_absolute_error: 0.3164\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.0373 - mean_absolute_error: 0.1485 - val_loss: 0.1249 - val_mean_absolute_error: 0.3039\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0426 - mean_absolute_error: 0.1518 - val_loss: 0.1464 - val_mean_absolute_error: 0.3177\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0402 - mean_absolute_error: 0.1457 - val_loss: 0.1216 - val_mean_absolute_error: 0.2898\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0355 - mean_absolute_error: 0.1413 - val_loss: 0.1311 - val_mean_absolute_error: 0.2970\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0507 - mean_absolute_error: 0.1639 - val_loss: 0.1405 - val_mean_absolute_error: 0.3131\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 0.0432 - mean_absolute_error: 0.1492 - val_loss: 0.1172 - val_mean_absolute_error: 0.2766\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0445 - mean_absolute_error: 0.1483 - val_loss: 0.1420 - val_mean_absolute_error: 0.3168\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0419 - mean_absolute_error: 0.1475 - val_loss: 0.1243 - val_mean_absolute_error: 0.2930\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 1s 976ms/step - loss: 0.0407 - mean_absolute_error: 0.1478 - val_loss: 0.1107 - val_mean_absolute_error: 0.2684\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0363 - mean_absolute_error: 0.1427 - val_loss: 0.1214 - val_mean_absolute_error: 0.2858\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0362 - mean_absolute_error: 0.1373 - val_loss: 0.1368 - val_mean_absolute_error: 0.3035\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 0.0397 - mean_absolute_error: 0.1451 - val_loss: 0.1168 - val_mean_absolute_error: 0.2795\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0309 - mean_absolute_error: 0.1317 - val_loss: 0.1213 - val_mean_absolute_error: 0.2839\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.0416 - mean_absolute_error: 0.1512 - val_loss: 0.1306 - val_mean_absolute_error: 0.2978\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0339 - mean_absolute_error: 0.1361 - val_loss: 0.1041 - val_mean_absolute_error: 0.2594\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.0355 - mean_absolute_error: 0.1368 - val_loss: 0.1176 - val_mean_absolute_error: 0.2806\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0337 - mean_absolute_error: 0.1324 - val_loss: 0.1233 - val_mean_absolute_error: 0.2922\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0351 - mean_absolute_error: 0.1371 - val_loss: 0.1073 - val_mean_absolute_error: 0.2758\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.0391 - mean_absolute_error: 0.1367 - val_loss: 0.1370 - val_mean_absolute_error: 0.3004\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0403 - mean_absolute_error: 0.1429 - val_loss: 0.1066 - val_mean_absolute_error: 0.2697\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0340 - mean_absolute_error: 0.1361 - val_loss: 0.1307 - val_mean_absolute_error: 0.2949\n"
     ]
    }
   ],
   "source": [
    "elman_model = model_elman(\n",
    "    window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "    training_flag=__RNN_TRAINING__, checkpoint_path=model_path+\"elman.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "existing-strengthening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7340 - mean_absolute_error: 0.7260 - val_loss: 0.5671 - val_mean_absolute_error: 0.5970\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.6243 - mean_absolute_error: 0.6551 - val_loss: 0.4628 - val_mean_absolute_error: 0.5194\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 1s 976ms/step - loss: 0.5301 - mean_absolute_error: 0.6035 - val_loss: 0.3767 - val_mean_absolute_error: 0.4719\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.5966 - mean_absolute_error: 0.6463 - val_loss: 0.2968 - val_mean_absolute_error: 0.4025\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.5874 - mean_absolute_error: 0.6065 - val_loss: 0.3323 - val_mean_absolute_error: 0.4188\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.3435 - mean_absolute_error: 0.4542 - val_loss: 0.1595 - val_mean_absolute_error: 0.2650\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 0.2105 - mean_absolute_error: 0.3508 - val_loss: 0.1721 - val_mean_absolute_error: 0.2799\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 0.1760 - mean_absolute_error: 0.3281 - val_loss: 0.1058 - val_mean_absolute_error: 0.2422\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 0.1604 - mean_absolute_error: 0.3093 - val_loss: 0.1326 - val_mean_absolute_error: 0.2948\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 1s 990ms/step - loss: 0.1760 - mean_absolute_error: 0.3310 - val_loss: 0.1389 - val_mean_absolute_error: 0.3214\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 1s 985ms/step - loss: 0.1642 - mean_absolute_error: 0.3238 - val_loss: 0.1404 - val_mean_absolute_error: 0.3231\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.1703 - mean_absolute_error: 0.3297 - val_loss: 0.1468 - val_mean_absolute_error: 0.3236\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.2094 - mean_absolute_error: 0.3757 - val_loss: 0.1572 - val_mean_absolute_error: 0.3390\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.1906 - mean_absolute_error: 0.3626 - val_loss: 0.1291 - val_mean_absolute_error: 0.3033\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.1795 - mean_absolute_error: 0.3440 - val_loss: 0.1253 - val_mean_absolute_error: 0.2962\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1579 - mean_absolute_error: 0.3156 - val_loss: 0.1079 - val_mean_absolute_error: 0.2716\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1375 - mean_absolute_error: 0.2981 - val_loss: 0.0840 - val_mean_absolute_error: 0.2289\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1410 - mean_absolute_error: 0.2903 - val_loss: 0.0873 - val_mean_absolute_error: 0.2331\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1524 - mean_absolute_error: 0.2961 - val_loss: 0.0889 - val_mean_absolute_error: 0.2341\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1308 - mean_absolute_error: 0.2735 - val_loss: 0.1024 - val_mean_absolute_error: 0.2452\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0989 - mean_absolute_error: 0.2443 - val_loss: 0.1013 - val_mean_absolute_error: 0.2481\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1207 - mean_absolute_error: 0.2602 - val_loss: 0.1250 - val_mean_absolute_error: 0.2691\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.1364 - mean_absolute_error: 0.2775 - val_loss: 0.1268 - val_mean_absolute_error: 0.2724\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1149 - mean_absolute_error: 0.2592 - val_loss: 0.1105 - val_mean_absolute_error: 0.2569\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.1045 - mean_absolute_error: 0.2395 - val_loss: 0.1065 - val_mean_absolute_error: 0.2508\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.1092 - mean_absolute_error: 0.2536 - val_loss: 0.1293 - val_mean_absolute_error: 0.2798\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.1069 - mean_absolute_error: 0.2366 - val_loss: 0.1069 - val_mean_absolute_error: 0.2532\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.1185 - mean_absolute_error: 0.2575 - val_loss: 0.1021 - val_mean_absolute_error: 0.2521\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0849 - mean_absolute_error: 0.2149 - val_loss: 0.0825 - val_mean_absolute_error: 0.2232\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0812 - mean_absolute_error: 0.2177 - val_loss: 0.1093 - val_mean_absolute_error: 0.2561\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0962 - mean_absolute_error: 0.2262 - val_loss: 0.0736 - val_mean_absolute_error: 0.2101\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0973 - mean_absolute_error: 0.2347 - val_loss: 0.0893 - val_mean_absolute_error: 0.2393\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0961 - mean_absolute_error: 0.2316 - val_loss: 0.0809 - val_mean_absolute_error: 0.2192\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1065 - mean_absolute_error: 0.2431 - val_loss: 0.0823 - val_mean_absolute_error: 0.2255\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1000 - mean_absolute_error: 0.2416 - val_loss: 0.0931 - val_mean_absolute_error: 0.2435\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0870 - mean_absolute_error: 0.2210 - val_loss: 0.0718 - val_mean_absolute_error: 0.2105\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.1140 - mean_absolute_error: 0.2488 - val_loss: 0.0719 - val_mean_absolute_error: 0.2122\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 1s 990ms/step - loss: 0.0925 - mean_absolute_error: 0.2314 - val_loss: 0.0931 - val_mean_absolute_error: 0.2410\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.0722 - mean_absolute_error: 0.2094 - val_loss: 0.0938 - val_mean_absolute_error: 0.2437\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0696 - mean_absolute_error: 0.1985 - val_loss: 0.1131 - val_mean_absolute_error: 0.2720\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0783 - mean_absolute_error: 0.2022 - val_loss: 0.1324 - val_mean_absolute_error: 0.2999\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0790 - mean_absolute_error: 0.2160 - val_loss: 0.1208 - val_mean_absolute_error: 0.2810\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 1s 978ms/step - loss: 0.0631 - mean_absolute_error: 0.1890 - val_loss: 0.1364 - val_mean_absolute_error: 0.3066\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 1s 981ms/step - loss: 0.0921 - mean_absolute_error: 0.2141 - val_loss: 0.1320 - val_mean_absolute_error: 0.2970\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 0.0790 - mean_absolute_error: 0.2109 - val_loss: 0.1368 - val_mean_absolute_error: 0.2995\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 0.0668 - mean_absolute_error: 0.1890 - val_loss: 0.1214 - val_mean_absolute_error: 0.2859\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 0.0710 - mean_absolute_error: 0.1963 - val_loss: 0.1345 - val_mean_absolute_error: 0.2926\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0687 - mean_absolute_error: 0.1946 - val_loss: 0.1029 - val_mean_absolute_error: 0.2448\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0535 - mean_absolute_error: 0.1760 - val_loss: 0.1026 - val_mean_absolute_error: 0.2526\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0736 - mean_absolute_error: 0.2005 - val_loss: 0.0991 - val_mean_absolute_error: 0.2463\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0598 - mean_absolute_error: 0.1801 - val_loss: 0.1096 - val_mean_absolute_error: 0.2589\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 1s 977ms/step - loss: 0.0663 - mean_absolute_error: 0.1915 - val_loss: 0.0939 - val_mean_absolute_error: 0.2368\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0618 - mean_absolute_error: 0.1836 - val_loss: 0.0935 - val_mean_absolute_error: 0.2357\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0778 - mean_absolute_error: 0.2047 - val_loss: 0.0932 - val_mean_absolute_error: 0.2363\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0704 - mean_absolute_error: 0.1898 - val_loss: 0.1127 - val_mean_absolute_error: 0.2592\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0613 - mean_absolute_error: 0.1842 - val_loss: 0.0832 - val_mean_absolute_error: 0.2208\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0678 - mean_absolute_error: 0.1902 - val_loss: 0.1168 - val_mean_absolute_error: 0.2711\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0658 - mean_absolute_error: 0.1834 - val_loss: 0.1031 - val_mean_absolute_error: 0.2483\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0728 - mean_absolute_error: 0.2007 - val_loss: 0.1115 - val_mean_absolute_error: 0.2650\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0589 - mean_absolute_error: 0.1774 - val_loss: 0.1379 - val_mean_absolute_error: 0.2981\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 0.0643 - mean_absolute_error: 0.1849 - val_loss: 0.1086 - val_mean_absolute_error: 0.2667\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0461 - mean_absolute_error: 0.1636 - val_loss: 0.1142 - val_mean_absolute_error: 0.2772\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 0.0594 - mean_absolute_error: 0.1777 - val_loss: 0.1124 - val_mean_absolute_error: 0.2692\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0638 - mean_absolute_error: 0.1852 - val_loss: 0.1276 - val_mean_absolute_error: 0.2910\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0650 - mean_absolute_error: 0.1811 - val_loss: 0.1182 - val_mean_absolute_error: 0.2752\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0468 - mean_absolute_error: 0.1588 - val_loss: 0.1350 - val_mean_absolute_error: 0.2966\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0617 - mean_absolute_error: 0.1787 - val_loss: 0.1121 - val_mean_absolute_error: 0.2624\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0606 - mean_absolute_error: 0.1809 - val_loss: 0.1085 - val_mean_absolute_error: 0.2581\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0507 - mean_absolute_error: 0.1693 - val_loss: 0.1089 - val_mean_absolute_error: 0.2626\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0510 - mean_absolute_error: 0.1651 - val_loss: 0.1131 - val_mean_absolute_error: 0.2644\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0583 - mean_absolute_error: 0.1715 - val_loss: 0.1023 - val_mean_absolute_error: 0.2534\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0670 - mean_absolute_error: 0.1866 - val_loss: 0.1278 - val_mean_absolute_error: 0.2820\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0565 - mean_absolute_error: 0.1692 - val_loss: 0.1080 - val_mean_absolute_error: 0.2563\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.0566 - mean_absolute_error: 0.1736 - val_loss: 0.1177 - val_mean_absolute_error: 0.2730\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 0.0550 - mean_absolute_error: 0.1751 - val_loss: 0.1184 - val_mean_absolute_error: 0.2742\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0568 - mean_absolute_error: 0.1685 - val_loss: 0.1159 - val_mean_absolute_error: 0.2658\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0548 - mean_absolute_error: 0.1714 - val_loss: 0.1251 - val_mean_absolute_error: 0.2794\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0615 - mean_absolute_error: 0.1797 - val_loss: 0.1256 - val_mean_absolute_error: 0.2822\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0496 - mean_absolute_error: 0.1671 - val_loss: 0.1189 - val_mean_absolute_error: 0.2751\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0469 - mean_absolute_error: 0.1609 - val_loss: 0.1501 - val_mean_absolute_error: 0.3116\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0652 - mean_absolute_error: 0.1811 - val_loss: 0.1002 - val_mean_absolute_error: 0.2530\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0557 - mean_absolute_error: 0.1755 - val_loss: 0.1296 - val_mean_absolute_error: 0.2904\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0430 - mean_absolute_error: 0.1591 - val_loss: 0.1108 - val_mean_absolute_error: 0.2638\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0604 - mean_absolute_error: 0.1834 - val_loss: 0.1134 - val_mean_absolute_error: 0.2687\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0497 - mean_absolute_error: 0.1628 - val_loss: 0.1485 - val_mean_absolute_error: 0.3103\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0410 - mean_absolute_error: 0.1516 - val_loss: 0.1010 - val_mean_absolute_error: 0.2516\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0615 - mean_absolute_error: 0.1726 - val_loss: 0.1044 - val_mean_absolute_error: 0.2608\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0541 - mean_absolute_error: 0.1665 - val_loss: 0.1087 - val_mean_absolute_error: 0.2593\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.0545 - mean_absolute_error: 0.1754 - val_loss: 0.1177 - val_mean_absolute_error: 0.2763\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 1s 974ms/step - loss: 0.0461 - mean_absolute_error: 0.1561 - val_loss: 0.1227 - val_mean_absolute_error: 0.2731\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0502 - mean_absolute_error: 0.1660 - val_loss: 0.1403 - val_mean_absolute_error: 0.2988\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.0503 - mean_absolute_error: 0.1679 - val_loss: 0.1267 - val_mean_absolute_error: 0.2819\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 1s 978ms/step - loss: 0.0520 - mean_absolute_error: 0.1638 - val_loss: 0.1166 - val_mean_absolute_error: 0.2706\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 0.0481 - mean_absolute_error: 0.1593 - val_loss: 0.1205 - val_mean_absolute_error: 0.2836\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0434 - mean_absolute_error: 0.1562 - val_loss: 0.1334 - val_mean_absolute_error: 0.2942\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0431 - mean_absolute_error: 0.1561 - val_loss: 0.1334 - val_mean_absolute_error: 0.3003\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0430 - mean_absolute_error: 0.1545 - val_loss: 0.1326 - val_mean_absolute_error: 0.2963\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0493 - mean_absolute_error: 0.1566 - val_loss: 0.1349 - val_mean_absolute_error: 0.2957\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0539 - mean_absolute_error: 0.1626 - val_loss: 0.1225 - val_mean_absolute_error: 0.2845\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0449 - mean_absolute_error: 0.1583 - val_loss: 0.1240 - val_mean_absolute_error: 0.2866\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 979ms/step - loss: 0.0520 - mean_absolute_error: 0.1664 - val_loss: 0.1214 - val_mean_absolute_error: 0.2776\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0478 - mean_absolute_error: 0.1629 - val_loss: 0.1247 - val_mean_absolute_error: 0.2797\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 1s 973ms/step - loss: 0.0469 - mean_absolute_error: 0.1614 - val_loss: 0.1174 - val_mean_absolute_error: 0.2709\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 1s 955ms/step - loss: 0.0423 - mean_absolute_error: 0.1550 - val_loss: 0.1129 - val_mean_absolute_error: 0.2719\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0447 - mean_absolute_error: 0.1542 - val_loss: 0.1364 - val_mean_absolute_error: 0.2955\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0539 - mean_absolute_error: 0.1746 - val_loss: 0.1044 - val_mean_absolute_error: 0.2591\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0417 - mean_absolute_error: 0.1482 - val_loss: 0.1362 - val_mean_absolute_error: 0.3030\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0598 - mean_absolute_error: 0.1739 - val_loss: 0.1151 - val_mean_absolute_error: 0.2739\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0431 - mean_absolute_error: 0.1517 - val_loss: 0.1209 - val_mean_absolute_error: 0.2825\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 0.0358 - mean_absolute_error: 0.1447 - val_loss: 0.1578 - val_mean_absolute_error: 0.3279\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0496 - mean_absolute_error: 0.1609 - val_loss: 0.1225 - val_mean_absolute_error: 0.2813\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 1s 971ms/step - loss: 0.0514 - mean_absolute_error: 0.1665 - val_loss: 0.1090 - val_mean_absolute_error: 0.2736\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0473 - mean_absolute_error: 0.1611 - val_loss: 0.1093 - val_mean_absolute_error: 0.2614\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0320 - mean_absolute_error: 0.1347 - val_loss: 0.1055 - val_mean_absolute_error: 0.2596\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0407 - mean_absolute_error: 0.1470 - val_loss: 0.1176 - val_mean_absolute_error: 0.2696\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0346 - mean_absolute_error: 0.1377 - val_loss: 0.1243 - val_mean_absolute_error: 0.2800\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0310 - mean_absolute_error: 0.1326 - val_loss: 0.1179 - val_mean_absolute_error: 0.2739\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0421 - mean_absolute_error: 0.1499 - val_loss: 0.0963 - val_mean_absolute_error: 0.2450\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.0423 - mean_absolute_error: 0.1510 - val_loss: 0.1174 - val_mean_absolute_error: 0.2777\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.0508 - mean_absolute_error: 0.1628 - val_loss: 0.1249 - val_mean_absolute_error: 0.2875\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0404 - mean_absolute_error: 0.1470 - val_loss: 0.1134 - val_mean_absolute_error: 0.2704\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0403 - mean_absolute_error: 0.1495 - val_loss: 0.1192 - val_mean_absolute_error: 0.2782\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0408 - mean_absolute_error: 0.1467 - val_loss: 0.1167 - val_mean_absolute_error: 0.2728\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.0487 - mean_absolute_error: 0.1610 - val_loss: 0.1015 - val_mean_absolute_error: 0.2586\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0415 - mean_absolute_error: 0.1454 - val_loss: 0.1185 - val_mean_absolute_error: 0.2854\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.0523 - mean_absolute_error: 0.1567 - val_loss: 0.1206 - val_mean_absolute_error: 0.2815\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0511 - mean_absolute_error: 0.1652 - val_loss: 0.1209 - val_mean_absolute_error: 0.2792\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0468 - mean_absolute_error: 0.1614 - val_loss: 0.1190 - val_mean_absolute_error: 0.2782\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0374 - mean_absolute_error: 0.1365 - val_loss: 0.1164 - val_mean_absolute_error: 0.2787\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0422 - mean_absolute_error: 0.1457 - val_loss: 0.1304 - val_mean_absolute_error: 0.2924\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 1s 977ms/step - loss: 0.0454 - mean_absolute_error: 0.1507 - val_loss: 0.1093 - val_mean_absolute_error: 0.2637\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0403 - mean_absolute_error: 0.1423 - val_loss: 0.1180 - val_mean_absolute_error: 0.2726\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0367 - mean_absolute_error: 0.1404 - val_loss: 0.1045 - val_mean_absolute_error: 0.2564\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0378 - mean_absolute_error: 0.1459 - val_loss: 0.0975 - val_mean_absolute_error: 0.2485\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0407 - mean_absolute_error: 0.1504 - val_loss: 0.1017 - val_mean_absolute_error: 0.2512\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0298 - mean_absolute_error: 0.1315 - val_loss: 0.0939 - val_mean_absolute_error: 0.2422\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.0345 - mean_absolute_error: 0.1415 - val_loss: 0.0944 - val_mean_absolute_error: 0.2503\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0344 - mean_absolute_error: 0.1359 - val_loss: 0.0903 - val_mean_absolute_error: 0.2353\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 1s 979ms/step - loss: 0.0462 - mean_absolute_error: 0.1597 - val_loss: 0.1036 - val_mean_absolute_error: 0.2588\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0404 - mean_absolute_error: 0.1432 - val_loss: 0.1117 - val_mean_absolute_error: 0.2709\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0463 - mean_absolute_error: 0.1534 - val_loss: 0.1244 - val_mean_absolute_error: 0.2800\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0407 - mean_absolute_error: 0.1489 - val_loss: 0.1247 - val_mean_absolute_error: 0.2886\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0376 - mean_absolute_error: 0.1437 - val_loss: 0.0942 - val_mean_absolute_error: 0.2435\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.0382 - mean_absolute_error: 0.1438 - val_loss: 0.1020 - val_mean_absolute_error: 0.2616\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0396 - mean_absolute_error: 0.1453 - val_loss: 0.1074 - val_mean_absolute_error: 0.2642\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0364 - mean_absolute_error: 0.1444 - val_loss: 0.1025 - val_mean_absolute_error: 0.2500\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0333 - mean_absolute_error: 0.1359 - val_loss: 0.1141 - val_mean_absolute_error: 0.2754\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0509 - mean_absolute_error: 0.1613 - val_loss: 0.1085 - val_mean_absolute_error: 0.2695\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.0322 - mean_absolute_error: 0.1347 - val_loss: 0.1111 - val_mean_absolute_error: 0.2695\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0423 - mean_absolute_error: 0.1477 - val_loss: 0.1027 - val_mean_absolute_error: 0.2631\n"
     ]
    }
   ],
   "source": [
    "gru_model = model_gru(\n",
    "    window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "    training_flag=__RNN_TRAINING__, checkpoint_path=model_path+\"gru.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "concerned-somewhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8478 - mean_absolute_error: 0.7581 - val_loss: 0.5066 - val_mean_absolute_error: 0.5650\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7835 - mean_absolute_error: 0.7469 - val_loss: 0.4238 - val_mean_absolute_error: 0.4894\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.6922 - mean_absolute_error: 0.7072 - val_loss: 0.4574 - val_mean_absolute_error: 0.5126\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.7121 - mean_absolute_error: 0.7066 - val_loss: 0.4306 - val_mean_absolute_error: 0.4998\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6639 - mean_absolute_error: 0.6597 - val_loss: 0.2935 - val_mean_absolute_error: 0.4032\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.4308 - mean_absolute_error: 0.5163 - val_loss: 0.2731 - val_mean_absolute_error: 0.3808\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4159 - mean_absolute_error: 0.5126 - val_loss: 0.2377 - val_mean_absolute_error: 0.3237\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.3078 - mean_absolute_error: 0.4145 - val_loss: 0.2589 - val_mean_absolute_error: 0.3519\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2263 - mean_absolute_error: 0.3736 - val_loss: 0.1810 - val_mean_absolute_error: 0.2960\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1613 - mean_absolute_error: 0.3248 - val_loss: 0.1583 - val_mean_absolute_error: 0.3021\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 1s 978ms/step - loss: 0.1907 - mean_absolute_error: 0.3344 - val_loss: 0.1722 - val_mean_absolute_error: 0.3312\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1783 - mean_absolute_error: 0.3316 - val_loss: 0.1362 - val_mean_absolute_error: 0.3054\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.1690 - mean_absolute_error: 0.3242 - val_loss: 0.1201 - val_mean_absolute_error: 0.2945\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.2309 - mean_absolute_error: 0.3823 - val_loss: 0.1174 - val_mean_absolute_error: 0.2884\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1731 - mean_absolute_error: 0.3360 - val_loss: 0.0986 - val_mean_absolute_error: 0.2687\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.1775 - mean_absolute_error: 0.3329 - val_loss: 0.0970 - val_mean_absolute_error: 0.2529\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 1s 943ms/step - loss: 0.1587 - mean_absolute_error: 0.3184 - val_loss: 0.0836 - val_mean_absolute_error: 0.2346\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1302 - mean_absolute_error: 0.2729 - val_loss: 0.0725 - val_mean_absolute_error: 0.2212\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.1351 - mean_absolute_error: 0.2769 - val_loss: 0.0644 - val_mean_absolute_error: 0.1983\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1236 - mean_absolute_error: 0.2619 - val_loss: 0.0748 - val_mean_absolute_error: 0.2142\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1175 - mean_absolute_error: 0.2581 - val_loss: 0.0890 - val_mean_absolute_error: 0.2233\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1032 - mean_absolute_error: 0.2413 - val_loss: 0.0912 - val_mean_absolute_error: 0.2332\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.0936 - mean_absolute_error: 0.2223 - val_loss: 0.1237 - val_mean_absolute_error: 0.2724\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 1s 984ms/step - loss: 0.1254 - mean_absolute_error: 0.2516 - val_loss: 0.0909 - val_mean_absolute_error: 0.2355\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0926 - mean_absolute_error: 0.2314 - val_loss: 0.1617 - val_mean_absolute_error: 0.3124\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0902 - mean_absolute_error: 0.2245 - val_loss: 0.1198 - val_mean_absolute_error: 0.2750\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1127 - mean_absolute_error: 0.2424 - val_loss: 0.1043 - val_mean_absolute_error: 0.2413\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0925 - mean_absolute_error: 0.2225 - val_loss: 0.1340 - val_mean_absolute_error: 0.2899\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0930 - mean_absolute_error: 0.2150 - val_loss: 0.1298 - val_mean_absolute_error: 0.2883\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0846 - mean_absolute_error: 0.2170 - val_loss: 0.1188 - val_mean_absolute_error: 0.2624\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.1009 - mean_absolute_error: 0.2292 - val_loss: 0.1058 - val_mean_absolute_error: 0.2582\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0809 - mean_absolute_error: 0.2144 - val_loss: 0.1245 - val_mean_absolute_error: 0.2804\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0758 - mean_absolute_error: 0.1994 - val_loss: 0.1088 - val_mean_absolute_error: 0.2487\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 0.0720 - mean_absolute_error: 0.1944 - val_loss: 0.0937 - val_mean_absolute_error: 0.2320\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0725 - mean_absolute_error: 0.1944 - val_loss: 0.0795 - val_mean_absolute_error: 0.2155\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0780 - mean_absolute_error: 0.2054 - val_loss: 0.0866 - val_mean_absolute_error: 0.2199\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0866 - mean_absolute_error: 0.2158 - val_loss: 0.0872 - val_mean_absolute_error: 0.2299\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0907 - mean_absolute_error: 0.2145 - val_loss: 0.0691 - val_mean_absolute_error: 0.2077\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0616 - mean_absolute_error: 0.1920 - val_loss: 0.0710 - val_mean_absolute_error: 0.2077\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0718 - mean_absolute_error: 0.1959 - val_loss: 0.0684 - val_mean_absolute_error: 0.2019\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0532 - mean_absolute_error: 0.1757 - val_loss: 0.0874 - val_mean_absolute_error: 0.2264\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0780 - mean_absolute_error: 0.2007 - val_loss: 0.0950 - val_mean_absolute_error: 0.2400\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0705 - mean_absolute_error: 0.1909 - val_loss: 0.0878 - val_mean_absolute_error: 0.2280\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0828 - mean_absolute_error: 0.2055 - val_loss: 0.0891 - val_mean_absolute_error: 0.2305\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0685 - mean_absolute_error: 0.1817 - val_loss: 0.0834 - val_mean_absolute_error: 0.2284\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 0.0628 - mean_absolute_error: 0.1803 - val_loss: 0.0952 - val_mean_absolute_error: 0.2379\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0687 - mean_absolute_error: 0.1848 - val_loss: 0.0912 - val_mean_absolute_error: 0.2326\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 1s 987ms/step - loss: 0.0637 - mean_absolute_error: 0.1823 - val_loss: 0.0954 - val_mean_absolute_error: 0.2397\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0571 - mean_absolute_error: 0.1716 - val_loss: 0.0732 - val_mean_absolute_error: 0.2086\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0564 - mean_absolute_error: 0.1758 - val_loss: 0.1163 - val_mean_absolute_error: 0.2652\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0527 - mean_absolute_error: 0.1696 - val_loss: 0.0968 - val_mean_absolute_error: 0.2426\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0546 - mean_absolute_error: 0.1694 - val_loss: 0.0810 - val_mean_absolute_error: 0.2144\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0552 - mean_absolute_error: 0.1719 - val_loss: 0.0926 - val_mean_absolute_error: 0.2359\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0550 - mean_absolute_error: 0.1701 - val_loss: 0.0939 - val_mean_absolute_error: 0.2383\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0619 - mean_absolute_error: 0.1753 - val_loss: 0.0913 - val_mean_absolute_error: 0.2294\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.0565 - mean_absolute_error: 0.1737 - val_loss: 0.0893 - val_mean_absolute_error: 0.2316\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0493 - mean_absolute_error: 0.1652 - val_loss: 0.1018 - val_mean_absolute_error: 0.2552\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0574 - mean_absolute_error: 0.1753 - val_loss: 0.1048 - val_mean_absolute_error: 0.2465\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0563 - mean_absolute_error: 0.1748 - val_loss: 0.0918 - val_mean_absolute_error: 0.2304\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 0.0494 - mean_absolute_error: 0.1622 - val_loss: 0.0785 - val_mean_absolute_error: 0.2166\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0413 - mean_absolute_error: 0.1515 - val_loss: 0.0946 - val_mean_absolute_error: 0.2339\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0382 - mean_absolute_error: 0.1478 - val_loss: 0.0906 - val_mean_absolute_error: 0.2327\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0575 - mean_absolute_error: 0.1681 - val_loss: 0.0793 - val_mean_absolute_error: 0.2226\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0466 - mean_absolute_error: 0.1567 - val_loss: 0.0755 - val_mean_absolute_error: 0.2155\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0523 - mean_absolute_error: 0.1670 - val_loss: 0.0742 - val_mean_absolute_error: 0.2116\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0472 - mean_absolute_error: 0.1572 - val_loss: 0.0889 - val_mean_absolute_error: 0.2268\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.0666 - mean_absolute_error: 0.1822 - val_loss: 0.0961 - val_mean_absolute_error: 0.2438\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 0.0590 - mean_absolute_error: 0.1769 - val_loss: 0.0933 - val_mean_absolute_error: 0.2368\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0471 - mean_absolute_error: 0.1549 - val_loss: 0.0857 - val_mean_absolute_error: 0.2238\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0478 - mean_absolute_error: 0.1609 - val_loss: 0.0832 - val_mean_absolute_error: 0.2276\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.0447 - mean_absolute_error: 0.1558 - val_loss: 0.0905 - val_mean_absolute_error: 0.2290\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0510 - mean_absolute_error: 0.1648 - val_loss: 0.0863 - val_mean_absolute_error: 0.2273\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0514 - mean_absolute_error: 0.1575 - val_loss: 0.0909 - val_mean_absolute_error: 0.2328\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0508 - mean_absolute_error: 0.1630 - val_loss: 0.0793 - val_mean_absolute_error: 0.2161\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0506 - mean_absolute_error: 0.1564 - val_loss: 0.1061 - val_mean_absolute_error: 0.2522\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0483 - mean_absolute_error: 0.1563 - val_loss: 0.0967 - val_mean_absolute_error: 0.2427\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0547 - mean_absolute_error: 0.1625 - val_loss: 0.0825 - val_mean_absolute_error: 0.2160\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0549 - mean_absolute_error: 0.1647 - val_loss: 0.0707 - val_mean_absolute_error: 0.2017\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0447 - mean_absolute_error: 0.1524 - val_loss: 0.0923 - val_mean_absolute_error: 0.2371\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0427 - mean_absolute_error: 0.1523 - val_loss: 0.0831 - val_mean_absolute_error: 0.2158\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 0.0461 - mean_absolute_error: 0.1559 - val_loss: 0.0953 - val_mean_absolute_error: 0.2375\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.0488 - mean_absolute_error: 0.1551 - val_loss: 0.0943 - val_mean_absolute_error: 0.2444\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0473 - mean_absolute_error: 0.1561 - val_loss: 0.1025 - val_mean_absolute_error: 0.2492\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 0.0529 - mean_absolute_error: 0.1606 - val_loss: 0.0876 - val_mean_absolute_error: 0.2206\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0457 - mean_absolute_error: 0.1515 - val_loss: 0.0684 - val_mean_absolute_error: 0.2010\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0435 - mean_absolute_error: 0.1507 - val_loss: 0.0715 - val_mean_absolute_error: 0.2034\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0519 - mean_absolute_error: 0.1685 - val_loss: 0.0849 - val_mean_absolute_error: 0.2237\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0470 - mean_absolute_error: 0.1498 - val_loss: 0.0709 - val_mean_absolute_error: 0.2114\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0390 - mean_absolute_error: 0.1441 - val_loss: 0.0673 - val_mean_absolute_error: 0.2040\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 0.0392 - mean_absolute_error: 0.1458 - val_loss: 0.0644 - val_mean_absolute_error: 0.2012\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0501 - mean_absolute_error: 0.1550 - val_loss: 0.0799 - val_mean_absolute_error: 0.2158\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0377 - mean_absolute_error: 0.1411 - val_loss: 0.0766 - val_mean_absolute_error: 0.2196\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.0443 - mean_absolute_error: 0.1546 - val_loss: 0.0734 - val_mean_absolute_error: 0.2104\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0427 - mean_absolute_error: 0.1512 - val_loss: 0.0713 - val_mean_absolute_error: 0.2070\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0437 - mean_absolute_error: 0.1567 - val_loss: 0.0661 - val_mean_absolute_error: 0.2018\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0417 - mean_absolute_error: 0.1509 - val_loss: 0.0751 - val_mean_absolute_error: 0.2130\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0623 - mean_absolute_error: 0.1740 - val_loss: 0.0639 - val_mean_absolute_error: 0.1987\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.0475 - mean_absolute_error: 0.1564 - val_loss: 0.0769 - val_mean_absolute_error: 0.2163\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0457 - mean_absolute_error: 0.1559 - val_loss: 0.0767 - val_mean_absolute_error: 0.2135\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0484 - mean_absolute_error: 0.1520 - val_loss: 0.0817 - val_mean_absolute_error: 0.2244\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 954ms/step - loss: 0.0428 - mean_absolute_error: 0.1448 - val_loss: 0.0902 - val_mean_absolute_error: 0.2302\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0415 - mean_absolute_error: 0.1463 - val_loss: 0.0671 - val_mean_absolute_error: 0.1978\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.0389 - mean_absolute_error: 0.1449 - val_loss: 0.0670 - val_mean_absolute_error: 0.1991\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0467 - mean_absolute_error: 0.1526 - val_loss: 0.0732 - val_mean_absolute_error: 0.2086\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 0.0384 - mean_absolute_error: 0.1449 - val_loss: 0.0654 - val_mean_absolute_error: 0.1908\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0439 - mean_absolute_error: 0.1527 - val_loss: 0.0727 - val_mean_absolute_error: 0.2058\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0443 - mean_absolute_error: 0.1510 - val_loss: 0.0708 - val_mean_absolute_error: 0.2083\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0530 - mean_absolute_error: 0.1605 - val_loss: 0.0830 - val_mean_absolute_error: 0.2224\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0393 - mean_absolute_error: 0.1457 - val_loss: 0.0823 - val_mean_absolute_error: 0.2126\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0492 - mean_absolute_error: 0.1588 - val_loss: 0.0657 - val_mean_absolute_error: 0.1966\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0512 - mean_absolute_error: 0.1574 - val_loss: 0.0723 - val_mean_absolute_error: 0.2062\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0461 - mean_absolute_error: 0.1586 - val_loss: 0.0992 - val_mean_absolute_error: 0.2409\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0383 - mean_absolute_error: 0.1431 - val_loss: 0.0813 - val_mean_absolute_error: 0.2226\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0563 - mean_absolute_error: 0.1697 - val_loss: 0.0708 - val_mean_absolute_error: 0.2073\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 1s 946ms/step - loss: 0.0373 - mean_absolute_error: 0.1403 - val_loss: 0.0728 - val_mean_absolute_error: 0.2128\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 1s 969ms/step - loss: 0.0345 - mean_absolute_error: 0.1348 - val_loss: 0.0968 - val_mean_absolute_error: 0.2373\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0463 - mean_absolute_error: 0.1581 - val_loss: 0.0906 - val_mean_absolute_error: 0.2370\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0583 - mean_absolute_error: 0.1571 - val_loss: 0.0913 - val_mean_absolute_error: 0.2323\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 0.0387 - mean_absolute_error: 0.1459 - val_loss: 0.0751 - val_mean_absolute_error: 0.2129\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0405 - mean_absolute_error: 0.1521 - val_loss: 0.0763 - val_mean_absolute_error: 0.2120\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 1s 937ms/step - loss: 0.0392 - mean_absolute_error: 0.1434 - val_loss: 0.0688 - val_mean_absolute_error: 0.1995\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0384 - mean_absolute_error: 0.1423 - val_loss: 0.0758 - val_mean_absolute_error: 0.2119\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0500 - mean_absolute_error: 0.1553 - val_loss: 0.0689 - val_mean_absolute_error: 0.2017\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.0408 - mean_absolute_error: 0.1440 - val_loss: 0.0808 - val_mean_absolute_error: 0.2138\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0380 - mean_absolute_error: 0.1411 - val_loss: 0.0705 - val_mean_absolute_error: 0.2058\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0508 - mean_absolute_error: 0.1551 - val_loss: 0.0848 - val_mean_absolute_error: 0.2194\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0336 - mean_absolute_error: 0.1326 - val_loss: 0.0759 - val_mean_absolute_error: 0.2112\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 1s 957ms/step - loss: 0.0421 - mean_absolute_error: 0.1440 - val_loss: 0.0522 - val_mean_absolute_error: 0.1752\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 1s 989ms/step - loss: 0.0456 - mean_absolute_error: 0.1528 - val_loss: 0.0769 - val_mean_absolute_error: 0.2127\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0479 - mean_absolute_error: 0.1553 - val_loss: 0.0726 - val_mean_absolute_error: 0.2010\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0413 - mean_absolute_error: 0.1437 - val_loss: 0.0749 - val_mean_absolute_error: 0.2104\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 0.0485 - mean_absolute_error: 0.1589 - val_loss: 0.0828 - val_mean_absolute_error: 0.2243\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0377 - mean_absolute_error: 0.1409 - val_loss: 0.0929 - val_mean_absolute_error: 0.2348\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0332 - mean_absolute_error: 0.1347 - val_loss: 0.0972 - val_mean_absolute_error: 0.2276\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0400 - mean_absolute_error: 0.1450 - val_loss: 0.0605 - val_mean_absolute_error: 0.1880\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0389 - mean_absolute_error: 0.1419 - val_loss: 0.0733 - val_mean_absolute_error: 0.2053\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0400 - mean_absolute_error: 0.1480 - val_loss: 0.0900 - val_mean_absolute_error: 0.2251\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0383 - mean_absolute_error: 0.1418 - val_loss: 0.0728 - val_mean_absolute_error: 0.2085\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0321 - mean_absolute_error: 0.1356 - val_loss: 0.0612 - val_mean_absolute_error: 0.1895\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 0.0314 - mean_absolute_error: 0.1323 - val_loss: 0.0602 - val_mean_absolute_error: 0.1869\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0356 - mean_absolute_error: 0.1433 - val_loss: 0.0787 - val_mean_absolute_error: 0.2098\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0319 - mean_absolute_error: 0.1345 - val_loss: 0.0761 - val_mean_absolute_error: 0.2118\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.0323 - mean_absolute_error: 0.1316 - val_loss: 0.0898 - val_mean_absolute_error: 0.2261\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.0382 - mean_absolute_error: 0.1450 - val_loss: 0.0691 - val_mean_absolute_error: 0.1990\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0367 - mean_absolute_error: 0.1377 - val_loss: 0.0742 - val_mean_absolute_error: 0.2097\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0352 - mean_absolute_error: 0.1349 - val_loss: 0.0635 - val_mean_absolute_error: 0.1925\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0374 - mean_absolute_error: 0.1400 - val_loss: 0.0761 - val_mean_absolute_error: 0.2081\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0365 - mean_absolute_error: 0.1351 - val_loss: 0.0700 - val_mean_absolute_error: 0.2045\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0336 - mean_absolute_error: 0.1351 - val_loss: 0.0788 - val_mean_absolute_error: 0.2121\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.0345 - mean_absolute_error: 0.1374 - val_loss: 0.0620 - val_mean_absolute_error: 0.1885\n"
     ]
    }
   ],
   "source": [
    "multi_lstm_model = model_multi_lstm(\n",
    "    window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "    training_flag=__RNN_TRAINING__, checkpoint_path=model_path+\"multi_lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "through-roulette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8060 - mean_absolute_error: 0.7611 - val_loss: 0.4003 - val_mean_absolute_error: 0.4907\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.5856 - mean_absolute_error: 0.6415 - val_loss: 0.1151 - val_mean_absolute_error: 0.2642\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.2592 - mean_absolute_error: 0.3981 - val_loss: 0.2458 - val_mean_absolute_error: 0.4121\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.4233 - mean_absolute_error: 0.5398 - val_loss: 0.1169 - val_mean_absolute_error: 0.2728\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.1164 - mean_absolute_error: 0.2725 - val_loss: 0.1168 - val_mean_absolute_error: 0.2643\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3138 - mean_absolute_error: 0.4573 - val_loss: 0.1617 - val_mean_absolute_error: 0.2892\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.2405 - mean_absolute_error: 0.3930 - val_loss: 0.0766 - val_mean_absolute_error: 0.2072\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.1820 - mean_absolute_error: 0.3399 - val_loss: 0.0554 - val_mean_absolute_error: 0.1827\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.1610 - mean_absolute_error: 0.3205 - val_loss: 0.0722 - val_mean_absolute_error: 0.1941\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1251 - mean_absolute_error: 0.2857 - val_loss: 0.0963 - val_mean_absolute_error: 0.2450\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 1s 967ms/step - loss: 0.0825 - mean_absolute_error: 0.2266 - val_loss: 0.1483 - val_mean_absolute_error: 0.3177\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.1402 - mean_absolute_error: 0.2954 - val_loss: 0.1511 - val_mean_absolute_error: 0.3244\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1344 - mean_absolute_error: 0.2936 - val_loss: 0.1261 - val_mean_absolute_error: 0.2864\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0801 - mean_absolute_error: 0.2208 - val_loss: 0.0885 - val_mean_absolute_error: 0.2338\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0821 - mean_absolute_error: 0.2204 - val_loss: 0.1344 - val_mean_absolute_error: 0.2750\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0878 - mean_absolute_error: 0.2329 - val_loss: 0.1415 - val_mean_absolute_error: 0.2817\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1286 - mean_absolute_error: 0.2850 - val_loss: 0.1266 - val_mean_absolute_error: 0.2683\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.1309 - mean_absolute_error: 0.2803 - val_loss: 0.1116 - val_mean_absolute_error: 0.2519\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0789 - mean_absolute_error: 0.2163 - val_loss: 0.0878 - val_mean_absolute_error: 0.2277\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0919 - mean_absolute_error: 0.2298 - val_loss: 0.0820 - val_mean_absolute_error: 0.2266\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 1s 933ms/step - loss: 0.0746 - mean_absolute_error: 0.2072 - val_loss: 0.0940 - val_mean_absolute_error: 0.2340\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0729 - mean_absolute_error: 0.2070 - val_loss: 0.0852 - val_mean_absolute_error: 0.2317\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0683 - mean_absolute_error: 0.2070 - val_loss: 0.1022 - val_mean_absolute_error: 0.2383\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0895 - mean_absolute_error: 0.2272 - val_loss: 0.0768 - val_mean_absolute_error: 0.2153\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0780 - mean_absolute_error: 0.2101 - val_loss: 0.0715 - val_mean_absolute_error: 0.2022\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.0690 - mean_absolute_error: 0.2046 - val_loss: 0.0701 - val_mean_absolute_error: 0.2024\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0841 - mean_absolute_error: 0.2267 - val_loss: 0.0519 - val_mean_absolute_error: 0.1774\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0846 - mean_absolute_error: 0.2283 - val_loss: 0.1045 - val_mean_absolute_error: 0.2458\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 0.0744 - mean_absolute_error: 0.2055 - val_loss: 0.1040 - val_mean_absolute_error: 0.2592\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0760 - mean_absolute_error: 0.2049 - val_loss: 0.1512 - val_mean_absolute_error: 0.3294\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.0671 - mean_absolute_error: 0.2016 - val_loss: 0.1702 - val_mean_absolute_error: 0.3376\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0735 - mean_absolute_error: 0.2019 - val_loss: 0.1263 - val_mean_absolute_error: 0.2922\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0762 - mean_absolute_error: 0.2124 - val_loss: 0.0896 - val_mean_absolute_error: 0.2407\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0652 - mean_absolute_error: 0.1938 - val_loss: 0.1042 - val_mean_absolute_error: 0.2501\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0619 - mean_absolute_error: 0.1876 - val_loss: 0.0940 - val_mean_absolute_error: 0.2416\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 0.0709 - mean_absolute_error: 0.1989 - val_loss: 0.0999 - val_mean_absolute_error: 0.2479\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0509 - mean_absolute_error: 0.1696 - val_loss: 0.0887 - val_mean_absolute_error: 0.2341\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0603 - mean_absolute_error: 0.1891 - val_loss: 0.0884 - val_mean_absolute_error: 0.2300\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0571 - mean_absolute_error: 0.1823 - val_loss: 0.0759 - val_mean_absolute_error: 0.2138\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0596 - mean_absolute_error: 0.1852 - val_loss: 0.0752 - val_mean_absolute_error: 0.2137\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0657 - mean_absolute_error: 0.1941 - val_loss: 0.0945 - val_mean_absolute_error: 0.2384\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0494 - mean_absolute_error: 0.1696 - val_loss: 0.0843 - val_mean_absolute_error: 0.2231\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0549 - mean_absolute_error: 0.1764 - val_loss: 0.1153 - val_mean_absolute_error: 0.2626\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0494 - mean_absolute_error: 0.1671 - val_loss: 0.1043 - val_mean_absolute_error: 0.2480\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0582 - mean_absolute_error: 0.1765 - val_loss: 0.1114 - val_mean_absolute_error: 0.2585\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0407 - mean_absolute_error: 0.1550 - val_loss: 0.1003 - val_mean_absolute_error: 0.2338\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0490 - mean_absolute_error: 0.1675 - val_loss: 0.0838 - val_mean_absolute_error: 0.2280\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0431 - mean_absolute_error: 0.1601 - val_loss: 0.0954 - val_mean_absolute_error: 0.2266\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0596 - mean_absolute_error: 0.1781 - val_loss: 0.0925 - val_mean_absolute_error: 0.2342\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0568 - mean_absolute_error: 0.1725 - val_loss: 0.0912 - val_mean_absolute_error: 0.2327\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0539 - mean_absolute_error: 0.1753 - val_loss: 0.0942 - val_mean_absolute_error: 0.2363\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0537 - mean_absolute_error: 0.1776 - val_loss: 0.0576 - val_mean_absolute_error: 0.1855\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0618 - mean_absolute_error: 0.1809 - val_loss: 0.0994 - val_mean_absolute_error: 0.2367\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0512 - mean_absolute_error: 0.1707 - val_loss: 0.0725 - val_mean_absolute_error: 0.2030\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0450 - mean_absolute_error: 0.1619 - val_loss: 0.0826 - val_mean_absolute_error: 0.2266\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0487 - mean_absolute_error: 0.1662 - val_loss: 0.1066 - val_mean_absolute_error: 0.2484\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 1s 960ms/step - loss: 0.0442 - mean_absolute_error: 0.1590 - val_loss: 0.1068 - val_mean_absolute_error: 0.2548\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0495 - mean_absolute_error: 0.1700 - val_loss: 0.0904 - val_mean_absolute_error: 0.2353\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0439 - mean_absolute_error: 0.1595 - val_loss: 0.1343 - val_mean_absolute_error: 0.2937\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 1s 943ms/step - loss: 0.0473 - mean_absolute_error: 0.1652 - val_loss: 0.1390 - val_mean_absolute_error: 0.3045\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0426 - mean_absolute_error: 0.1554 - val_loss: 0.1428 - val_mean_absolute_error: 0.3135\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0452 - mean_absolute_error: 0.1630 - val_loss: 0.1137 - val_mean_absolute_error: 0.2731\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0527 - mean_absolute_error: 0.1703 - val_loss: 0.0868 - val_mean_absolute_error: 0.2291\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0464 - mean_absolute_error: 0.1635 - val_loss: 0.0756 - val_mean_absolute_error: 0.2123\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0458 - mean_absolute_error: 0.1641 - val_loss: 0.0800 - val_mean_absolute_error: 0.2186\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 1s 958ms/step - loss: 0.0428 - mean_absolute_error: 0.1597 - val_loss: 0.1097 - val_mean_absolute_error: 0.2568\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0413 - mean_absolute_error: 0.1515 - val_loss: 0.0918 - val_mean_absolute_error: 0.2355\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0536 - mean_absolute_error: 0.1693 - val_loss: 0.1129 - val_mean_absolute_error: 0.2592\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0486 - mean_absolute_error: 0.1622 - val_loss: 0.0946 - val_mean_absolute_error: 0.2374\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0427 - mean_absolute_error: 0.1529 - val_loss: 0.0828 - val_mean_absolute_error: 0.2269\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 1s 940ms/step - loss: 0.0529 - mean_absolute_error: 0.1693 - val_loss: 0.0903 - val_mean_absolute_error: 0.2312\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0404 - mean_absolute_error: 0.1537 - val_loss: 0.0891 - val_mean_absolute_error: 0.2317\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0466 - mean_absolute_error: 0.1561 - val_loss: 0.0915 - val_mean_absolute_error: 0.2369\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 0.0475 - mean_absolute_error: 0.1617 - val_loss: 0.1351 - val_mean_absolute_error: 0.2934\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0556 - mean_absolute_error: 0.1767 - val_loss: 0.1030 - val_mean_absolute_error: 0.2522\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0443 - mean_absolute_error: 0.1622 - val_loss: 0.0993 - val_mean_absolute_error: 0.2474\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 1s 962ms/step - loss: 0.0475 - mean_absolute_error: 0.1670 - val_loss: 0.0681 - val_mean_absolute_error: 0.2026\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0563 - mean_absolute_error: 0.1765 - val_loss: 0.1014 - val_mean_absolute_error: 0.2437\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0437 - mean_absolute_error: 0.1522 - val_loss: 0.0872 - val_mean_absolute_error: 0.2250\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0414 - mean_absolute_error: 0.1532 - val_loss: 0.0959 - val_mean_absolute_error: 0.2439\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0519 - mean_absolute_error: 0.1689 - val_loss: 0.0927 - val_mean_absolute_error: 0.2369\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0371 - mean_absolute_error: 0.1473 - val_loss: 0.0934 - val_mean_absolute_error: 0.2371\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.0400 - mean_absolute_error: 0.1464 - val_loss: 0.0733 - val_mean_absolute_error: 0.2150\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 1s 970ms/step - loss: 0.0365 - mean_absolute_error: 0.1496 - val_loss: 0.0732 - val_mean_absolute_error: 0.2084\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0380 - mean_absolute_error: 0.1489 - val_loss: 0.0856 - val_mean_absolute_error: 0.2259\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 0.0464 - mean_absolute_error: 0.1600 - val_loss: 0.0990 - val_mean_absolute_error: 0.2438\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0530 - mean_absolute_error: 0.1650 - val_loss: 0.0853 - val_mean_absolute_error: 0.2275\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0501 - mean_absolute_error: 0.1636 - val_loss: 0.0714 - val_mean_absolute_error: 0.2068\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.0476 - mean_absolute_error: 0.1629 - val_loss: 0.0807 - val_mean_absolute_error: 0.2161\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0364 - mean_absolute_error: 0.1460 - val_loss: 0.0737 - val_mean_absolute_error: 0.2115\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0433 - mean_absolute_error: 0.1549 - val_loss: 0.0929 - val_mean_absolute_error: 0.2345\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0510 - mean_absolute_error: 0.1658 - val_loss: 0.0902 - val_mean_absolute_error: 0.2344\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0520 - mean_absolute_error: 0.1677 - val_loss: 0.1172 - val_mean_absolute_error: 0.2654\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0436 - mean_absolute_error: 0.1580 - val_loss: 0.0842 - val_mean_absolute_error: 0.2188\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0417 - mean_absolute_error: 0.1532 - val_loss: 0.0727 - val_mean_absolute_error: 0.2041\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0388 - mean_absolute_error: 0.1495 - val_loss: 0.0785 - val_mean_absolute_error: 0.2172\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0442 - mean_absolute_error: 0.1637 - val_loss: 0.0567 - val_mean_absolute_error: 0.1819\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0383 - mean_absolute_error: 0.1515 - val_loss: 0.0672 - val_mean_absolute_error: 0.1906\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 0.0416 - mean_absolute_error: 0.1498 - val_loss: 0.0953 - val_mean_absolute_error: 0.2250\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 1s 972ms/step - loss: 0.0439 - mean_absolute_error: 0.1543 - val_loss: 0.0938 - val_mean_absolute_error: 0.2313\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 957ms/step - loss: 0.0456 - mean_absolute_error: 0.1530 - val_loss: 0.0814 - val_mean_absolute_error: 0.2129\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.0384 - mean_absolute_error: 0.1450 - val_loss: 0.0672 - val_mean_absolute_error: 0.1995\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0457 - mean_absolute_error: 0.1598 - val_loss: 0.0803 - val_mean_absolute_error: 0.2130\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0450 - mean_absolute_error: 0.1604 - val_loss: 0.0828 - val_mean_absolute_error: 0.2156\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 1s 964ms/step - loss: 0.0416 - mean_absolute_error: 0.1547 - val_loss: 0.0805 - val_mean_absolute_error: 0.2208\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0452 - mean_absolute_error: 0.1582 - val_loss: 0.0946 - val_mean_absolute_error: 0.2356\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0333 - mean_absolute_error: 0.1383 - val_loss: 0.1105 - val_mean_absolute_error: 0.2548\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0378 - mean_absolute_error: 0.1422 - val_loss: 0.0613 - val_mean_absolute_error: 0.1877\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0365 - mean_absolute_error: 0.1434 - val_loss: 0.0744 - val_mean_absolute_error: 0.2049\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 0.0404 - mean_absolute_error: 0.1502 - val_loss: 0.0778 - val_mean_absolute_error: 0.2098\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0446 - mean_absolute_error: 0.1605 - val_loss: 0.0876 - val_mean_absolute_error: 0.2197\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0327 - mean_absolute_error: 0.1377 - val_loss: 0.0938 - val_mean_absolute_error: 0.2350\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 1s 965ms/step - loss: 0.0422 - mean_absolute_error: 0.1577 - val_loss: 0.0874 - val_mean_absolute_error: 0.2246\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0345 - mean_absolute_error: 0.1403 - val_loss: 0.0910 - val_mean_absolute_error: 0.2208\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 1s 959ms/step - loss: 0.0376 - mean_absolute_error: 0.1408 - val_loss: 0.0612 - val_mean_absolute_error: 0.1896\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0354 - mean_absolute_error: 0.1454 - val_loss: 0.0795 - val_mean_absolute_error: 0.2154\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0531 - mean_absolute_error: 0.1683 - val_loss: 0.0648 - val_mean_absolute_error: 0.1903\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0409 - mean_absolute_error: 0.1578 - val_loss: 0.0869 - val_mean_absolute_error: 0.2131\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0340 - mean_absolute_error: 0.1386 - val_loss: 0.0831 - val_mean_absolute_error: 0.2115\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0424 - mean_absolute_error: 0.1485 - val_loss: 0.0914 - val_mean_absolute_error: 0.2303\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0421 - mean_absolute_error: 0.1549 - val_loss: 0.0867 - val_mean_absolute_error: 0.2246\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0399 - mean_absolute_error: 0.1492 - val_loss: 0.0577 - val_mean_absolute_error: 0.1884\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0387 - mean_absolute_error: 0.1485 - val_loss: 0.0549 - val_mean_absolute_error: 0.1776\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0398 - mean_absolute_error: 0.1521 - val_loss: 0.0821 - val_mean_absolute_error: 0.2133\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0384 - mean_absolute_error: 0.1496 - val_loss: 0.0897 - val_mean_absolute_error: 0.2292\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 1s 950ms/step - loss: 0.0350 - mean_absolute_error: 0.1434 - val_loss: 0.0967 - val_mean_absolute_error: 0.2264\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 1s 949ms/step - loss: 0.0364 - mean_absolute_error: 0.1439 - val_loss: 0.0996 - val_mean_absolute_error: 0.2408\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0379 - mean_absolute_error: 0.1487 - val_loss: 0.0979 - val_mean_absolute_error: 0.2274\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 1s 951ms/step - loss: 0.0340 - mean_absolute_error: 0.1430 - val_loss: 0.0847 - val_mean_absolute_error: 0.2129\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 1s 956ms/step - loss: 0.0378 - mean_absolute_error: 0.1495 - val_loss: 0.0595 - val_mean_absolute_error: 0.1863\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0357 - mean_absolute_error: 0.1450 - val_loss: 0.0746 - val_mean_absolute_error: 0.2071\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 0.0323 - mean_absolute_error: 0.1367 - val_loss: 0.1164 - val_mean_absolute_error: 0.2560\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0337 - mean_absolute_error: 0.1403 - val_loss: 0.0572 - val_mean_absolute_error: 0.1803\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 0.0348 - mean_absolute_error: 0.1367 - val_loss: 0.0713 - val_mean_absolute_error: 0.1985\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0387 - mean_absolute_error: 0.1471 - val_loss: 0.0677 - val_mean_absolute_error: 0.1919\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0364 - mean_absolute_error: 0.1475 - val_loss: 0.0668 - val_mean_absolute_error: 0.1998\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0394 - mean_absolute_error: 0.1543 - val_loss: 0.0760 - val_mean_absolute_error: 0.2082\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 1s 966ms/step - loss: 0.0407 - mean_absolute_error: 0.1433 - val_loss: 0.0919 - val_mean_absolute_error: 0.2341\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0438 - mean_absolute_error: 0.1459 - val_loss: 0.0944 - val_mean_absolute_error: 0.2290\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 1s 947ms/step - loss: 0.0336 - mean_absolute_error: 0.1393 - val_loss: 0.0668 - val_mean_absolute_error: 0.1991\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0350 - mean_absolute_error: 0.1424 - val_loss: 0.0938 - val_mean_absolute_error: 0.2273\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 1s 961ms/step - loss: 0.0486 - mean_absolute_error: 0.1637 - val_loss: 0.0883 - val_mean_absolute_error: 0.2236\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0300 - mean_absolute_error: 0.1314 - val_loss: 0.1032 - val_mean_absolute_error: 0.2379\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0435 - mean_absolute_error: 0.1522 - val_loss: 0.0889 - val_mean_absolute_error: 0.2204\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0355 - mean_absolute_error: 0.1432 - val_loss: 0.0858 - val_mean_absolute_error: 0.2152\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0346 - mean_absolute_error: 0.1436 - val_loss: 0.0820 - val_mean_absolute_error: 0.2127\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0429 - mean_absolute_error: 0.1530 - val_loss: 0.0662 - val_mean_absolute_error: 0.1931\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0393 - mean_absolute_error: 0.1445 - val_loss: 0.0567 - val_mean_absolute_error: 0.1774\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 1s 942ms/step - loss: 0.0337 - mean_absolute_error: 0.1370 - val_loss: 0.0835 - val_mean_absolute_error: 0.2118\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0393 - mean_absolute_error: 0.1457 - val_loss: 0.0707 - val_mean_absolute_error: 0.1979\n"
     ]
    }
   ],
   "source": [
    "multi_conv_model = model_multi_conv(\n",
    "    window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "    training_flag=__RNN_TRAINING__, checkpoint_path=model_path+\"multi_conv.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-boating",
   "metadata": {},
   "source": [
    "## core / window.py / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-coupon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fleet-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_to_day_mean(array):\n",
    "    time = 24\n",
    "    array = array.reshape((array.shape[0], array.shape[1] // time, time, array.shape[2]))\n",
    "    array = array.mean(2)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "initial-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compa(model=None,df = None, plot_col=0, input_width=7*24, label_width=5*24, target_std=None, target_mean=None, predict_day=4):\n",
    "    \n",
    "    print(df.shape)\n",
    "    print(plot_col)\n",
    "    \n",
    "    width = input_width + label_width\n",
    "    \n",
    "    length = df.shape[0]\n",
    "    length -= width\n",
    "    \n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(length):\n",
    "        dataset = df.iloc[i:i+width].to_numpy()\n",
    "        input = dataset[:input_width]\n",
    "        label = dataset[input_width:, plot_col:plot_col+1]\n",
    "        \n",
    "        input = input.reshape((-1,)+input.shape)\n",
    "        label = label.reshape((-1,)+label.shape)\n",
    "        \n",
    "        inputs.append(input)\n",
    "        labels.append(label)\n",
    "        \n",
    "    inputs = np.concatenate(inputs, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    print(inputs.shape)\n",
    "    predictions = model(inputs)\n",
    "    \n",
    "    inputs_target = inputs[:,:,plot_col:plot_col+1]\n",
    "    \n",
    "    return inputs_target, labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hazardous-queens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3507, 530)\n",
      "2\n",
      "(3219, 168, 530)\n",
      "WARNING:tensorflow:Layer gru is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs, labels, pred = compa(model=gru_model,df=test_df,\n",
    "    plot_col=out_features[0], target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "above-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3219, 168, 1) (3219, 120, 1) (3219, 120, 1)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape, labels.shape, pred.shape)\n",
    "#labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "simplified-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 3216 3217 3218]\n",
      "[ 168  169  170 ... 3384 3385 3386]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504a84f0227c4b73b42ea1c6ee34b90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5a78032bd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = inputs.shape[0]\n",
    "input_index = np.array(range(length))\n",
    "label_index = input_index + 24*7\n",
    "    \n",
    "print(input_index)\n",
    "print(label_index)\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(input_index, inputs[:, 0, :], label='input')\n",
    "plt.plot(label_index, labels[:, 0, :], label='label')\n",
    "plt.plot(label_index, pred[:, 0, :], label='pred')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-worth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-sterling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-camel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-scene",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "curious-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_to_day_mean(array):\n",
    "    time = 24\n",
    "    array = array.reshape((array.shape[0], array.shape[1] // time, time, array.shape[2]))\n",
    "    array = array.mean(2)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "perfect-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compa(model=None,df = None, plot_col=0, input_width=7*24, label_width=5*24, target_std=None, target_mean=None, predict_day=4):\n",
    "    \n",
    "    #print(df.shape)\n",
    "    #print(plot_col)\n",
    "    \n",
    "    width = input_width + label_width\n",
    "    \n",
    "    length = df.shape[0]\n",
    "    length -= width\n",
    "    \n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(0, length, 24):\n",
    "        dataset = df.iloc[i:i+width].to_numpy()\n",
    "        input = dataset[:input_width]\n",
    "        label = dataset[input_width:, plot_col:plot_col+1]\n",
    "        \n",
    "        input = input.reshape((-1,)+input.shape)\n",
    "        label = label.reshape((-1,)+label.shape)\n",
    "        \n",
    "        inputs.append(input)\n",
    "        labels.append(label)\n",
    "        \n",
    "    inputs = np.concatenate(inputs, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    predictions = model(inputs).numpy()\n",
    "    print(predictions.shape)\n",
    "    \n",
    "    predictions = predictions * target_std[plot_col] + target_mean[plot_col]\n",
    "    labels = labels * target_std[plot_col] + target_mean[plot_col]\n",
    "\n",
    "    pred_day = hour_to_day_mean(predictions)\n",
    "    \n",
    "    label_day = hour_to_day_mean(labels)\n",
    "    \n",
    "    inputs_target = inputs[:,:,plot_col:plot_col+1]\n",
    "    inputs_target = inputs_target * target_std[plot_col] + target_mean[plot_col]\n",
    "    inputs_day = hour_to_day_mean(inputs_target)\n",
    "    \n",
    "    #plt.figure(figsize=(10, 800))\n",
    "    \n",
    "    input_index = np.array(range(0, length, 24))\n",
    "    label_index = input_index + 24*7 + predict_day * 24\n",
    "    \n",
    "    #print(input_index)\n",
    "    #print(label_index)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(input_index, inputs_day[:, 0, :], label='input')\n",
    "    plt.plot(label_index, label_day[:, predict_day, :], label='label')\n",
    "    plt.plot(label_index, pred_day[:, predict_day, :], label='pred')\n",
    "    plt.legend()\n",
    "    \n",
    "    print(pred_day.shape)\n",
    "    print(label_day.shape)\n",
    "    \n",
    "    o1 = np.mean(labels)\n",
    "    nse1 = ((label_day - pred_day)**2).sum(axis=0)\n",
    "    nse2 = ((label_day - o1)**2).sum(axis=0)\n",
    "    nse3 = 1 - (nse1[predict_day]/nse2[predict_day])\n",
    "    \n",
    "    pbias1 = (label_day - pred_day).sum(axis=0)\n",
    "    pbias2 = (label_day).sum(axis=0)\n",
    "    pbias3 = (pbias1[predict_day]/pbias2[predict_day])*100\n",
    "    \n",
    "    return nse3, np.abs(pbias3), pred_day, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "solar-stocks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 168, 530)\n",
      "(135, 120, 1)\n",
      "(135, 120, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6df45ba6d5406e8a38ede6383e123b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 5, 1)\n",
      "(135, 5, 1)\n",
      "\n",
      "\n",
      "[0.74340952]\n",
      "[0.64644044]\n"
     ]
    }
   ],
   "source": [
    "val_nse['GUR'], val_pbias['GRU'], pred, label = compa(\n",
    "    model=gru_model,df=test_df, plot_col=out_features[0], target_std=target_std, target_mean=target_mean,\n",
    "    #predict_day = rnn_predict_day)\n",
    "    predict_day = 4)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(val_nse['Linear'])\n",
    "print(val_pbias['Linear'])\n",
    "#print(pred)\n",
    "#print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-pioneer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-tourist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "automated-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_nse['Linear'], val_pbias['Linear'], pred, label = multi_window.compa(\n",
    "     multi_linear_model, plot_col=out_features[0], windows=multi_window.example3,\n",
    "     target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)\n",
    "val_nse['ELMAN'], val_pbias['ELMAN'], pred, label = multi_window.compa(\n",
    "     elman_model, plot_col=out_features[0], windows=multi_window.example3,\n",
    "     target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)\n",
    "val_nse['GRU'], val_pbias['GRU'], pred, label = multi_window.compa(\n",
    "     gru_model, plot_col=out_features[0], windows=multi_window.example3,\n",
    "     target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)\n",
    "val_nse['LSTM'], val_pbias['LSTM'], pred, label = multi_window.compa(\n",
    "     multi_lstm_model, plot_col=out_features[0], windows=multi_window.example3,\n",
    "     target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)\n",
    "val_nse['CONV'], val_pbias['CONV'], pred, label = multi_window.compa(\n",
    "     multi_conv_model, plot_col=out_features[0], windows=multi_window.example3,\n",
    "     target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "foster-effort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model path :  save/han/models/do/\n",
      "year : 2016 ~ 2019\n",
      "run :  range(0, 9)\n",
      "tatget :  do\n",
      "target col index :  2\n",
      "Linear :  0.6888956405233193 3.383958115860465\n",
      "ELMAN :  0.8345927546857886 0.25486962747768166\n",
      "GRU :  0.7519940672240171 0.11684678956706705\n",
      "LSTM :  0.814257637227541 2.1594456597902454\n",
      "CNN :  0.5136420119572949 5.819502649991832\n",
      "GAIN_VAL_PER :  {'0': 0.2664700448513031, '4': 1.2488173246383667, '5': 0.10198544710874557}\n",
      "GAIN_TEST_PER :  {'0': 0.2476963847875595, '4': 0.2624276280403137, '5': 0.09651713073253632}\n"
     ]
    }
   ],
   "source": [
    "print(\"save model path : \", model_path)\n",
    "print(\"year : \" + start_year + \" ~ \"+ end_year)\n",
    "print('run : ', run_num)\n",
    "print('tatget : ', rnn_target_column)\n",
    "print('target col index : ', target_col_idx)\n",
    "print('Linear : ', val_nse['Linear'], val_pbias['Linear'])\n",
    "print('ELMAN : ', val_nse['ELMAN'], val_pbias['ELMAN'])\n",
    "print('GRU : ', val_nse['GRU'], val_pbias['GRU'])\n",
    "print('LSTM : ', val_nse['LSTM'], val_pbias['LSTM'])\n",
    "print('CNN : ', val_nse['CONV'], val_pbias['CONV'])\n",
    "print('GAIN_VAL_PER : ', gain_val_performance)\n",
    "print('GAIN_TEST_PER : ', gain_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "improving-africa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbffd50558f842008d8e42c5cc2ca3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x = np.arange(len(val_nse))\n",
    "width = 0.35\n",
    "plt.figure()\n",
    "plt.title(watershed + '  ['+start_year+','+end_year+']  ' + rnn_target_column)\n",
    "plt.bar(x, val_pbias.values(), 0.3, label='PBIAS' )\n",
    "plt.bar(x + width, val_nse.values(), 0.3, label='NSE')\n",
    "plt.xticks(x,val_nse.keys(), rotation=0)\n",
    "_ = plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-parameter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

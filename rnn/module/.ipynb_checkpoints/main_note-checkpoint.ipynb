{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "skilled-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "from core.gain import *\n",
    "from core.rnn_predic import *\n",
    "from core.models import *\n",
    "from core.util import *\n",
    "#from core.window import WindowGenerator, MissData, make_dataset_water, WaterDataGenerator\n",
    "from core.window import WindowGenerator, make_dataset_gain, make_dataset_water\n",
    "from core.file_open import make_dataframe\n",
    "from core.miss_data import MissData\n",
    "import json\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "needed-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "level-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "parameters_dir = 'input'\n",
    "\n",
    "parameters_file = 'input.json'\n",
    "parameters_path = '{dir}/{file}'.format(dir=parameters_dir, file=parameters_file)\n",
    "\n",
    "with open(parameters_path, encoding='utf8') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "\n",
    "gain_parameters = parameters['gain']\n",
    "rnn_parameters = parameters['rnn']\n",
    "file_parameters = parameters['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fresh-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_path = parameters_dir+'/'+ file_parameters['watershed'] + '.json'\n",
    "with open(parameters_path, encoding='utf8') as json_file:\n",
    "    parameters = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secret-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "plain-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parameters = parameters['data']\n",
    "\n",
    "interpolation_option = data_parameters['interpolation']\n",
    "colum_idx = data_parameters['columns']\n",
    "watershed = data_parameters['watershed']\n",
    "file_names = data_parameters['files']\n",
    "folder = data_parameters['directorys']\n",
    "for i in range(len(folder)):\n",
    "    folder[i] = watershed+folder[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "straight-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "__GAIN_TRAINING__ = gain_parameters['train']\n",
    "gain_epochs = gain_parameters['max_epochs']\n",
    "gain_in_setps = gain_parameters['input_width']\n",
    "gain_out_setps = gain_parameters['label_width']\n",
    "gain_batch_size = gain_parameters['batch_size']\n",
    "gain_fill_no = gain_parameters['fill_width']\n",
    "gain_shift = gain_parameters['shift_width']\n",
    "gain_miss_rate = gain_parameters['miss_rate']\n",
    "\n",
    "__RNN_TRAINING__ = rnn_parameters['train']\n",
    "rnn_epochs = rnn_parameters['max_epochs']\n",
    "rnn_in_setps = rnn_parameters['input_width']\n",
    "rnn_out_steps = rnn_parameters['label_width']\n",
    "rnn_batch_size = rnn_parameters['batch_size']\n",
    "rnn_predict_day = rnn_parameters['predict_day']\n",
    "rnn_target_column = rnn_parameters['target_column']\n",
    "\n",
    "if rnn_predict_day < 3 or rnn_predict_day >5:\n",
    "    print('predict_day err')\n",
    "    exit(88)\n",
    "rnn_predict_day -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-heritage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "patent-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_num = range(len(folder))\n",
    "real_df_all = pd.DataFrame([])\n",
    "target_all = target_mean = target_std = 0\n",
    "\n",
    "gain_val_performance = {}\n",
    "gain_performance = {}\n",
    "\n",
    "length = len(run_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "front-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpol flag :  [False, False]\n",
      "folder :  data/nak/자동/\n",
      "colum_idx :  :,[26,27,28,29,30,31,32,33]\n",
      "file_names[idx] :  [['도개_2016.xlsx', '도개_2017.xlsx', '도개_2018.xlsx', '도개_2019.xlsx'], ['신암_2016.xlsx', '신암_2017.xlsx', '신암_2018.xlsx', '신암_2019.xlsx']]\n",
      "data/nak/자동/도개_2016.xlsx\n",
      "data/nak/자동/도개_2017.xlsx\n",
      "data/nak/자동/도개_2018.xlsx\n",
      "data/nak/자동/도개_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/자동/신암_2016.xlsx\n",
      "data/nak/자동/신암_2017.xlsx\n",
      "data/nak/자동/신암_2018.xlsx\n",
      "data/nak/자동/신암_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "MissData :  save/  miss :  (3967, 12)\n",
      "MissData :  save/  miss :  (3967, 12)\n",
      "1/1 [==============================] - 0s 194ms/step - gen_loss: 110.6778 - disc_loss: 0.7226 - rmse: 1.0142 - val_loss: 0.9133\n",
      "MissData :  save/  miss :  (3967, 12)\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9128\n",
      "MissData :  save/  miss :  (3967, 12)\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/nak/수질/\n",
      "colum_idx :  :,[28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44]\n",
      "file_names[idx] :  [['상주3_2016.xlsx', '상주3_2017.xlsx', '상주3_2018.xlsx', '상주3_2019.xlsx'], ['상주2_2016.xlsx', '상주2_2017.xlsx', '상주2_2018.xlsx', '상주2_2019.xlsx'], ['병성천-1_2016.xlsx', '병성천-1_2017.xlsx', '병성천-1_2018.xlsx', '병성천-1_2019.xlsx']]\n",
      "data/nak/수질/상주3_2016.xlsx\n",
      "data/nak/수질/상주3_2017.xlsx\n",
      "data/nak/수질/상주3_2018.xlsx\n",
      "data/nak/수질/상주3_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/수질/상주2_2016.xlsx\n",
      "data/nak/수질/상주2_2017.xlsx\n",
      "data/nak/수질/상주2_2018.xlsx\n",
      "data/nak/수질/상주2_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/수질/병성천-1_2016.xlsx\n",
      "data/nak/수질/병성천-1_2017.xlsx\n",
      "data/nak/수질/병성천-1_2018.xlsx\n",
      "data/nak/수질/병성천-1_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "interpol flag :  [False, False]\n",
      "folder :  data/nak/보/\n",
      "colum_idx :  :,[26,27]\n",
      "file_names[idx] :  [['낙단보_2016.xlsx', '낙단보_2017.xlsx', '낙단보_2018.xlsx', '낙단보_2019.xlsx'], ['상주보_2016.xlsx', '상주보_2017.xlsx', '상주보_2018.xlsx', '상주보_2019.xlsx']]\n",
      "data/nak/보/낙단보_2016.xlsx\n",
      "data/nak/보/낙단보_2017.xlsx\n",
      "data/nak/보/낙단보_2018.xlsx\n",
      "data/nak/보/낙단보_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/보/상주보_2016.xlsx\n",
      "data/nak/보/상주보_2017.xlsx\n",
      "data/nak/보/상주보_2018.xlsx\n",
      "data/nak/보/상주보_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "MissData :  save/  miss :  (4201, 6)\n",
      "MissData :  save/  miss :  (4201, 6)\n",
      "1/1 [==============================] - 0s 73ms/step - gen_loss: 123.1214 - disc_loss: 0.7249 - rmse: 1.3306 - val_loss: 1.0144\n",
      "MissData :  save/  miss :  (4201, 6)\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9984\n",
      "MissData :  save/  miss :  (4201, 6)\n",
      "interpol flag :  [False, False]\n",
      "folder :  data/nak/유량/\n",
      "colum_idx :  :,[26]\n",
      "file_names[idx] :  [['병성_2016.xlsx', '병성_2017.xlsx', '병성_2018.xlsx', '병성_2019.xlsx']]\n",
      "data/nak/유량/병성_2016.xlsx\n",
      "data/nak/유량/병성_2017.xlsx\n",
      "data/nak/유량/병성_2018.xlsx\n",
      "data/nak/유량/병성_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "MissData :  save/  miss :  (828, 5)\n",
      "MissData :  save/  miss :  (828, 5)\n",
      "1/1 [==============================] - 0s 74ms/step - gen_loss: 167.3594 - disc_loss: 0.7230 - rmse: 1.0099 - val_loss: 0.6181\n",
      "MissData :  save/  miss :  (828, 5)\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4326\n",
      "MissData :  save/  miss :  (828, 5)\n",
      "interpol flag :  [False, False]\n",
      "folder :  data/nak/수위/\n",
      "colum_idx :  :,[26]\n",
      "file_names[idx] :  [['의성군(낙단교)_2016.xlsx', '의성군(낙단교)_2017.xlsx', '의성군(낙단교)_2018.xlsx', '의성군(낙단교)_2019.xlsx'], ['상주시(병성교)_2016.xlsx', '상주시(병성교)_2017.xlsx', '상주시(병성교)_2018.xlsx', '상주시(병성교)_2019.xlsx']]\n",
      "data/nak/수위/의성군(낙단교)_2016.xlsx\n",
      "data/nak/수위/의성군(낙단교)_2017.xlsx\n",
      "data/nak/수위/의성군(낙단교)_2018.xlsx\n",
      "data/nak/수위/의성군(낙단교)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/수위/상주시(병성교)_2016.xlsx\n",
      "data/nak/수위/상주시(병성교)_2017.xlsx\n",
      "data/nak/수위/상주시(병성교)_2018.xlsx\n",
      "data/nak/수위/상주시(병성교)_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "MissData :  save/  miss :  (1281, 5)\n",
      "MissData :  save/  miss :  (1281, 5)\n",
      "1/1 [==============================] - 0s 74ms/step - gen_loss: 129.4764 - disc_loss: 0.7295 - rmse: 1.0521 - val_loss: 1.0272\n",
      "MissData :  save/  miss :  (1281, 5)\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0335\n",
      "MissData :  save/  miss :  (1281, 5)\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/nak/총량/\n",
      "colum_idx :  :,28:45\n",
      "file_names[idx] :  [['상주3_2016.xlsx', '상주3_2017.xlsx', '상주3_2018.xlsx', '상주3_2019.xlsx'], ['위천6_2016.xlsx', '위천6_2017.xlsx', '위천6_2018.xlsx', '위천6_2019.xlsx'], ['병성천-1_2016.xlsx', '병성천-1_2017.xlsx', '병성천-1_2018.xlsx', '병성천-1_2019.xlsx']]\n",
      "data/nak/총량/상주3_2016.xlsx\n",
      "data/nak/총량/상주3_2017.xlsx\n",
      "data/nak/총량/상주3_2018.xlsx\n",
      "data/nak/총량/상주3_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/총량/위천6_2016.xlsx\n",
      "data/nak/총량/위천6_2017.xlsx\n",
      "data/nak/총량/위천6_2018.xlsx\n",
      "data/nak/총량/위천6_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/총량/병성천-1_2016.xlsx\n",
      "data/nak/총량/병성천-1_2017.xlsx\n",
      "data/nak/총량/병성천-1_2018.xlsx\n",
      "data/nak/총량/병성천-1_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/nak/퇴적물/\n",
      "colum_idx :  :,[27,28,29,30,31,33]\n",
      "file_names[idx] :  [['낙단_2016.xlsx', '낙단_2017.xlsx', '낙단_2018.xlsx', '낙단_2019.xlsx'], ['낙단U_2016.xlsx', '낙단U_2017.xlsx', '낙단U_2018.xlsx', '낙단U_2019.xlsx'], ['도남_2016.xlsx', '도남_2017.xlsx', '도남_2018.xlsx', '도남_2019.xlsx']]\n",
      "data/nak/퇴적물/낙단_2016.xlsx\n",
      "data/nak/퇴적물/낙단_2017.xlsx\n",
      "data/nak/퇴적물/낙단_2018.xlsx\n",
      "data/nak/퇴적물/낙단_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/퇴적물/낙단U_2016.xlsx\n",
      "data/nak/퇴적물/낙단U_2017.xlsx\n",
      "data/nak/퇴적물/낙단U_2018.xlsx\n",
      "data/nak/퇴적물/낙단U_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/퇴적물/도남_2016.xlsx\n",
      "data/nak/퇴적물/도남_2017.xlsx\n",
      "data/nak/퇴적물/도남_2018.xlsx\n",
      "data/nak/퇴적물/도남_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/nak/TMS/\n",
      "colum_idx :  :,[27,28,30,31,32,33,35]\n",
      "file_names[idx] :  [['안동천연가스건설_2016.xlsx', '안동천연가스건설_2017.xlsx', '안동천연가스건설_2018.xlsx', '안동천연가스건설_2019.xlsx'], ['의성다인하수_2016.xlsx', '의성다인하수_2017.xlsx', '의성다인하수_2018.xlsx', '의성다인하수_2019.xlsx'], ['상주하수_2016.xlsx', '상주하수_2017.xlsx', '상주하수_2018.xlsx', '상주하수_2019.xlsx']]\n",
      "data/nak/TMS/안동천연가스건설_2016.xlsx\n",
      "data/nak/TMS/안동천연가스건설_2017.xlsx\n",
      "data/nak/TMS/안동천연가스건설_2018.xlsx\n",
      "data/nak/TMS/안동천연가스건설_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/TMS/의성다인하수_2016.xlsx\n",
      "data/nak/TMS/의성다인하수_2017.xlsx\n",
      "data/nak/TMS/의성다인하수_2018.xlsx\n",
      "data/nak/TMS/의성다인하수_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/TMS/상주하수_2016.xlsx\n",
      "data/nak/TMS/상주하수_2017.xlsx\n",
      "data/nak/TMS/상주하수_2018.xlsx\n",
      "data/nak/TMS/상주하수_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/nak/조류/\n",
      "colum_idx :  :,[30,32,34,36,38,41,46,47,50]\n",
      "file_names[idx] :  [['낙단보_2016.xlsx', '낙단보_2017.xlsx', '낙단보_2018.xlsx', '낙단보_2019.xlsx'], ['상주보_2016.xlsx', '상주보_2017.xlsx', '상주보_2018.xlsx', '상주보_2019.xlsx']]\n",
      "data/nak/조류/낙단보_2016.xlsx\n",
      "data/nak/조류/낙단보_2017.xlsx\n",
      "data/nak/조류/낙단보_2018.xlsx\n",
      "data/nak/조류/낙단보_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "data/nak/조류/상주보_2016.xlsx\n",
      "data/nak/조류/상주보_2017.xlsx\n",
      "data/nak/조류/상주보_2018.xlsx\n",
      "data/nak/조류/상주보_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/nak/방사성/\n",
      "colum_idx :  :,[28,29]\n",
      "file_names[idx] :  [['상주3_2016.xlsx', '상주3_2017.xlsx', '상주3_2018.xlsx', '상주3_2019.xlsx']]\n",
      "data/nak/방사성/상주3_2016.xlsx\n",
      "data/nak/방사성/상주3_2017.xlsx\n",
      "data/nak/방사성/상주3_2018.xlsx\n",
      "data/nak/방사성/상주3_2019.xlsx\n",
      "time range in files :  2016-01-01 00:00  ~  2019-12-31 23:00\n"
     ]
    }
   ],
   "source": [
    "for i in range(length):\n",
    "\n",
    "    idx = run_num[i]\n",
    "\n",
    "    print('interpol flag : ', interpolation_option[idx])\n",
    "    print('folder : ', data_path + folder[idx])\n",
    "    print('colum_idx : ', colum_idx[idx])\n",
    "    print('file_names[idx] : ', file_names[idx])\n",
    "\n",
    "    #start = time.time()\n",
    "\n",
    "    #if watershed == '한강_12days_test':\n",
    "    #    df, times = make_dataframe_temp_12days(folder[idx], file_names[idx], colum_idx[idx], interpolate=interpolation_option[idx])\n",
    "    #else:\n",
    "    df, times = make_dataframe(data_path+folder[idx], file_names[idx], colum_idx[idx], interpolation=interpolation_option[idx])\n",
    "\n",
    "    df_all, train_mean, train_std, df = normalize(df)\n",
    "\n",
    "\n",
    "\n",
    "    if i == 0:\n",
    "        dfff = df\n",
    "        target_all = df_all\n",
    "        target_std = train_std\n",
    "        target_mean = train_mean\n",
    "        start_year = str(times.iloc[0].year)\n",
    "        end_year = str(times.iloc[-1].year)\n",
    "\n",
    "    if interpolation_option[idx][0] == False:\n",
    "\n",
    "        loadfiles = ['idx.npy', 'miss.npy', 'discriminator.h5', 'generator.h5']\n",
    "\n",
    "        gain_calc_falg = True\n",
    "\n",
    "        if __GAIN_TRAINING__ == True:\n",
    "            gain_calc_falg = MissData.save(pd.concat(df, axis=0).to_numpy(), max_tseq=24, save_dir='save/')\n",
    "            #print(folder[idx], ': training ', 'Miss date save : ', gain_calc_falg)\n",
    "        else:\n",
    "            for file in loadfiles:\n",
    "                if os.path.isfile('save/' + folder[idx]+file):\n",
    "                    shutil.copyfile('save/' + folder[idx]+file, 'save/'+file)\n",
    "                    #print('load file name : save/' + folder[idx]+file)\n",
    "                else:\n",
    "                    if file == 'miss.npy':\n",
    "                        gain_calc_falg = MissData.save(pd.concat(df, axis=0).to_numpy(), max_tseq=24, save_dir='save/')\n",
    "                        #print(folder[idx], ': is not miss.npy ', 'Miss date save : ', gain_calc_falg)\n",
    "\n",
    "        if gain_calc_falg == True:\n",
    "            #print('GainWindowGenerator in main')\n",
    "            WindowGenerator.make_dataset = make_dataset_gain\n",
    "            wide_window = WindowGenerator(input_width=gain_in_setps, label_width=gain_out_setps, shift=gain_shift,\n",
    "                                          fill_no=gain_fill_no, miss_rate=gain_miss_rate, batch_size=gain_batch_size,\n",
    "                                          train_df = df_all, val_df = df_all, test_df = df_all, df = df)\n",
    "\n",
    "            #gain = model_GAIN(shape=wide_window.dg.shape[1:], gen_sigmoid=False, epochs=gain_epochs, training_flag=__GAIN_TRAINING__, window=wide_window, model_save_path='save/')\n",
    "            gain = model_GAIN(shape=(gain_in_setps, df_all.shape[1]), gen_sigmoid=False, epochs=gain_epochs,\n",
    "                              training_flag=__GAIN_TRAINING__, window=wide_window, model_save_path='save/')\n",
    "\n",
    "            gain_val_performance[str(i)] = gain.evaluate(wide_window.val)\n",
    "            gain_performance[str(i)] = gain.evaluate(wide_window.test, verbose=0)\n",
    "\n",
    "            #print('file proc in main')\n",
    "            if __GAIN_TRAINING__ == True:\n",
    "                #dir = 'save/'+folder[i]\n",
    "                if not os.path.exists('save/' + folder[idx]):\n",
    "                    os.makedirs('save/'+folder[idx])\n",
    "                for file in loadfiles:\n",
    "                    shutil.copyfile('save/' + file, 'save/' + folder[idx] + file)\n",
    "\n",
    "            #print('create_dataset_with_gain in main')\n",
    "            #ori, gan = create_dataset_with_gain(gain=gain, window=wide_window, df=df)\n",
    "            ori, gan = create_dataset_with_gain(gain=gain, shape=(gain_in_setps, df_all.shape[1]), df=df)\n",
    "\n",
    "        else:\n",
    "            gan = create_dataset_interpol(window=gain_in_setps, df=df)\n",
    "    else:\n",
    "        gan = create_dataset_interpol(window=gain_in_setps, df=df)\n",
    "\n",
    "    if i == 0 :\n",
    "#        if i < length -1:\n",
    "#            gan = gan[:,:-4]  #맨마지막전까지 사인코사인삭제\n",
    "#            print(gan.shape)\n",
    "        real_df_all = pd.DataFrame(gan)\n",
    "    else:\n",
    "#        if i < length -1:\n",
    "#            gan = gan[:,:-4]  #맨마지막전까지 사인코사인삭제\n",
    "#            print(gan.shape)\n",
    "        real_df_all = pd.concat([real_df_all, pd.DataFrame(gan)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "different-cornwall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35064, 269)\n"
     ]
    }
   ],
   "source": [
    "print(real_df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rental-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df, test_df2 = dataset_slice(real_df_all, 0.8, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "homeless-wholesale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------prediction\n",
      "-------------------prediction\n",
      "-------------------prediction\n",
      "real_df_all.type :  <class 'pandas.core.frame.DataFrame'>\n",
      "train_df.type :  <class 'pandas.core.frame.DataFrame'>\n",
      "train_df.shape :  (28051, 269) val_df.shape :  (3506, 269) test_df.shape: (3507, 269)\n"
     ]
    }
   ],
   "source": [
    "print('-------------------prediction')\n",
    "print('-------------------prediction')\n",
    "print('-------------------prediction')\n",
    "\n",
    "print('real_df_all.type : ', type(real_df_all))\n",
    "print('train_df.type : ', type(train_df))\n",
    "print('train_df.shape : ', train_df.shape, 'val_df.shape : ', val_df.shape, 'test_df.shape:' ,test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "provincial-holocaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_columns_indices:\n",
      "{'tmpr_value': 0, 'ph_value': 1, 'do_value': 2, 'ec_value': 3, 'toc_value': 4, '총질소_값': 5, '총인_값': 6, '클로로필-a_값': 7, 'Day sin': 8, 'Day cos': 9, 'Year sin': 10, 'Year cos': 11}\n",
      "target columns :  do\n",
      "target_col_idx :  2\n",
      "out_num_features :  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_columns_indices = {name: i for i, name in enumerate(dfff[0])}\n",
    "\n",
    "print(\"label_columns_indices:\")\n",
    "print(label_columns_indices)\n",
    "\n",
    "\n",
    "target_dic = {\"do\":\"do_value\", \"toc\":\"toc_value\", \"tn\":\"총질소_값\", \"tp\":\"총인_값\", \"chl-a\":\"클로로필-a_값\"}\n",
    "\n",
    "print('target columns : ', rnn_target_column)\n",
    "num_features = dfff[0].shape[1]\n",
    "\n",
    "target_col_idx = label_columns_indices[target_dic[rnn_target_column]]\n",
    "out_features = [target_col_idx]\n",
    "out_num_features = len(out_features)\n",
    "\n",
    "print(\"target_col_idx : \", target_col_idx)\n",
    "print('out_num_features : ', out_num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "robust-partnership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model path :  save/nak/models/do/\n"
     ]
    }
   ],
   "source": [
    "val_nse = {}\n",
    "val_pbias = {}\n",
    "\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset_water\n",
    "multi_window = WindowGenerator(\n",
    "    input_width=rnn_in_setps,label_width=rnn_out_steps, shift=rnn_out_steps,out_features=out_features,\n",
    "    out_num_features=out_num_features,label_columns=dfff[0].columns, batch_size=rnn_batch_size,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df, test_df2=test_df2)\n",
    "\n",
    "if __RNN_TRAINING__:\n",
    "    if not os.path.exists('save/' + watershed):\n",
    "        os.makedirs('save/' + watershed)\n",
    "\n",
    "\n",
    "idx = [2, 4, 5, 6, 7]\n",
    "pa = [\"do/\", \"toc/\", \"nitrogen/\", \"phosphorus/\", \"chlorophyll-a/\"]\n",
    "\n",
    "indices = {name: i for i, name in enumerate(idx)}\n",
    "\n",
    "model_path = \"save/\" + watershed + \"models/\" + pa[indices[target_col_idx]]\n",
    "print(\"save model path : \", model_path)\n",
    "\n",
    "val_nse = {}\n",
    "val_pbias = {}\n",
    "\n",
    " # +\"gru.ckpt\" -- path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-davis",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "virgin-china",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x7f378c97df80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "      1/Unknown - 0s 34us/step - loss: 0.9579 - mean_absolute_error: 0.7746WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f3787fe3cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 490ms/step - loss: 0.9579 - mean_absolute_error: 0.7746 - val_loss: 0.2278 - val_mean_absolute_error: 0.3714\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x7f378ceec320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "      1/Unknown - 0s 34us/step - loss: 1.0813 - mean_absolute_error: 0.8502WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f378ccc9710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 521ms/step - loss: 1.0813 - mean_absolute_error: 0.8502 - val_loss: 0.2493 - val_mean_absolute_error: 0.3999\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_train_function.<locals>.train_function at 0x7f37878dc320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "      1/Unknown - 0s 53us/step - loss: 0.9383 - mean_absolute_error: 0.7871WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7f367475fa70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 547ms/step - loss: 0.9383 - mean_absolute_error: 0.7871 - val_loss: 0.2506 - val_mean_absolute_error: 0.3982\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x7f36c432e440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "      1/Unknown - 0s 32us/step - loss: 0.8231 - mean_absolute_error: 0.7342WARNING:tensorflow:7 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f367429d440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 0.8231 - mean_absolute_error: 0.7342 - val_loss: 0.2772 - val_mean_absolute_error: 0.4185\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_train_function.<locals>.train_function at 0x7f36c40ae680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "      1/Unknown - 0s 39us/step - loss: 1.0517 - mean_absolute_error: 0.8271WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f36c41eaef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1/1 [==============================] - 1s 501ms/step - loss: 1.0517 - mean_absolute_error: 0.8271 - val_loss: 0.2583 - val_mean_absolute_error: 0.3953\n"
     ]
    }
   ],
   "source": [
    "multi_linear_model = model_multi_linear(\n",
    "    window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "    #training_flag=__RNN_TRAINING__, checkpoint_path=\"save/\"+watershed+\"models/multi_linear.ckpt\")\n",
    "    training_flag=__RNN_TRAINING__, checkpoint_path=model_path+\"multi_linear.ckpt\")\n",
    "elman_model = model_elman(\n",
    "    window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "    training_flag=__RNN_TRAINING__, checkpoint_path=model_path+\"elman.ckpt\")\n",
    "gru_model = model_gru(\n",
    "    window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "    training_flag=__RNN_TRAINING__, checkpoint_path=model_path+\"gru.ckpt\")\n",
    "multi_lstm_model = model_multi_lstm(\n",
    "    window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "    training_flag=__RNN_TRAINING__, checkpoint_path=model_path+\"multi_lstm.ckpt\")\n",
    "multi_conv_model = model_multi_conv(\n",
    "    window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "    training_flag=__RNN_TRAINING__, checkpoint_path=model_path+\"multi_conv.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-bones",
   "metadata": {},
   "source": [
    "## core / window.py / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "southern-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_to_day_mean(array):\n",
    "    time = 24\n",
    "    array = array.reshape((array.shape[0], array.shape[1] // time, time, array.shape[2]))\n",
    "    array = array.mean(2)\n",
    "    return array\n",
    "\n",
    "def compa(model=None,df = None, plot_col=0, input_width=7*24, label_width=5*24, target_std=None, target_mean=None, predict_day=4):\n",
    "    \n",
    "    print(df.shape)\n",
    "    \n",
    "    width = input_width + label_width\n",
    "    \n",
    "    length = df.shape[0]\n",
    "    length -= width\n",
    "    \n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(length):\n",
    "        dataset = df.iloc[i:i+width].to_numpy()\n",
    "        input = dataset[:input_width]\n",
    "        label = dataset[input_width:, plot_col:plot_col+1]\n",
    "        \n",
    "        input = input.reshape((-1,)+input.shape)\n",
    "        label = label.reshape((-1,)+label.shape)\n",
    "        \n",
    "        inputs.append(input)\n",
    "        labels.append(label)\n",
    "        \n",
    "    inputs = np.concatenate(inputs, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    predictions = model(inputs)\n",
    "    print(predictions.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    predictions = predictions.numpy() * target_std[plot_col] + target_mean[plot_col]\n",
    "    labels = labels * target_std[plot_col] + target_mean[plot_col]\n",
    "\n",
    "    pred_day = hour_to_day_mean(predictions)\n",
    "    label_day = hour_to_day_mean(labels)\n",
    "    \n",
    "    print(pred_day.shape)\n",
    "    print(label_day.shape)\n",
    "    \n",
    "    o1 = np.mean(labels)\n",
    "    nse1 = ((label_day - pred_day)**2).sum(axis=0)\n",
    "    nse2 = ((label_day - o1)**2).sum(axis=0)\n",
    "    nse3 = 1 - (nse1[predict_day]/nse2[predict_day])\n",
    "    \n",
    "    pbias1 = (label_day - pred_day).sum(axis=0)\n",
    "    pbias2 = (label_day).sum(axis=0)\n",
    "    pbias3 = (pbias1[predict_day]/pbias2[predict_day])*100\n",
    "    \n",
    "    return nse3, np.abs(pbias3), pred_day, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "tracked-costume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3507, 269)\n",
      "(3219, 168, 269)\n",
      "(3219, 120, 1)\n",
      "(3219, 120, 1)\n",
      "(3219, 5, 1)\n",
      "(3219, 5, 1)\n",
      "\n",
      "\n",
      "[-0.05102824]\n",
      "[4.00389567]\n",
      "[[[10.092263]\n",
      "  [10.057929]\n",
      "  [10.048203]\n",
      "  [10.07513 ]\n",
      "  [10.09616 ]]\n",
      "\n",
      " [[10.096898]\n",
      "  [10.068516]\n",
      "  [10.062088]\n",
      "  [10.082856]\n",
      "  [10.100906]]\n",
      "\n",
      " [[10.097118]\n",
      "  [10.076479]\n",
      "  [10.074333]\n",
      "  [10.087087]\n",
      "  [10.101193]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[10.605725]\n",
      "  [10.564545]\n",
      "  [10.549426]\n",
      "  [10.572507]\n",
      "  [10.595583]]\n",
      "\n",
      " [[10.607627]\n",
      "  [10.572167]\n",
      "  [10.560718]\n",
      "  [10.577658]\n",
      "  [10.597819]]\n",
      "\n",
      " [[10.626492]\n",
      "  [10.598893]\n",
      "  [10.591389]\n",
      "  [10.600314]\n",
      "  [10.616399]]]\n",
      "[[[ 9.79000001]\n",
      "  [ 9.57667001]\n",
      "  [ 9.41667001]\n",
      "  ...\n",
      "  [12.95999993]\n",
      "  [12.81333014]\n",
      "  [12.41917   ]]\n",
      "\n",
      " [[ 9.57667001]\n",
      "  [ 9.41667001]\n",
      "  [ 9.12083   ]\n",
      "  ...\n",
      "  [12.81333014]\n",
      "  [12.41917   ]\n",
      "  [12.52167005]]\n",
      "\n",
      " [[ 9.41667001]\n",
      "  [ 9.12083   ]\n",
      "  [ 9.07999999]\n",
      "  ...\n",
      "  [12.41917   ]\n",
      "  [12.52167005]\n",
      "  [12.36167005]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 9.73167   ]\n",
      "  [ 9.73917   ]\n",
      "  [ 9.77250001]\n",
      "  ...\n",
      "  [10.05749999]\n",
      "  [10.06250001]\n",
      "  [10.06167   ]]\n",
      "\n",
      " [[ 9.73917   ]\n",
      "  [ 9.77250001]\n",
      "  [ 9.76917001]\n",
      "  ...\n",
      "  [10.06250001]\n",
      "  [10.06167   ]\n",
      "  [10.04667001]]\n",
      "\n",
      " [[ 9.77250001]\n",
      "  [ 9.76917001]\n",
      "  [ 9.79000001]\n",
      "  ...\n",
      "  [10.06167   ]\n",
      "  [10.04667001]\n",
      "  [10.03833001]]]\n"
     ]
    }
   ],
   "source": [
    "val_nse['Linear'], val_pbias['Linear'], pred, label = compa(\n",
    "    model=multi_linear_model,df=test_df,\n",
    "    plot_col=out_features[0], target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(val_nse['Linear'])\n",
    "print(val_pbias['Linear'])\n",
    "print(pred)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-fighter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-prague",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-asbestos",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-exercise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-window",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-economics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "taken-effect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07809746265411377\n",
      "3.786558285355568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.0780974074162133, 3.7865572143491164)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_nse['Linear'], val_pbias['Linear'], pred, label = multi_window.compa(\n",
    "     multi_linear_model, plot_col=out_features[0], windows=multi_window.example3,\n",
    "     target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)\n",
    "\n",
    "val_nse['Linear'], val_pbias['Linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-japan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-advertiser",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "experienced-sellers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146.26598  133.33546  107.28667  118.575134 124.37179 ]\n",
      "[134.41826 123.35732  98.18045 110.81671 114.09221]\n",
      "-0.09009885787963867\n",
      "[130.71611  141.83789  124.887764 139.40192  132.2336  ]\n",
      "[109.20328  127.29116  113.71104  125.805954 119.22199 ]\n",
      "-0.1091376543045044\n",
      "[120.30303  104.23574  122.72825  114.753716 130.8842  ]\n",
      "[ 97.24309   91.461426 112.65303   97.301895 111.72922 ]\n",
      "-0.17144107818603516\n",
      "[151.94402 154.08969 138.0146  126.34219 139.06163]\n",
      "[130.78513  129.44556  126.98188  118.807236 118.67969 ]\n",
      "-0.1717391014099121\n",
      "[148.90193 154.90924 114.33689 128.76678 119.45164]\n",
      "[148.7929  150.57416 109.0241  127.86395 121.46621]\n",
      "0.016585469245910645\n"
     ]
    }
   ],
   "source": [
    "val_nse['Linear'], val_pbias['Linear'], pred, label = multi_window.compa(\n",
    "     multi_linear_model, plot_col=out_features[0], windows=multi_window.example3,\n",
    "     target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)\n",
    "val_nse['ELMAN'], val_pbias['ELMAN'], pred, label = multi_window.compa(\n",
    "     elman_model, plot_col=out_features[0], windows=multi_window.example3,\n",
    "     target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)\n",
    "val_nse['GRU'], val_pbias['GRU'], pred, label = multi_window.compa(\n",
    "     gru_model, plot_col=out_features[0], windows=multi_window.example3,\n",
    "     target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)\n",
    "val_nse['LSTM'], val_pbias['LSTM'], pred, label = multi_window.compa(\n",
    "     multi_lstm_model, plot_col=out_features[0], windows=multi_window.example3,\n",
    "     target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)\n",
    "val_nse['CONV'], val_pbias['CONV'], pred, label = multi_window.compa(\n",
    "     multi_conv_model, plot_col=out_features[0], windows=multi_window.example3,\n",
    "     target_std=target_std, target_mean=target_mean, predict_day = rnn_predict_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "collective-timeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model path :  save/nak/models/do/\n",
      "year : 2016 ~ 2019\n",
      "run :  range(0, 10)\n",
      "tatget :  do\n",
      "target col index :  2\n",
      "Linear :  -0.033300107689041125 3.7408505781293537\n",
      "ELMAN :  -0.08320734996370893 3.6169399112087413\n",
      "GRU :  -0.18778040951093034 4.93887837152724\n",
      "LSTM :  -0.1554341121067051 4.64866745872777\n",
      "CNN :  -0.18837036444153488 5.621612891607546\n",
      "GAIN_VAL_PER :  {'0': 0.9128366112709045, '2': 0.9984226822853088, '3': 0.43262776732444763, '4': 1.033467411994934}\n",
      "GAIN_TEST_PER :  {'0': 0.9263740181922913, '2': 1.006889820098877, '3': 1.8827637434005737, '4': 0.9874472618103027}\n"
     ]
    }
   ],
   "source": [
    "print(\"save model path : \", model_path)\n",
    "print(\"year : \" + start_year + \" ~ \"+ end_year)\n",
    "print('run : ', run_num)\n",
    "print('tatget : ', rnn_target_column)\n",
    "print('target col index : ', target_col_idx)\n",
    "print('Linear : ', val_nse['Linear'], val_pbias['Linear'])\n",
    "print('ELMAN : ', val_nse['ELMAN'], val_pbias['ELMAN'])\n",
    "print('GRU : ', val_nse['GRU'], val_pbias['GRU'])\n",
    "print('LSTM : ', val_nse['LSTM'], val_pbias['LSTM'])\n",
    "print('CNN : ', val_nse['CONV'], val_pbias['CONV'])\n",
    "print('GAIN_VAL_PER : ', gain_val_performance)\n",
    "print('GAIN_TEST_PER : ', gain_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "chief-smith",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x = np.arange(len(val_nse))\n",
    "width = 0.35\n",
    "plt.figure()\n",
    "plt.title(watershed + '  ['+start_year+','+end_year+']  ' + rnn_target_column)\n",
    "plt.bar(x, val_pbias.values(), 0.3, label='PBIAS' )\n",
    "plt.bar(x + width, val_nse.values(), 0.3, label='NSE')\n",
    "plt.xticks(x,val_nse.keys(), rotation=0)\n",
    "_ = plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-revision",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

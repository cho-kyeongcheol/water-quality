{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bored-conservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "from core.gain import *\n",
    "from core.rnn_predic import *\n",
    "from core.models import *\n",
    "from core.util import *\n",
    "#from core.window import WindowGenerator, MissData, make_dataset_water, WaterDataGenerator\n",
    "from core.window import WindowGenerator, make_dataset_gain, make_dataset_water\n",
    "from core.file_open import make_dataframe\n",
    "from core.miss_data import MissData\n",
    "import json\n",
    "%matplotlib widget\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instant-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_to_day_mean(array):\n",
    "    time = 24\n",
    "    array = array.reshape((array.shape[0], array.shape[1] // time, time, array.shape[2]))\n",
    "    array = array.mean(2)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "outstanding-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compa(model=None,df = None, plot_col=0, input_width=7*24, label_width=5*24, target_std=None, target_mean=None, predict_day=4):\n",
    "    width = input_width + label_width\n",
    "    length = df.shape[0] - width\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(0, length, 24):\n",
    "        dataset = df.iloc[i:i+width].to_numpy()\n",
    "        input = dataset[:input_width]\n",
    "        label = dataset[input_width:, plot_col:plot_col+1]\n",
    "        \n",
    "        input = input.reshape((-1,)+input.shape)\n",
    "        label = label.reshape((-1,)+label.shape)\n",
    "        \n",
    "        inputs.append(input)\n",
    "        labels.append(label)\n",
    "        \n",
    "        \n",
    "    inputs = np.concatenate(inputs, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "\n",
    "    predictions = model(inputs).numpy()\n",
    "    \n",
    "    predictions = predictions * target_std[plot_col] + target_mean[plot_col]\n",
    "    labels = labels * target_std[plot_col] + target_mean[plot_col]\n",
    "\n",
    "    pred_day = hour_to_day_mean(predictions)\n",
    "    \n",
    "    label_day = hour_to_day_mean(labels)\n",
    "    \n",
    "    inputs_target = inputs[:,:,plot_col:plot_col+1]\n",
    "    inputs_target = inputs_target * target_std[plot_col] + target_mean[plot_col]\n",
    "    inputs_day = hour_to_day_mean(inputs_target)\n",
    "    \n",
    "    plt.figure()\n",
    "    #input_index = np.array(range(0, length, 24))\n",
    "    input_index = np.array(range(inputs_day.shape[0]))\n",
    "    #label_index = input_index + 24* (7 + predict_day)\n",
    "    label_index = input_index + (7 + predict_day)\n",
    "    plt.plot(input_index, inputs_day[:, 0, :], label='input')\n",
    "    plt.plot(label_index, label_day[:, predict_day, :], label='label')\n",
    "    plt.plot(label_index, pred_day[:, predict_day, :], label='pred')\n",
    "    plt.legend()\n",
    "    #plt.savefig('test_plt.png')\n",
    "    \n",
    "    o1 = np.mean(label_day[:,predict_day,:])\n",
    "    nse1 = ((label_day - pred_day)**2).sum(axis=0)\n",
    "    nse2 = ((label_day - o1)**2).sum(axis=0)\n",
    "    nse3 = 1 - (nse1[predict_day]/nse2[predict_day])\n",
    "    pbias1 = (label_day - pred_day).sum(axis=0)\n",
    "    pbias2 = (label_day).sum(axis=0)\n",
    "    pbias3 = (pbias1[predict_day]/pbias2[predict_day])*100\n",
    "    \n",
    "    \n",
    "    labels_test = labels.mean(axis=1)\n",
    "    predis_test = inputs_target.mean(axis=1)\n",
    "    \n",
    "    nse2_1 = ((labels_test - predis_test)**2).sum()\n",
    "    nse2_2 = ((labels_test - o1)**2).sum()\n",
    "    nse2_3 = 1 - (nse2_1/nse2_2)\n",
    "    \n",
    "    pbias2_1 = (labels_test - predis_test).sum()\n",
    "    pbias2_2 = labels_test.sum()\n",
    "    pbias2_3 = pbias2_1/pbias2_2 * 100\n",
    "    \n",
    "    mae = (np.abs(label_day - pred_day)).mean()\n",
    "    mse = ((label_day - pred_day)**2).mean()\n",
    "    rmse = np.sqrt(((label_day - pred_day)**2).mean())\n",
    "    \n",
    "    o_ = np.mean(label_day[:,predict_day,:])\n",
    "    p_ = np.mean(pred_day[:,predict_day,:])\n",
    "    \n",
    "    oi = label_day[:,predict_day,:]\n",
    "    pi = pred_day[:,predict_day,:]\n",
    "    \n",
    "    high = ((oi-o_)*(pi-p_)).sum()\n",
    "    low = np.sqrt( ( (oi-o_)**2 ).sum() )\n",
    "    low = low * np.sqrt( ( (pi-p_)**2 ).sum() )\n",
    "    \n",
    "    R = high/low\n",
    "    RS = (R)**2\n",
    "    \n",
    "    return nse3, pbias3, pred_day, labels, mae, rmse, RS, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "offensive-spider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "norman-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "parameters_dir = 'input'\n",
    "\n",
    "parameters_file = 'input.json'\n",
    "parameters_path = '{dir}/{file}'.format(dir=parameters_dir, file=parameters_file)\n",
    "\n",
    "with open(parameters_path, encoding='utf8') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "\n",
    "gain_parameters = parameters['gain']\n",
    "rnn_parameters = parameters['rnn']\n",
    "file_parameters = parameters['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defensive-traffic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'han_pull'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_parameters['watershed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unlimited-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_path = parameters_dir+'/'+ file_parameters['watershed'] + '.json'\n",
    "with open(parameters_path, encoding='utf8') as json_file:\n",
    "    parameters = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "changed-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alternate-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parameters = parameters['data']\n",
    "\n",
    "interpolation_option = data_parameters['interpolation']\n",
    "colum_idx = data_parameters['columns']\n",
    "watershed = data_parameters['watershed']\n",
    "file_names = data_parameters['files']\n",
    "folder = data_parameters['directorys']\n",
    "for i in range(len(folder)):\n",
    "    folder[i] = watershed+folder[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "committed-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "__GAIN_TRAINING__ = gain_parameters['train']\n",
    "gain_epochs = gain_parameters['max_epochs']\n",
    "gain_in_setps = gain_parameters['input_width']\n",
    "gain_out_setps = gain_parameters['label_width']\n",
    "gain_batch_size = gain_parameters['batch_size']\n",
    "gain_fill_no = gain_parameters['fill_width']\n",
    "gain_shift = gain_parameters['shift_width']\n",
    "gain_miss_rate = gain_parameters['miss_rate']\n",
    "\n",
    "__RNN_TRAINING__ = rnn_parameters['train']\n",
    "rnn_epochs = rnn_parameters['max_epochs']\n",
    "rnn_in_setps = rnn_parameters['input_width']\n",
    "rnn_out_steps = rnn_parameters['label_width']\n",
    "rnn_batch_size = rnn_parameters['batch_size']\n",
    "rnn_predict_day = rnn_parameters['predict_day']\n",
    "rnn_target_column = rnn_parameters['target_column']\n",
    "\n",
    "if rnn_predict_day < 3 or rnn_predict_day >5:\n",
    "    print('predict_day err')\n",
    "    exit(88)\n",
    "rnn_predict_day -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "powered-sixth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 2000, True, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__GAIN_TRAINING__, gain_epochs ,__RNN_TRAINING__, rnn_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suspected-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_num = range(len(folder))\n",
    "#run_num = [0]\n",
    "#if file_parameters['watershed'] == 'nak':\n",
    "#    run_num = range(len(folder))\n",
    "#else:\n",
    "#    run_num = [0]\n",
    "\n",
    "__GAIN_TRAINING__ = False\n",
    "\n",
    "real_df_all = pd.DataFrame([])\n",
    "target_all = target_mean = target_std = 0\n",
    "\n",
    "gain_val_performance = {}\n",
    "gain_performance = {}\n",
    "\n",
    "length = len(run_num)\n",
    "\n",
    "ddday = 31\n",
    "mmmonth = 12\n",
    "\n",
    "#length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "undefined-sperm",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interpol flag :  [False, False]\n",
      "folder :  data/han/자동/\n",
      "colum_idx :  :,[26,27,28,29,30,31,32,33]\n",
      "file_names[idx] :  [['가평_2016.xlsx', '가평_2017.xlsx', '가평_2018.xlsx'], ['서상_2016.xlsx', '서상_2017.xlsx', '서상_2018.xlsx'], ['의암호_2016.xlsx', '의암호_2017.xlsx', '의암호_2018.xlsx']]\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2146\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/han/수질/\n",
      "colum_idx :  :,[28,29,30,31,32,33,34,35,36,37,39,40,41,42,43,44]\n",
      "file_names[idx] :  [['대성리_2016.xlsx', '대성리_2017.xlsx', '대성리_2018.xlsx'], ['청평댐3_2016.xlsx', '청평댐3_2017.xlsx', '청평댐3_2018.xlsx'], ['남이섬_2016.xlsx', '남이섬_2017.xlsx', '남이섬_2018.xlsx'], ['가평천3_2016.xlsx', '가평천3_2017.xlsx', '가평천3_2018.xlsx'], ['춘성교_2016.xlsx', '춘성교_2017.xlsx', '춘성교_2018.xlsx'], ['의암_2016.xlsx', '의암_2017.xlsx', '의암_2018.xlsx'], ['춘천_2016.xlsx', '춘천_2017.xlsx', '춘천_2018.xlsx'], ['춘천댐1_2016.xlsx', '춘천댐1_2017.xlsx', '춘천댐1_2018.xlsx'], ['춘천댐3_2016.xlsx', '춘천댐3_2017.xlsx', '춘천댐3_2018.xlsx']]\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/han/방사성/\n",
      "colum_idx :  :,[28,29]\n",
      "file_names[idx] :  [['의암댐_2016.xlsx', '의암댐_2017.xlsx', '의암댐_2018.xlsx']]\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/han/TMS/\n",
      "colum_idx :  :,[27,28,30,31,32,33,35]\n",
      "file_names[idx] :  [['가평청평하수_2016.xlsx', '가평청평하수_2017.xlsx', '가평청평하수_2018.xlsx'], ['가평신천하수_2016.xlsx', '가평신천하수_2017.xlsx', '가평신천하수_2018.xlsx'], ['가평하수_2016.xlsx', '가평하수_2017.xlsx', '가평하수_2018.xlsx'], ['춘천강촌하수_2016.xlsx', '춘천강촌하수_2017.xlsx', '춘천강촌하수_2018.xlsx'], ['춘천하수_2016.xlsx', '춘천하수_2017.xlsx', '춘천하수_2018.xlsx'], ['화천하수_2016.xlsx', '화천하수_2017.xlsx', '화천하수_2018.xlsx']]\n",
      "interpol flag :  [False, False]\n",
      "folder :  data/han/유량/\n",
      "colum_idx :  :,[26]\n",
      "file_names[idx] :  [['가평군(대성리)_2016.xlsx', '가평군(대성리)_2017.xlsx', '가평군(대성리)_2018.xlsx'], ['가평군(청평교)_2016.xlsx', '가평군(청평교)_2017.xlsx', '가평군(청평교)_2018.xlsx'], ['가평군(가평교)_2016.xlsx', '가평군(가평교)_2017.xlsx', '가평군(가평교)_2018.xlsx'], ['춘천시(강촌교)_2016.xlsx', '춘천시(강촌교)_2017.xlsx', '춘천시(강촌교)_2018.xlsx']]\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3166\n",
      "interpol flag :  [False, False]\n",
      "folder :  data/han/수위/\n",
      "colum_idx :  :,[26]\n",
      "file_names[idx] :  [['가평군(대성리)_2016.xlsx', '가평군(대성리)_2017.xlsx', '가평군(대성리)_2018.xlsx'], ['가평군(청평교)_2016.xlsx', '가평군(청평교)_2017.xlsx', '가평군(청평교)_2018.xlsx'], ['가평군(청평댐)_2016.xlsx', '가평군(청평댐)_2017.xlsx', '가평군(청평댐)_2018.xlsx'], ['가평군(가평교)_2016.xlsx', '가평군(가평교)_2017.xlsx', '가평군(가평교)_2018.xlsx'], ['춘천시(강촌교)_2016.xlsx', '춘천시(강촌교)_2017.xlsx', '춘천시(강촌교)_2018.xlsx'], ['춘천시(소양2교)_2016.xlsx', '춘천시(소양2교)_2017.xlsx', '춘천시(소양2교)_2018.xlsx'], ['춘천시(춘천댐)_2016.xlsx', '춘천시(춘천댐)_2017.xlsx', '춘천시(춘천댐)_2018.xlsx'], ['화천군(화천대교)_2016.xlsx', '화천군(화천대교)_2017.xlsx', '화천군(화천대교)_2018.xlsx']]\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1071\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/han/총량/\n",
      "colum_idx :  :,28:45\n",
      "file_names[idx] :  [['조종천3_2016.xlsx', '조종천3_2017.xlsx', '조종천3_2018.xlsx'], ['청평_2016.xlsx', '청평_2017.xlsx', '청평_2018.xlsx'], ['가평천3_2016.xlsx', '가평천3_2017.xlsx', '가평천3_2018.xlsx'], ['춘성교_2016.xlsx', '춘성교_2017.xlsx', '춘성교_2018.xlsx'], ['화천_2016.xlsx', '화천_2017.xlsx', '화천_2018.xlsx']]\n",
      "interpol flag :  [True, False]\n",
      "folder :  data/han/퇴적물/\n",
      "colum_idx :  :,[27,28,29,30,31,33]\n",
      "file_names[idx] :  [['대성리_2016.xlsx', '대성리_2017.xlsx', '대성리_2018.xlsx'], ['청평댐2_2016.xlsx', '청평댐2_2017.xlsx', '청평댐2_2018.xlsx'], ['춘성교_2016.xlsx', '춘성교_2017.xlsx', '춘성교_2018.xlsx'], ['의암댐2_2016.xlsx', '의암댐2_2017.xlsx', '의암댐2_2018.xlsx'], ['춘천댐2_2016.xlsx', '춘천댐2_2017.xlsx', '춘천댐2_2018.xlsx'], ['춘천댐3_2016.xlsx', '춘천댐3_2017.xlsx', '춘천댐3_2018.xlsx']]\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/han/조류/\n",
      "colum_idx :  :,[30,31,36,40,50]\n",
      "file_names[idx] :  [['의암호_2016.xlsx', '의암호_2017.xlsx', '의암호_2018.xlsx'], ['춘천호_2016.xlsx', '춘천호_2017.xlsx', '춘천호_2018.xlsx']]\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/han/산업계/\n",
      "colum_idx :  :,5:\n",
      "file_names[idx] :  [['1_2016.xlsx', '1_2017.xlsx', '1_2018.xlsx'], ['2_2016.xlsx', '2_2017.xlsx', '2_2018.xlsx'], ['3_2016.xlsx', '3_2017.xlsx', '3_2018.xlsx'], ['4_2016.xlsx', '4_2017.xlsx', '4_2018.xlsx'], ['5_2016.xlsx', '5_2017.xlsx', '5_2018.xlsx'], ['6_2016.xlsx', '6_2017.xlsx', '6_2018.xlsx'], ['7_2016.xlsx', '7_2017.xlsx', '7_2018.xlsx'], ['8_2016.xlsx', '8_2017.xlsx', '8_2018.xlsx'], ['9_2016.xlsx', '9_2017.xlsx', '9_2018.xlsx'], ['10_2016.xlsx', '10_2017.xlsx', '10_2018.xlsx'], ['11_2016.xlsx', '11_2017.xlsx', '11_2018.xlsx'], ['12_2016.xlsx', '12_2017.xlsx', '12_2018.xlsx']]\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/han/물사용량/\n",
      "colum_idx :  :,5:\n",
      "file_names[idx] :  [['1_2016.xlsx', '1_2017.xlsx', '1_2018.xlsx'], ['2_2016.xlsx', '2_2017.xlsx', '2_2018.xlsx'], ['3_2016.xlsx', '3_2017.xlsx', '3_2018.xlsx'], ['4_2016.xlsx', '4_2017.xlsx', '4_2018.xlsx'], ['5_2016.xlsx', '5_2017.xlsx', '5_2018.xlsx'], ['6_2016.xlsx', '6_2017.xlsx', '6_2018.xlsx'], ['7_2016.xlsx', '7_2017.xlsx', '7_2018.xlsx'], ['8_2016.xlsx', '8_2017.xlsx', '8_2018.xlsx'], ['9_2016.xlsx', '9_2017.xlsx', '9_2018.xlsx'], ['10_2016.xlsx', '10_2017.xlsx', '10_2018.xlsx'], ['11_2016.xlsx', '11_2017.xlsx', '11_2018.xlsx'], ['12_2016.xlsx', '12_2017.xlsx', '12_2018.xlsx']]\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/han/인구/\n",
      "colum_idx :  :,5:\n",
      "file_names[idx] :  [['1_2016.xlsx', '1_2017.xlsx', '1_2018.xlsx'], ['2_2016.xlsx', '2_2017.xlsx', '2_2018.xlsx'], ['3_2016.xlsx', '3_2017.xlsx', '3_2018.xlsx'], ['4_2016.xlsx', '4_2017.xlsx', '4_2018.xlsx'], ['5_2016.xlsx', '5_2017.xlsx', '5_2018.xlsx'], ['6_2016.xlsx', '6_2017.xlsx', '6_2018.xlsx'], ['7_2016.xlsx', '7_2017.xlsx', '7_2018.xlsx'], ['8_2016.xlsx', '8_2017.xlsx', '8_2018.xlsx'], ['9_2016.xlsx', '9_2017.xlsx', '9_2018.xlsx'], ['10_2016.xlsx', '10_2017.xlsx', '10_2018.xlsx'], ['11_2016.xlsx', '11_2017.xlsx', '11_2018.xlsx'], ['12_2016.xlsx', '12_2017.xlsx', '12_2018.xlsx']]\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/han/양식계/\n",
      "colum_idx :  :,5:\n",
      "file_names[idx] :  [['1_2016.xlsx', '1_2017.xlsx', '1_2018.xlsx'], ['2_2016.xlsx', '2_2017.xlsx', '2_2018.xlsx'], ['3_2016.xlsx', '3_2017.xlsx', '3_2018.xlsx'], ['4_2016.xlsx', '4_2017.xlsx', '4_2018.xlsx'], ['5_2016.xlsx', '5_2017.xlsx', '5_2018.xlsx'], ['6_2016.xlsx', '6_2017.xlsx', '6_2018.xlsx'], ['7_2016.xlsx', '7_2017.xlsx', '7_2018.xlsx'], ['8_2016.xlsx', '8_2017.xlsx', '8_2018.xlsx'], ['9_2016.xlsx', '9_2017.xlsx', '9_2018.xlsx'], ['10_2016.xlsx', '10_2017.xlsx', '10_2018.xlsx'], ['11_2016.xlsx', '11_2017.xlsx', '11_2018.xlsx'], ['12_2016.xlsx', '12_2017.xlsx', '12_2018.xlsx']]\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/han/축산계/\n",
      "colum_idx :  :,5:\n",
      "file_names[idx] :  [['1_2016.xlsx', '1_2017.xlsx', '1_2018.xlsx'], ['2_2016.xlsx', '2_2017.xlsx', '2_2018.xlsx'], ['3_2016.xlsx', '3_2017.xlsx', '3_2018.xlsx'], ['4_2016.xlsx', '4_2017.xlsx', '4_2018.xlsx'], ['5_2016.xlsx', '5_2017.xlsx', '5_2018.xlsx'], ['6_2016.xlsx', '6_2017.xlsx', '6_2018.xlsx'], ['7_2016.xlsx', '7_2017.xlsx', '7_2018.xlsx'], ['8_2016.xlsx', '8_2017.xlsx', '8_2018.xlsx'], ['9_2016.xlsx', '9_2017.xlsx', '9_2018.xlsx'], ['10_2016.xlsx', '10_2017.xlsx', '10_2018.xlsx'], ['11_2016.xlsx', '11_2017.xlsx', '11_2018.xlsx'], ['12_2016.xlsx', '12_2017.xlsx', '12_2018.xlsx']]\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/han/토지계/\n",
      "colum_idx :  :,[5,6,7,8,9,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32]\n",
      "file_names[idx] :  [['1_2016.xlsx', '1_2017.xlsx', '1_2018.xlsx'], ['2_2016.xlsx', '2_2017.xlsx', '2_2018.xlsx'], ['3_2016.xlsx', '3_2017.xlsx', '3_2018.xlsx'], ['4_2016.xlsx', '4_2017.xlsx', '4_2018.xlsx'], ['5_2016.xlsx', '5_2017.xlsx', '5_2018.xlsx'], ['6_2016.xlsx', '6_2017.xlsx', '6_2018.xlsx'], ['7_2016.xlsx', '7_2017.xlsx', '7_2018.xlsx'], ['8_2016.xlsx', '8_2017.xlsx', '8_2018.xlsx'], ['9_2016.xlsx', '9_2017.xlsx', '9_2018.xlsx'], ['10_2016.xlsx', '10_2017.xlsx', '10_2018.xlsx'], ['11_2016.xlsx', '11_2017.xlsx', '11_2018.xlsx'], ['12_2016.xlsx', '12_2017.xlsx', '12_2018.xlsx']]\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "interpol flag :  [True, True]\n",
      "folder :  data/han/기타수질오염원/\n",
      "colum_idx :  :,5:\n",
      "file_names[idx] :  [['1_2016.xlsx', '1_2017.xlsx', '1_2018.xlsx'], ['2_2016.xlsx', '2_2017.xlsx', '2_2018.xlsx'], ['3_2016.xlsx', '3_2017.xlsx', '3_2018.xlsx'], ['4_2016.xlsx', '4_2017.xlsx', '4_2018.xlsx'], ['5_2016.xlsx', '5_2017.xlsx', '5_2018.xlsx'], ['6_2016.xlsx', '6_2017.xlsx', '6_2018.xlsx'], ['7_2016.xlsx', '7_2017.xlsx', '7_2018.xlsx'], ['8_2016.xlsx', '8_2017.xlsx', '8_2018.xlsx'], ['9_2016.xlsx', '9_2017.xlsx', '9_2018.xlsx'], ['10_2016.xlsx', '10_2017.xlsx', '10_2018.xlsx'], ['11_2016.xlsx', '11_2017.xlsx', '11_2018.xlsx'], ['12_2016.xlsx', '12_2017.xlsx', '12_2018.xlsx']]\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n",
      "row in\n"
     ]
    }
   ],
   "source": [
    "for i in range(length):\n",
    "\n",
    "    idx = run_num[i]\n",
    "\n",
    "    print('interpol flag : ', interpolation_option[idx])\n",
    "    print('folder : ', data_path + folder[idx])\n",
    "    print('colum_idx : ', colum_idx[idx])\n",
    "    print('file_names[idx] : ', file_names[idx])\n",
    "\n",
    "    #df, times = make_dataframe(data_path+folder[idx], file_names[idx], colum_idx[idx], interpolation=interpolation_option[idx])\n",
    "    df, times, mmmonth, ddday = make_dataframe(data_path+folder[idx], file_names[idx], \n",
    "                               colum_idx[idx], interpolation=interpolation_option[idx],\n",
    "                              first_file_no=i, month=mmmonth, day=ddday)\n",
    "\n",
    "    df_all, train_mean, train_std, df = normalize(df)\n",
    "\n",
    "\n",
    "    if i == 0:\n",
    "        dfff = df\n",
    "        target_all = df_all\n",
    "        target_std = train_std\n",
    "        target_mean = train_mean\n",
    "        start_year = str(times.iloc[0].year)\n",
    "        end_year = str(times.iloc[-1].year)\n",
    "\n",
    "    if interpolation_option[idx][0] == False:\n",
    "\n",
    "        loadfiles = ['idx.npy', 'miss.npy', 'discriminator.h5', 'generator.h5']\n",
    "\n",
    "        gain_calc_falg = True\n",
    "\n",
    "        if __GAIN_TRAINING__ == True:\n",
    "            gain_calc_falg = MissData.save(pd.concat(df, axis=0).to_numpy(), max_tseq=24, save_dir='save/')\n",
    "            #print(folder[idx], ': training ', 'Miss date save : ', gain_calc_falg)\n",
    "        else:\n",
    "            for file in loadfiles:\n",
    "                if os.path.isfile('save/' + folder[idx]+file):\n",
    "                    shutil.copyfile('save/' + folder[idx]+file, 'save/'+file)\n",
    "                    #print('load file name : save/' + folder[idx]+file)\n",
    "                else:\n",
    "                    if file == 'miss.npy':\n",
    "                        gain_calc_falg = MissData.save(pd.concat(df, axis=0).to_numpy(), max_tseq=24, save_dir='save/')\n",
    "                        #print(folder[idx], ': is not miss.npy ', 'Miss date save : ', gain_calc_falg)\n",
    "\n",
    "        if gain_calc_falg == True:\n",
    "            #print('GainWindowGenerator in main')\n",
    "            WindowGenerator.make_dataset = make_dataset_gain\n",
    "            wide_window = WindowGenerator(input_width=gain_in_setps, label_width=gain_out_setps, shift=gain_shift,\n",
    "                                          fill_no=gain_fill_no, miss_rate=gain_miss_rate, batch_size=gain_batch_size,\n",
    "                                          train_df = df_all, val_df = df_all, test_df = df_all, df = df)\n",
    "\n",
    "            #gain = model_GAIN(shape=wide_window.dg.shape[1:], gen_sigmoid=False, epochs=gain_epochs, training_flag=__GAIN_TRAINING__, window=wide_window, model_save_path='save/')\n",
    "            gain = model_GAIN(shape=(gain_in_setps, df_all.shape[1]), gen_sigmoid=False, epochs=gain_epochs,\n",
    "                              training_flag=__GAIN_TRAINING__, window=wide_window, model_save_path='save/')\n",
    "\n",
    "            gain_val_performance[str(i)] = gain.evaluate(wide_window.val)\n",
    "            gain_performance[str(i)] = gain.evaluate(wide_window.test, verbose=0)\n",
    "\n",
    "            #print('file proc in main')\n",
    "            if __GAIN_TRAINING__ == True:\n",
    "                #dir = 'save/'+folder[i]\n",
    "                if not os.path.exists('save/' + folder[idx]):\n",
    "                    os.makedirs('save/'+folder[idx])\n",
    "                for file in loadfiles:\n",
    "                    shutil.copyfile('save/' + file, 'save/' + folder[idx] + file)\n",
    "\n",
    "            #print('create_dataset_with_gain in main')\n",
    "            #ori, gan = create_dataset_with_gain(gain=gain, window=wide_window, df=df)\n",
    "            ori, gan = create_dataset_with_gain(gain=gain, shape=(gain_in_setps, df_all.shape[1]), df=df)\n",
    "\n",
    "        else:\n",
    "            gan = create_dataset_interpol(window=gain_in_setps, df=df)\n",
    "    else:\n",
    "        gan = create_dataset_interpol(window=gain_in_setps, df=df)\n",
    "\n",
    "    if i == 0 :\n",
    "#        if i < length -1:\n",
    "#            gan = gan[:,:-4]  #맨마지막전까지 사인코사인삭제\n",
    "#            print(gan.shape)\n",
    "        real_df_all = pd.DataFrame(gan)\n",
    "    else:\n",
    "#        if i < length -1:\n",
    "#            gan = gan[:,:-4]  #맨마지막전까지 사인코사인삭제\n",
    "#            print(gan.shape)\n",
    "        real_df_all = pd.concat([real_df_all, pd.DataFrame(gan)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-evening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "civilian-creator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "#            RRRRRRRRRRRRRRRRRR          NNNNNN       NNNNNN      NNNNNN       NNNNNN\n",
    "#           RRRRRRRRRRRRRRRRRRRR        NNNNNNN      NNNNNN      NNNNNNN      NNNNNN\n",
    "#          RRRRRRR      RRRRRRRR       NNNNNNNN     NNNNNN      NNNNNNNN     NNNNNN\n",
    "#         RRRRRRR      RRRRRRRR       NNNNNNNNN    NNNNNN      NNNNNNNNN    NNNNNN\n",
    "#        RRRRRRRRRRRRRRRRRRRR        NNNNNNNNNN   NNNNNN      NNNNNNNNNN   NNNNNN\n",
    "#       RRRRRRRRRRRRRRRRR           NNNNNNNNNNN  NNNNNN      NNNNNNNNNNN  NNNNNN \n",
    "#      RRRRRRR     RRRRRRR         NNNNNNN NNNN NNNNNN      NNNNNNN NNNN NNNNNN\n",
    "#     RRRRRRR       RRRRRRR       NNNNNNN  NNNNNNNNNN      NNNNNNN  NNNNNNNNNN\n",
    "#    RRRRRRR        RRRRRRR      NNNNNNN   NNNNNNNNN      NNNNNNN   NNNNNNNNN\n",
    "#   RRRRRRR         RRRRRRR     NNNNNNN    NNNNNNNN      NNNNNNN    NNNNNNNN \n",
    "#  RRRRRRR         RRRRRRR     NNNNNNN     NNNNNNN      NNNNNNN     NNNNNNN\n",
    "#-----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comprehensive-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pd.DataFrame(gan).tail\n",
    "#real_df_all.tail\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "technological-homework",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_columns_indices:\n",
      "{'tmpr_value': 0, 'ph_value': 1, 'do_value': 2, 'ec_value': 3, 'toc_value': 4, '총질소_값': 5, '총인_값': 6, '클로로필-a_값': 7, 'Day sin': 8, 'Day cos': 9, 'Year sin': 10, 'Year cos': 11}\n",
      "target_col_idx :  2\n",
      "out_num_features :  1\n"
     ]
    }
   ],
   "source": [
    "label_columns_indices = {name: i for i, name in enumerate(dfff[0])}\n",
    "print(\"label_columns_indices:\")\n",
    "print(label_columns_indices)\n",
    "target_dic = {\"do\":\"do_value\", \"toc\":\"toc_value\", \"tn\":\"총질소_값\", \"tp\":\"총인_값\", \"chl-a\":\"클로로필-a_값\"}\n",
    "target_col_idx = label_columns_indices[target_dic[rnn_target_column]]\n",
    "out_features = [target_col_idx]\n",
    "out_num_features = len(out_features)\n",
    "\n",
    "print(\"target_col_idx : \", target_col_idx)\n",
    "print('out_num_features : ', out_num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-shift",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "prime-fellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26304, 1587)\n",
      "chl-a\n"
     ]
    }
   ],
   "source": [
    "#ctrl f -- 타겟\n",
    "\n",
    "print(real_df_all.shape)\n",
    "rnn_target_column = 'chl-a'\n",
    "print(rnn_target_column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "nasty-canberra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.shape :  (18412, 1587) val_df.shape :  (5261, 1587) test_df.shape: (2631, 1587)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#train_df, test_df, val_df, test_df2 = dataset_slice(real_df_all, 0.8, 0.1, 0.1)\n",
    "#teg_check = 'train=8, test=1, val=1'\n",
    "\n",
    "train_df, test_df, val_df = dataset_slice(real_df_all, 0.7, 0.1, 0.2)\n",
    "teg_check = 'train=7, val=1, test=2'\n",
    "\n",
    "print('train_df.shape : ', train_df.shape, 'val_df.shape : ', val_df.shape, 'test_df.shape:' ,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "academic-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake_df.shape[0]/8760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "sought-radar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_columns_indices:\n",
      "{'tmpr_value': 0, 'ph_value': 1, 'do_value': 2, 'ec_value': 3, 'toc_value': 4, '총질소_값': 5, '총인_값': 6, '클로로필-a_값': 7, 'Day sin': 8, 'Day cos': 9, 'Year sin': 10, 'Year cos': 11}\n"
     ]
    }
   ],
   "source": [
    "idx = [2, 4, 5, 6, 7]\n",
    "pa = [\"do/\", \"toc/\", \"nitrogen/\", \"phosphorus/\", \"chlorophyll-a/\"]\n",
    "indices = {name: i for i, name in enumerate(idx)}\n",
    "target_dic = {\"do\":\"do_value\", \"toc\":\"toc_value\", \"tn\":\"총질소_값\", \"tp\":\"총인_값\", \"chl-a\":\"클로로필-a_값\"}\n",
    "label_columns_indices = {name: i for i, name in enumerate(dfff[0])}\n",
    "print(\"label_columns_indices:\")\n",
    "print(label_columns_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "imposed-stake",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_col_idx = label_columns_indices[target_dic[rnn_target_column]]\n",
    "out_features = [target_col_idx]\n",
    "out_num_features = len(out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "transsexual-grace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model path :  save/han/models/han_pull/chlorophyll-a/\n"
     ]
    }
   ],
   "source": [
    "WindowGenerator.make_dataset = make_dataset_water\n",
    "multi_window = WindowGenerator(\n",
    "    input_width=rnn_in_setps,label_width=rnn_out_steps, shift=rnn_out_steps,out_features=out_features,\n",
    "    out_num_features=out_num_features,label_columns=dfff[0].columns, batch_size=rnn_batch_size,\n",
    "    train_df=train_df, val_df=val_df, test_df=test_df)\n",
    "\n",
    "model_path = \"save/\" + watershed + \"models/\" + file_parameters['watershed'] + '/'+  pa[indices[target_col_idx]]\n",
    "print(\"save model path : \", model_path)\n",
    "\n",
    "if __RNN_TRAINING__:\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "super-medicaid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 240, True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_epochs, rnn_in_setps, __RNN_TRAINING__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-commander",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "closing-beads",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/15\n",
      "5/5 [==============================] - 191s 38s/step - loss: 0.5992 - mean_absolute_error: 0.5996 - nse: -0.6735 - val_loss: 1.3190 - val_mean_absolute_error: 0.6502 - val_nse: -0.1977\n",
      "Epoch 2/15\n",
      "5/5 [==============================] - 175s 35s/step - loss: 0.3618 - mean_absolute_error: 0.4626 - nse: -0.1182 - val_loss: 1.2119 - val_mean_absolute_error: 0.5947 - val_nse: -0.1061\n",
      "Epoch 3/15\n",
      "5/5 [==============================] - 174s 35s/step - loss: 0.2486 - mean_absolute_error: 0.3838 - nse: 0.1420 - val_loss: 1.1267 - val_mean_absolute_error: 0.5588 - val_nse: -0.0210\n",
      "Epoch 4/15\n",
      "5/5 [==============================] - 175s 35s/step - loss: 0.2080 - mean_absolute_error: 0.3472 - nse: 0.3377 - val_loss: 1.0328 - val_mean_absolute_error: 0.5315 - val_nse: 0.0492\n",
      "Epoch 5/15\n",
      "5/5 [==============================] - 175s 35s/step - loss: 0.1739 - mean_absolute_error: 0.3153 - nse: 0.4874 - val_loss: 1.1173 - val_mean_absolute_error: 0.5763 - val_nse: -0.0260\n",
      "Epoch 6/15\n",
      "5/5 [==============================] - 175s 35s/step - loss: 0.1350 - mean_absolute_error: 0.2772 - nse: 0.5123 - val_loss: 1.0008 - val_mean_absolute_error: 0.5475 - val_nse: 0.0814\n",
      "Epoch 7/15\n",
      "5/5 [==============================] - 175s 35s/step - loss: 0.1386 - mean_absolute_error: 0.2808 - nse: 0.5831 - val_loss: 1.0970 - val_mean_absolute_error: 0.5680 - val_nse: -0.0130\n",
      "Epoch 8/15\n",
      "5/5 [==============================] - 176s 35s/step - loss: 0.1270 - mean_absolute_error: 0.2670 - nse: 0.6152 - val_loss: 1.0602 - val_mean_absolute_error: 0.5678 - val_nse: 0.0243\n",
      "Epoch 9/15\n",
      "5/5 [==============================] - 175s 35s/step - loss: 0.1134 - mean_absolute_error: 0.2519 - nse: 0.6285 - val_loss: 0.9575 - val_mean_absolute_error: 0.5406 - val_nse: 0.1196\n",
      "Epoch 10/15\n",
      "5/5 [==============================] - 175s 35s/step - loss: 0.1153 - mean_absolute_error: 0.2582 - nse: 0.6473 - val_loss: 1.0930 - val_mean_absolute_error: 0.5764 - val_nse: -0.0038\n",
      "Epoch 11/15\n",
      "5/5 [==============================] - 175s 35s/step - loss: 0.1019 - mean_absolute_error: 0.2395 - nse: 0.6164 - val_loss: 1.1347 - val_mean_absolute_error: 0.5986 - val_nse: -0.0520\n",
      "Epoch 12/15\n",
      "5/5 [==============================] - 176s 35s/step - loss: 0.0961 - mean_absolute_error: 0.2311 - nse: 0.6584 - val_loss: 1.1214 - val_mean_absolute_error: 0.5922 - val_nse: -0.0401\n",
      "Epoch 13/15\n",
      "5/5 [==============================] - 174s 35s/step - loss: 0.1011 - mean_absolute_error: 0.2363 - nse: 0.7007 - val_loss: 1.1541 - val_mean_absolute_error: 0.6056 - val_nse: -0.0656\n",
      "Epoch 14/15\n",
      "5/5 [==============================] - 175s 35s/step - loss: 0.0906 - mean_absolute_error: 0.2236 - nse: 0.6987 - val_loss: 1.1083 - val_mean_absolute_error: 0.5831 - val_nse: -0.0207\n",
      "Epoch 15/15\n",
      "5/5 [==============================] - 175s 35s/step - loss: 0.0902 - mean_absolute_error: 0.2201 - nse: 0.7191 - val_loss: 1.0775 - val_mean_absolute_error: 0.5865 - val_nse: -0.0041\n"
     ]
    }
   ],
   "source": [
    "gru_model = model_gru(\n",
    "    #window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "    window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=15, steps_per_epoch = 5,\n",
    "    #window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=2, steps_per_epoch = 2,\n",
    "    #training_flag=__RNN_TRAINING__, checkpoint_path=model_path+\"gru.ckpt\", continue_train=False)\n",
    "    training_flag=True, checkpoint_path=model_path+\"gru.ckpt\", continue_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aging-occasions",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd79a1c0be064d9c8c90f574f9e6bfc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/han/models/han_pull/chlorophyll-a/\n",
      "year : 2016 ~ 2018\n",
      "run :  range(0, 16)\n",
      "target :  chl-a   7\n",
      "length :  26304\n",
      "train=7, val=1, test=2\n",
      "all_nse :  [0.53410782]\n",
      "all_pbias :  [-6.2936557]\n",
      "all_mae :  3.1502822397254513\n",
      "all_rmse :  5.337687707964228\n",
      "all_Rs :  0.5490558220798593\n",
      "all_R :  0.7409830106553451\n"
     ]
    }
   ],
   "source": [
    "val_nse = {}\n",
    "val_pbias = {}\n",
    "val_nse['GRU'], val_pbias['GRU'], pred, label, _mae, _rmse, _Rs, _R = compa(\n",
    "    model=gru_model,df=real_df_all, plot_col=out_features[0], target_std=target_std, target_mean=target_mean,\n",
    "    predict_day = rnn_predict_day)\n",
    "    #predict_day = 4)\n",
    "    \n",
    "print(model_path)\n",
    "print(\"year : \" + start_year + \" ~ \"+ end_year)\n",
    "print('run : ', run_num)\n",
    "print('target : ', rnn_target_column , \" \", out_features[0])\n",
    "print(\"length : \",real_df_all.shape[0])\n",
    "print(teg_check)\n",
    "\n",
    "print('all_nse : ', val_nse['GRU'])\n",
    "print('all_pbias : ', val_pbias['GRU'])\n",
    "print('all_mae : ', _mae)\n",
    "print('all_rmse : ', _rmse)\n",
    "print('all_Rs : ', _Rs)\n",
    "print('all_R : ', _R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "imported-frequency",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4907966af8a548b29606622eb3931e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "train_nse :  [0.7682126]\n",
      "train_pbias :  [-19.50011523]\n",
      "train_mae :  2.0819570195717847\n",
      "train_rmse :  2.4712510584334924\n",
      "train_Rs :  0.8626258699498459\n",
      "train_R :  0.9287765446811445\n"
     ]
    }
   ],
   "source": [
    "val_nse = {}\n",
    "val_pbias = {}\n",
    "val_nse['GRU'], val_pbias['GRU'], pred, label, _mae, _rmse, _Rs, _R = compa(\n",
    "    model=gru_model,df=train_df, plot_col=out_features[0], target_std=target_std, target_mean=target_mean,\n",
    "    predict_day = rnn_predict_day)\n",
    "    #predict_day = 4)\n",
    "\n",
    "print('----------------------------')\n",
    "print('train_nse : ', val_nse['GRU'])\n",
    "print('train_pbias : ', val_pbias['GRU'])\n",
    "print('train_mae : ', _mae)\n",
    "print('train_rmse : ', _rmse)\n",
    "print('train_Rs : ', _Rs)\n",
    "print('train_R : ', _R)\n",
    "\n",
    "#print('nse_train : ', val_nse['GRU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "documentary-lawyer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3f6c3cb6cd4dec8a90603c1fa8ccdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "val_nse :  [0.44237455]\n",
      "val_pbias :  [13.73031015]\n",
      "val_mae :  6.202395303611135\n",
      "val_rmse :  8.65052219097949\n",
      "val_Rs :  0.5438810461044179\n",
      "val_R :  0.7374829124152084\n"
     ]
    }
   ],
   "source": [
    "val_nse = {}\n",
    "val_pbias = {}\n",
    "val_nse['GRU'], val_pbias['GRU'], pred, label, _mae, _rmse, _Rs, _R = compa(\n",
    "    model=gru_model,df=test_df, plot_col=out_features[0], target_std=target_std, target_mean=target_mean,\n",
    "    predict_day = rnn_predict_day)\n",
    "    #predict_day = 4)\n",
    "\n",
    "print('----------------------------')\n",
    "print('val_nse : ', val_nse['GRU'])\n",
    "print('val_pbias : ', val_pbias['GRU'])\n",
    "print('val_mae : ', _mae)\n",
    "print('val_rmse : ', _rmse)\n",
    "print('val_Rs : ', _Rs)\n",
    "print('val_R : ', _R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "smooth-wilson",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0dc36953b0c4c84863dce473d026929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "test_nse :  [0.1953213]\n",
      "test_pbias :  [20.6149338]\n",
      "test_mae :  5.220278730007588\n",
      "test_rmse :  9.137366323314119\n",
      "test_Rs :  0.24646648777220204\n",
      "test_R :  0.4964539130394704\n"
     ]
    }
   ],
   "source": [
    "val_nse = {}\n",
    "val_pbias = {}\n",
    "val_nse['GRU'], val_pbias['GRU'], pred, label, _mae, _rmse, _Rs, _R = compa(\n",
    "    model=gru_model,df=val_df, plot_col=out_features[0], target_std=target_std, target_mean=target_mean,\n",
    "    predict_day = rnn_predict_day)\n",
    "\n",
    "print('----------------------------')\n",
    "print('test_nse : ', val_nse['GRU'])\n",
    "print('test_pbias : ', val_pbias['GRU'])\n",
    "print('test_mae : ', _mae)\n",
    "print('test_rmse : ', _rmse)\n",
    "print('test_Rs : ', _Rs)\n",
    "print('test_R : ', _R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "respective-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "primary-polyester",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e66a6ade5f40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#      SSSSSSSSSSSSSSSSSS                  ******              *********************      *****\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#-----------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "# 123SFACVTHYI78567UDBYUJM534523RDHGTHETYIE5I8I78O9P789J467UBDFGDASFSADCXVFDSWERTNERGRTTUTYAFGASDFSDBGFDF67E54563\n",
    "# 64534FDSFVSDHT56SDFG656USRHSDYA3Y RTA WERGERGSDFGVTY34TASDF dfasdfghhgbcvbsdfgrwergfdsfvzxcvasdfaweqdqasdfderadf\n",
    "# feasetttttttttttttttttttvxzcvxzvxcvxvnjfghjvb111nfghjdfhgdhthrtyyyyyyyyyyrtjliuioyuytrtyurtyughjuyityuityuityuijjty\n",
    "# hgfgdrrtyetghfdghvcvbnhjfghjgggnfnmjhkuytlryewqwerasdfgghrthfgjyruhjyuihjknhybgtvfrcdezxcabnghrtyreeghghte45654y  \n",
    "# tr345rgbbbdfghterty4534562345jhgy5462345234534n5345g345t3245d34f235345f345g34454f345t345er345234yt545y45tg45t534\n",
    "#       SSSSSSSSSSSSSS         ASDFALKJIVAJLMSEFLKMALSKVJALKSRKLTGAKLSDGVLK   *****    ***************   \n",
    "#            SSSSSSSSSSSSS               ******            ******              *****    *************       (*_*)  \n",
    "#                   SSSSSSSS               ******            ******              *****    *****            ~( (>\n",
    "#        SSSS         S  SSS               ******            ******              *****    *****            / (          \n",
    "#      SSSS          S  SSSS               ******            ******              *****    *****                     \n",
    "#     SSSSS            SSSS                ******             ******            ******    *****                     \n",
    "#      SSSSSSSSSSSSSSSSSS                  ******              *********************      *****                   \n",
    "#-----------------------------------------------------------------------------------------------------------------\n",
    "stop = stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-identifier",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sub_flag = True\n",
    "history_nse = []\n",
    "\n",
    "bob = 0\n",
    "b = 1\n",
    "\n",
    "while sub_flag:\n",
    "    \n",
    "\n",
    "    \n",
    "    gru_model = model_gru(\n",
    "        #window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=rnn_epochs,\n",
    "        window=multi_window, OUT_STEPS=rnn_out_steps, out_num_features=out_num_features, epochs=15, steps_per_epoch = 5,\n",
    "        training_flag=True, checkpoint_path=model_path+\"gru.ckpt\", continue_train=False)\n",
    "    \n",
    "    #nse, _, _, _ = compa(\n",
    "        #model=gru_model,df=val_df, plot_col=out_features[0], target_std=target_std, target_mean=target_mean,\n",
    "        #predict_day = rnn_predict_day)\n",
    "        #predict_day = 4)\n",
    "    \n",
    "    nse, _, _, _, _, _, _, _ = compa(\n",
    "    model=gru_model,df=val_df, plot_col=out_features[0], target_std=target_std, target_mean=target_mean,\n",
    "    #predict_day = rnn_predict_day)\n",
    "    predict_day = 4)\n",
    "    \n",
    "    if(nse > 0.5):\n",
    "        sub_flag = False\n",
    "   \n",
    "    \n",
    "    history_nse.append(nse)\n",
    "    \n",
    "    print('--------------------------')\n",
    "    print(history_nse)\n",
    "    print(nse)\n",
    "    print('--------------------------')\n",
    "    \n",
    "        \n",
    "    bob += b\n",
    "    if(bob < -4):\n",
    "        b = 1\n",
    "    if(bob > 0):\n",
    "        b = -1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-confidence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-cooling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-causing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-poison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-grove",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-battle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-hypothetical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-cartoon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-christmas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-planner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-craps",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-military",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-halloween",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-measurement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-variable",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-message",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-catalog",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-honduras",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-marker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-antibody",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
